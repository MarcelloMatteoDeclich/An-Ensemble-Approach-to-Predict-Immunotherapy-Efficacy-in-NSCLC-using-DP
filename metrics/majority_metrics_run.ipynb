{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import platform\n",
    "device_name = platform.node()\n",
    "\n",
    "previous_folder = os.getcwd()\n",
    "print (\"This is the working folder: \" + previous_folder)\n",
    "\n",
    "if device_name == 'mmd-MS-7D98': \n",
    "    #This passage is done because everytime I log into the remote server the default folder is:\n",
    "    #/mmd/home and I need to localize the correct folder to load the settings \n",
    "    os.chdir(\"/media/mmd/Samsung_T5/GitHub/UMD\")\n",
    "\n",
    "if previous_folder != os.getcwd(): # This is now the right working folder\n",
    "    print(\"The current working folder has been changed, now the working folder is: \" + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"my_library\")\n",
    "from my_library.config import *\n",
    "from my_library.metrics.cmp_metrics import *\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear example of spaghetti code\n",
    "I had to rush to obtain the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval = \"ALLeval/eval/test-int\"\n",
    "#eval = \"ALLeval/eval_15folds/test-int\"\n",
    "eval = \"ALLeval/eval_max50slides/test-int\"\n",
    "#eval = \"ALLeval/eval_1_single_fold/test-int\"\n",
    "#setup =\"1 Fold\"\n",
    "#setup =\"15 Fold\"\n",
    "setup = \"5 Folds-Max 50 Tiles\"\n",
    "#setup = \"5 Folds\"\n",
    "\n",
    "#ile_name = \"ABMIL_results_test_set_all models_15_fold.xlsx\"\n",
    "file_name = \"ABMIL_results_test_set_all models_Max50tiles_fold.xlsx\"\n",
    "#file_name = \"ABMIL_results_test_single_model.xlsx\"\n",
    "#file_name = \"ABMIL_results_test_set_all models.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = os.path.join(working_directory,eval)\n",
    "subfolder = [name for name in os.listdir(base_folder) if os.path.isdir(os.path.join(base_folder, name))]\n",
    "\n",
    "results = []\n",
    "intermediate_values = []\n",
    "df_test_list = []\n",
    "\n",
    "for m in subfolder:\n",
    "    df = []\n",
    "    print(m)\n",
    "    root_dir = os.path.join(base_folder, m)\n",
    "\n",
    "    %run -i './metriche/from_parquet.ipynb'\n",
    "\n",
    "    #print(parent_directory)\n",
    "    #compute_metrics(parent_directory, n_classes, parent_directory)\n",
    "    results.append(df)\n",
    "    df_test_list.append(df_test)\n",
    "    intermediate_values.append((m, y_true, y_pred, outcome_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_values[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in intermediate_values:\n",
    "    model, y_true, y_pred, outcome_labels = i\n",
    "\n",
    "    print(outcome_labels)\n",
    "    \n",
    "    labels = [idx for idx, val in enumerate(sorted(set(outcome_labels)))]\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    conf_matrix = np.array(conf_matrix)\n",
    "    plot_confusion_matrix_complex(conf_matrix, outcome_labels,  model, setup, working_directory = working_directory, cmap = \"YlGnBu\")\n",
    "\n",
    "\n",
    "    if model == \"pdl1-3\":\n",
    "        outcome_labels = np.array(list(outcome_labels))\n",
    "        outcome_labels[0], outcome_labels[1] = outcome_labels[1], outcome_labels[0]\n",
    "\n",
    "        conf_matrix[[0, 1]] = conf_matrix[[1, 0]]\n",
    "        plot_confusion_matrix_complex(conf_matrix, outcome_labels,  model, setup, working_directory = working_directory, cmap = \"YlGnBu\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"conf_matrix = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
    "conf_matrix = np.array(conf_matrix)\n",
    "plot_confusion_matrix_complex(conf_matrix, outcome_labels,  m, \"15 Folds\", \"YlGnBu\")\n",
    "\n",
    "outcome_labels = np.array(list(outcome_labels))\n",
    "outcome_labels[0], outcome_labels[1] = outcome_labels[1], outcome_labels[0]\n",
    "\n",
    "conf_matrix[[0, 1]] = conf_matrix[[1, 0]]\n",
    "plot_confusion_matrix_complex(conf_matrix, outcome_labels,  m, \"15 Folds\", \"YlGnBu\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for i, m in zip(results, subfolder):\n",
    "    transpose_df = i.T\n",
    "    transpose_df = transpose_df.rename(columns={0: m})\n",
    "    #display(transpose_df)\n",
    "    transpose_df = transpose_df.reset_index()\n",
    "    transpose_df.rename(columns={transpose_df.columns[0]: 'MyModel'}, inplace=True)\n",
    "\n",
    "    df_list.append(transpose_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_1 = pd.concat([df_list[0]] , axis=1)\n",
    "result_df_2 = pd.concat([df_list[1]] , axis=1)\n",
    "result_df_3 = pd.concat([df_list[2]] , axis=1)\n",
    "result_df_4 = pd.concat([df_list[3]] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(file_name) as writer:\n",
    "    result_df_1.to_excel(writer, sheet_name=\"Best Response 3\", index=False)\n",
    "    result_df_2.to_excel(writer, sheet_name=\"Adeno vs Squamous\", index=False)\n",
    "    result_df_3.to_excel(writer, sheet_name=\"PDL1 3 classes\", index=False)\n",
    "    result_df_4.to_excel(writer, sheet_name=\"PDL1 2 classes\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = pd.read_csv(f\"{working_directory}/projects/I3lung-sqadqc-project/annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = working_directory+\"/data_config.json\"\n",
    "\n",
    "import json\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)  # Load JSON data into a Python dictionary or list\n",
    "\n",
    "print(data)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(data[\"labels\"].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anyio import value\n",
    "from pandas import value_counts\n",
    "\n",
    "id_list_list = []\n",
    "\n",
    "for i,l in zip(df_test_list, labels):\n",
    "    df_joined = pd.merge(i, csv_df, on ='slide', how = 'left')\n",
    "    selected_df = df_joined[[\"slide\", l]]\n",
    "    value_counts = selected_df[l].value_counts()\n",
    "    df_counts = value_counts.to_frame(name=\"Count\")\n",
    "    df_counts[\"Percentage (%)\"] = (df_counts[\"Count\"] / df_counts[\"Count\"].sum()) * 100\n",
    "\n",
    "    #display(selected_df)\n",
    "    print(selected_df[l].value_counts())\n",
    "    display(df_counts)\n",
    "\n",
    "        # Convertire la colonna \"ID\" in una lista\n",
    "    id_list = df_joined[\"slide\"].tolist()\n",
    "    id_list = [i+\".pt\" for i in id_list]\n",
    "\n",
    "    # Mostrare la lista risultante\n",
    "    id_list_list.append(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiungere \".pt\" a tutte le stringhe nella colonna \"ID\"\n",
    "#df_joined[\"slide\"] = df_joined[\"slide\"] + \".pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_list_list = []\n",
    "folder_path = \"/media/mmd/Extreme SSD/work/bags/uni/full-qc/10x reinhard_fast\"\n",
    "for list_dir in id_list_list:\n",
    "    shape_list = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "\n",
    "        if filename in list_dir:\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Load the PyTorch object\n",
    "            data = torch.load(file_path)\n",
    "            \n",
    "            # If each .pt file stores a *single* tensor, print its shape\n",
    "            if hasattr(data, 'shape'):\n",
    "                #print(f\"{filename} => shape: {tuple(data.shape)}\")\n",
    "                shape_list.append(data.shape[0])\n",
    "            #else:\n",
    "                # If data isn't a single tensor, just show what was loaded\n",
    "                #print(f\"{filename} => not a single tensor (type: {type(data)})\")\n",
    "    print(len(shape_list))\n",
    "    shape_list_list.append(shape_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = shape_list_list[0]\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "n, bins, patches = plt.hist(values, bins=10)  # You can adjust 'bins' to change how many bars appear\n",
    "\n",
    "#plt.xticks(bins)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.size'] = 16\n",
    "\n",
    "# Annotate each bar with its count\n",
    "for i, patch in enumerate(patches):\n",
    "    # Find the center of each bin\n",
    "    bin_center = (bins[i] + bins[i+1]) / 2\n",
    "    \n",
    "    # Label just above the top of each bar\n",
    "    plt.text(bin_center, n[i], int(n[i]), \n",
    "             ha='center', va='bottom', )#fontsize=12)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "# Add axis labels and a title\n",
    "plt.xlabel(\"$N_i$\", fontsize=24)\n",
    "plt.ylabel(\"Frequency\", fontsize = 24)\n",
    "#plt.title(\"Histogram of Values\")\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig(\"histogram_tiles.png\", transparent=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
