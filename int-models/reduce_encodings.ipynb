{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import platform\n",
    "device_name = platform.node()\n",
    "\n",
    "previous_folder = os.getcwd()\n",
    "print (\"This is the working folder: \" + previous_folder)\n",
    "\n",
    "if device_name == 'mmd-MS-7D98': \n",
    "    #This passage is done because everytime I log into the remote server the default folder is:\n",
    "    #/mmd/home and I need to localize the correct folder to load the settings \n",
    "    os.chdir(\"/media/mmd/Samsung_T5/GitHub/UMD\")\n",
    "\n",
    "if previous_folder != os.getcwd(): # This is now the right working folder\n",
    "    print(\"The current working folder has been changed, now the working folder is: \" + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_library.pr_creation import *\n",
    "from my_library.CPTAC import *\n",
    "from my_library.config import *\n",
    "from my_library.abmil_config import *\n",
    "from my_library.create_random import *\n",
    "\n",
    "\n",
    "import slideflow as sf\n",
    "#%run \"config.py\"\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from my_library.config import *\n",
    "from my_library.pr_creation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_uni = \"/media/mmd/Extreme SSD/work/bags/uni/full-qc/10x reinhard_fast\"\n",
    "target_folder = working_directory + \"/reduced_bags\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/media/mmd/Extreme SSD/work/bags/uni/full-qc/10x reinhard_fast\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.pt'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Load the PyTorch object\n",
    "        data = torch.load(file_path)\n",
    "        \n",
    "        # If each .pt file stores a *single* tensor, print its shape\n",
    "        if hasattr(data, 'shape'):\n",
    "            print(f\"{filename} => shape: {tuple(data.shape)}\")\n",
    "        else:\n",
    "            # If data isn't a single tensor, just show what was loaded\n",
    "            print(f\"{filename} => not a single tensor (type: {type(data)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "def sample_and_save_pt_files(src_folder, dst_folder, sample_size=50, seed=None):\n",
    "    \"\"\"\n",
    "    Loads each `.pt` file in `src_folder`, randomly samples `sample_size` \n",
    "    items along the first dimension if enough rows exist, and saves to `dst_folder`.\n",
    "    \n",
    "    Args:\n",
    "        src_folder (str): Path to the folder containing the .pt files.\n",
    "        dst_folder (str): Path to the folder where the sampled tensors should be saved.\n",
    "        sample_size (int): Number of random rows to sample from the first dimension.\n",
    "        seed (int, optional): Random seed for reproducibility (e.g., 42). If None, no seed is set.\n",
    "    \"\"\"\n",
    "    # Optionally set random seed\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    # Create destination folder if it does not exist\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "    \n",
    "    # Iterate through .pt files in the source folder\n",
    "    for filename in os.listdir(src_folder):\n",
    "        if filename.endswith(\".pt\"):\n",
    "            src_path = os.path.join(src_folder, filename)\n",
    "            data = torch.load(src_path)\n",
    "            \n",
    "            # We assume each file is a single torch.Tensor\n",
    "            if isinstance(data, torch.Tensor):\n",
    "                # Check that data has enough rows\n",
    "                if data.shape[0] >= sample_size:\n",
    "                    # Randomly permute indices and pick the first `sample_size`\n",
    "                    idx = torch.randperm(data.shape[0])[:sample_size]\n",
    "                    subset_data = data[idx]\n",
    "                    \n",
    "                    # Save the subset to the destination folder\n",
    "                    dst_path = os.path.join(dst_folder, filename)\n",
    "                    torch.save(subset_data, dst_path)\n",
    "                    \n",
    "                    print(f\"Saved {filename} with shape {subset_data.shape} to {dst_path}\")\n",
    "                else:\n",
    "                    print(f\"Skipped {filename}: first dimension {data.shape[0]} < {sample_size}\")\n",
    "                    dst_path = os.path.join(dst_folder, filename)\n",
    "                    torch.save(data, dst_path)\n",
    "\n",
    "            else:\n",
    "                print(f\"Skipped {filename}: not a single torch.Tensor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_and_save_pt_files(dir_uni, target_folder, sample_size=50, seed=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
