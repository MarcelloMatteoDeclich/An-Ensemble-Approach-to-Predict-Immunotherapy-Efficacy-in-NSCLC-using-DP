{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"my_library\")\n",
    "from my_library.config import *\n",
    "from my_library.metrics.cmp_metrics import *\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "import os\n",
    "\n",
    "#%run -i visualization/compute_metrics_single_run.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_df = pd.read_csv(working_directory+\"/projects/I3lung-sqadqc-project/annotations.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Install requirements if needed:\n",
    "# pip install pyarrow\n",
    "\n",
    "# Read the Parquet file\n",
    "path = working_directory+\"/eval/train/pdl1-3/inner_iteration_1/00000-attention_mil\"\n",
    "df_predictions = pd.read_parquet(path + \"/predictions.parquet\")\n",
    "\n",
    "# Explore the data\n",
    "print(df_predictions.head())\n",
    "print(df_predictions.info())\n",
    "\n",
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = pd.merge(df_predictions, csv_df, on ='slide', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Distribution of values in 'category'\n",
    "distribution = df_joined[\"PDL1_CATHEGORY\"].value_counts()\n",
    "print(distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_dir = \"../eval/train/pdl1-3\"\n",
    "\n",
    "train_parquet_paths = []\n",
    "val_parquet_paths = []\n",
    "test_parquet_paths = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    # Check if the folder name contains \"attention\"\n",
    "    if \"attention\" in os.path.basename(dirpath).lower():\n",
    "\n",
    "        # If you want to do something with each file inside those folders\n",
    "        for f in filenames:\n",
    "            file_path = os.path.join(dirpath, f)\n",
    "            if f.lower().endswith(\".parquet\"):\n",
    "                #print(f\"   This is a Parquet file: {file_path}\")\n",
    "                train_parquet_paths.append(file_path)\n",
    "train_parquet_paths.sort()\n",
    "\n",
    "#print(\"Sorted Parquet paths:\")\n",
    "#for path in train_parquet_paths:\n",
    "#    print(path)\n",
    "\n",
    "root_dir = \"../eval/val/pdl1-3\"\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    # Check if the folder name contains \"attention\"\n",
    "    if \"attention\" in os.path.basename(dirpath).lower():\n",
    "\n",
    "        # If you want to do something with each file inside those folders\n",
    "        for f in filenames:\n",
    "            file_path = os.path.join(dirpath, f)\n",
    "            if f.lower().endswith(\".parquet\"):\n",
    "                #print(f\"   This is a Parquet file: {file_path}\")\n",
    "                val_parquet_paths.append(file_path)\n",
    "val_parquet_paths.sort()\n",
    "\n",
    "\n",
    "root_dir = \"../eval/test-int/pdl1-3\"\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    # Check if the folder name contains \"attention\"\n",
    "    if \"attention\" in os.path.basename(dirpath).lower():\n",
    "\n",
    "        # If you want to do something with each file inside those folders\n",
    "        for f in filenames:\n",
    "            file_path = os.path.join(dirpath, f)\n",
    "            if f.lower().endswith(\".parquet\"):\n",
    "                #print(f\"   This is a Parquet file: {file_path}\")\n",
    "                test_parquet_paths.append(file_path)\n",
    "test_parquet_paths.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_parquet_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_parquet_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the names of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = []\n",
    "numbers = []\n",
    "desired_order = [\"< 1 %\", \"1-49 %\", \">=50 %\"]\n",
    "\n",
    "train_models = []\n",
    "train_classification_reports = []\n",
    "for i in train_parquet_paths:\n",
    "    df_predictions = pd.read_parquet(i)\n",
    "    df_joined = pd.merge(df_predictions, csv_df, on ='slide', how = 'left')\n",
    "    #print(df_joined)\n",
    "    distribution = df_joined[[\"slide\", \"PDL1_CATHEGORY\"]]\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    x_list = np.ones((distribution.shape[0], 1))\n",
    "    y_list = df_joined[\"PDL1_CATHEGORY\"].to_numpy()\n",
    "\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy_clf.fit(x_list, y_list)\n",
    "\n",
    "    y_pred = dummy_clf.predict(x_list)\n",
    "\n",
    "    train_models.append(dummy_clf)\n",
    "\n",
    "    # Accuratezza generale\n",
    "    acc = accuracy_score(y_list, y_pred)\n",
    "    #print(acc)\n",
    "\n",
    "    # Report dettagliato per classe\n",
    "    report = classification_report(y_list, y_pred, digits=2, output_dict=True, zero_division=0)\n",
    "\n",
    "    #print(report)\n",
    "\n",
    "    train_classification_reports.append(report)\n",
    "\n",
    "#df_train = pd.DataFrame(metrics_list, numbers)\n",
    "#display(distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classification_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming your list of dictionaries is stored in the variable `reports`\n",
    "reports = train_classification_reports  # your list of dictionaries\n",
    "\n",
    "def average_report_group(group):\n",
    "    \"\"\"Average a group of report dictionaries.\"\"\"\n",
    "    avg_report = {}\n",
    "    # Loop over each key in the first dictionary of the group.\n",
    "    for key in group[0]:\n",
    "        if key == 'accuracy':\n",
    "            # Average the accuracy values directly.\n",
    "            avg_report[key] = np.mean([r[key] for r in group])\n",
    "        else:\n",
    "            # For keys that are nested dictionaries, average each inner metric.\n",
    "            inner_keys = group[0][key].keys()\n",
    "            avg_inner = {}\n",
    "            for metric in inner_keys:\n",
    "                avg_inner[metric] = np.mean([r[key][metric] for r in group])\n",
    "            avg_report[key] = avg_inner\n",
    "    return avg_report\n",
    "\n",
    "group_size = 5\n",
    "averaged_reports = []\n",
    "\n",
    "# Process the reports list in chunks of 5.\n",
    "for i in range(0, len(reports), group_size):\n",
    "    group = reports[i:i + group_size]\n",
    "    avg = average_report_group(group)\n",
    "    averaged_reports.append(avg)\n",
    "\n",
    "# Now `averaged_reports` contains the averaged dictionary for each group of 5 items.\n",
    "print(averaged_reports)\n",
    "\n",
    "df_averaged_pred = pd.DataFrame(averaged_reports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = []\n",
    "numbers = []\n",
    "desired_order = [\"< 1 %\", \"1-49 %\", \">=50 %\"]\n",
    "\n",
    "val_models = []\n",
    "val_classification_reports = []\n",
    "for i in val_parquet_paths:\n",
    "    df_predictions = pd.read_parquet(i)\n",
    "    df_joined = pd.merge(df_predictions, csv_df, on ='slide', how = 'left')\n",
    "    #print(df_joined)\n",
    "    distribution = df_joined[[\"slide\", \"PDL1_CATHEGORY\"]]\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    x_list = np.ones((distribution.shape[0], 1))\n",
    "    y_list = df_joined[\"PDL1_CATHEGORY\"].to_numpy()\n",
    "\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy_clf.fit(x_list, y_list)\n",
    "\n",
    "    y_pred = dummy_clf.predict(x_list)\n",
    "\n",
    "    val_models.append(dummy_clf)\n",
    "\n",
    "    # Accuratezza generale\n",
    "    acc = accuracy_score(y_list, y_pred)\n",
    "    print(acc)\n",
    "\n",
    "    # Report dettagliato per classe\n",
    "    report = classification_report(y_list, y_pred, digits=2, output_dict=True, zero_division=0)\n",
    "\n",
    "    print(report)\n",
    "\n",
    "    val_classification_reports.append(report)\n",
    "\n",
    "#df_train = pd.DataFrame(metrics_list, numbers)\n",
    "#display(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = []\n",
    "numbers = []\n",
    "desired_order = [\"< 1 %\", \"1-49 %\", \">=50 %\"]\n",
    "\n",
    "test_scores = []\n",
    "\n",
    "for i, path in enumerate(test_parquet_paths):\n",
    "    df_predictions = pd.read_parquet(path)\n",
    "    dummy_clf = train_models[i]\n",
    "    df_joined = pd.merge(df_predictions, csv_df, on ='slide', how = 'left')\n",
    "    #print(df_joined)\n",
    "    distribution = df_joined[[\"slide\",\"PDL1_CATHEGORY\"]]\n",
    "\n",
    "    y_true = df_joined[\"PDL1_CATHEGORY\"].to_numpy()\n",
    "    x_list = np.ones((distribution.shape[0], 1))\n",
    "\n",
    "    #print(distribution)\n",
    "\n",
    "    y_pred = dummy_clf.predict(x_list)\n",
    "\n",
    "    #val_models.append(dummy_clf)\n",
    "\n",
    "    # Accuratezza generale\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    #print(acc)\n",
    "\n",
    "    # Report dettagliato per classe\n",
    "    report = classification_report(y_true, y_pred, digits=2, output_dict=True, zero_division=0)\n",
    "    test_scores.append(report)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Your list of dictionaries (only a few items are shown for brevity; include all in your actual code)\n",
    "report = train_classification_reports\n",
    "\n",
    "def average_report_group_with_print(group, group_index):\n",
    "    print(f\"\\nProcessing group {group_index} (with {len(group)} items):\")\n",
    "    group_stats = {}\n",
    "    for key in group[0]:\n",
    "        if key == 'accuracy':\n",
    "            values = [r[key] for r in group]\n",
    "            avg_val = np.mean(values)\n",
    "            print(f\"  {key}: values = {values}, average = {avg_val:.4f}\")\n",
    "            group_stats[f\"{key}_avg\"] = avg_val\n",
    "        else:\n",
    "            # For nested dictionary keys (like '1-49 %', '< 1 %', etc.)\n",
    "            for subkey in group[0][key]:\n",
    "                values = [r[key][subkey] for r in group]\n",
    "                avg_val = np.mean(values)\n",
    "                print(f\"  {key} -> {subkey}: values = {values}, average = {avg_val:.4f}\")\n",
    "                flat_key = f\"{key}_{subkey}\"\n",
    "                group_stats[f\"{flat_key}_avg\"] = avg_val\n",
    "    return group_stats\n",
    "\n",
    "group_size = 5\n",
    "averaged_stats = []\n",
    "\n",
    "for i in range(0, len(reports), group_size):\n",
    "    group = reports[i:i+group_size]\n",
    "    group_index = i // group_size\n",
    "    group_stats = average_report_group_with_print(group, group_index)\n",
    "    averaged_stats.append(group_stats)\n",
    "\n",
    "# Create a DataFrame from the averaged statistics.\n",
    "df_train = pd.DataFrame(averaged_stats)\n",
    "\n",
    "print(\"\\nFinal DataFrame with averaged values:\")\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Your list of dictionaries (only a few items are shown for brevity; include all in your actual code)\n",
    "report = val_classification_reports\n",
    "\n",
    "def average_report_group_with_print(group, group_index):\n",
    "    print(f\"\\nProcessing group {group_index} (with {len(group)} items):\")\n",
    "    group_stats = {}\n",
    "    for key in group[0]:\n",
    "        if key == 'accuracy':\n",
    "            values = [r[key] for r in group]\n",
    "            avg_val = np.mean(values)\n",
    "            print(f\"  {key}: values = {values}, average = {avg_val:.4f}\")\n",
    "            group_stats[f\"{key}_avg\"] = avg_val\n",
    "        else:\n",
    "            # For nested dictionary keys (like '1-49 %', '< 1 %', etc.)\n",
    "            for subkey in group[0][key]:\n",
    "                values = [r[key][subkey] for r in group]\n",
    "                avg_val = np.mean(values)\n",
    "                print(f\"  {key} -> {subkey}: values = {values}, average = {avg_val:.4f}\")\n",
    "                flat_key = f\"{key}_{subkey}\"\n",
    "                group_stats[f\"{flat_key}_avg\"] = avg_val\n",
    "    return group_stats\n",
    "\n",
    "group_size = 5\n",
    "averaged_stats = []\n",
    "\n",
    "for i in range(0, len(reports), group_size):\n",
    "    group = reports[i:i+group_size]\n",
    "    group_index = i // group_size\n",
    "    group_stats = average_report_group_with_print(group, group_index)\n",
    "    averaged_stats.append(group_stats)\n",
    "\n",
    "# Create a DataFrame from the averaged statistics.\n",
    "df_val = pd.DataFrame(averaged_stats)\n",
    "\n",
    "print(\"\\nFinal DataFrame with averaged values:\")\n",
    "print(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Your list of dictionaries (only a few items are shown for brevity; include all in your actual code)\n",
    "report = test_scores\n",
    "\n",
    "def average_report_group_with_print(group, group_index):\n",
    "    print(f\"\\nProcessing group {group_index} (with {len(group)} items):\")\n",
    "    group_stats = {}\n",
    "    for key in group[0]:\n",
    "        if key == 'accuracy':\n",
    "            values = [r[key] for r in group]\n",
    "            avg_val = np.mean(values)\n",
    "            print(f\"  {key}: values = {values}, average = {avg_val:.4f}\")\n",
    "            group_stats[f\"{key}_avg\"] = avg_val\n",
    "        else:\n",
    "            # For nested dictionary keys (like '1-49 %', '< 1 %', etc.)\n",
    "            for subkey in group[0][key]:\n",
    "                values = [r[key][subkey] for r in group]\n",
    "                avg_val = np.mean(values)\n",
    "                print(f\"  {key} -> {subkey}: values = {values}, average = {avg_val:.4f}\")\n",
    "                flat_key = f\"{key}_{subkey}\"\n",
    "                group_stats[f\"{flat_key}_avg\"] = avg_val\n",
    "    return group_stats\n",
    "\n",
    "group_size = 5\n",
    "averaged_stats = []\n",
    "\n",
    "for i in range(0, len(reports), group_size):\n",
    "    group = reports[i:i+group_size]\n",
    "    group_index = i // group_size\n",
    "    group_stats = average_report_group_with_print(group, group_index)\n",
    "    averaged_stats.append(group_stats)\n",
    "\n",
    "# Create a DataFrame from the averaged statistics.\n",
    "df_test = pd.DataFrame(averaged_stats)\n",
    "\n",
    "print(\"\\nFinal DataFrame with averaged values:\")\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.reset_index()\n",
    "df_val=df_val.reset_index()\n",
    "df_test=df_test.reset_index()\n",
    "'''\n",
    "df_train.columns = [\"Total number of patients\", \"< 1 %\", \"1-49 %\", \">=50 %\"]\n",
    "df_val .columns = [\"Total number of patients\", \"< 1 %\", \"1-49 %\", \">=50 %\"]\n",
    "df_test.columns = [\"Total number of patients\", \"< 1 %\", \"1-49 %\", \">=50 %\"]\n",
    "'''\n",
    "\n",
    "\n",
    "df_train_prefixed = df_train.add_suffix(\"_train\")\n",
    "df_val_prefixed   = df_val.add_suffix(\"_val\")\n",
    "df_test_prefixed  = df_test.add_suffix(\"_test\")\n",
    "\n",
    "df_final = pd.concat([df_train_prefixed, df_val_prefixed, df_test_prefixed], axis=1)\n",
    "print(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Your list of dictionaries (using your provided sample; in your code include all items)\n",
    "reports = train_classification_reports\n",
    "\n",
    "# Number of items\n",
    "n = len(reports)\n",
    "print(f\"Total number of reports: {n}\\n\")\n",
    "\n",
    "# Function to compute average and CI (CI = 2*std/sqrt(n))\n",
    "def compute_avg_and_ci(values):\n",
    "    avg = np.mean(values)\n",
    "    std = np.std(values, ddof=1) if len(values) > 1 else 0.0\n",
    "    ci = 2 * std / np.sqrt(len(values)) if len(values) > 1 else 0.0\n",
    "    return avg, ci\n",
    "\n",
    "# Dictionary to hold our flattened average and CI values\n",
    "overall_stats = {}\n",
    "\n",
    "# Process each key in the first report as a template.\n",
    "for key in reports[0]:\n",
    "    if key == 'accuracy':\n",
    "        # Collect the accuracy values\n",
    "        values = [r[key] for r in reports]\n",
    "        avg, ci = compute_avg_and_ci(values)\n",
    "        print(f\"Metric '{key}':\")\n",
    "        print(f\"  Values: {values}\")\n",
    "        print(f\"  Average = {avg:.4f}, CI = {ci:.4f}\\n\")\n",
    "        overall_stats[f\"{key}_avg\"] = avg\n",
    "        overall_stats[f\"{key}_ci\"] = ci\n",
    "    else:\n",
    "        # For nested dictionary keys (like '1-49 %', '< 1 %', etc.)\n",
    "        for subkey in reports[0][key]:\n",
    "            values = [r[key][subkey] for r in reports]\n",
    "            avg, ci = compute_avg_and_ci(values)\n",
    "            print(f\"Metric '{key}' -> '{subkey}':\")\n",
    "            print(f\"  Values: {values}\")\n",
    "            print(f\"  Average = {avg:.4f}, CI = {ci:.4f}\\n\")\n",
    "            flat_key = f\"{key}_{subkey}\"\n",
    "            overall_stats[f\"{flat_key}_avg\"] = avg\n",
    "            overall_stats[f\"{flat_key}_ci\"] = ci\n",
    "\n",
    "# Create a DataFrame from the overall statistics dictionary.\n",
    "df = pd.DataFrame([overall_stats])\n",
    "print(\"Final DataFrame with overall averages and CIs:\")\n",
    "display(df)\n",
    "df.to_csv(\"pdl1-dummy-model-train.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Your list of dictionaries (using your provided sample; in your code include all items)\n",
    "reports = val_classification_reports\n",
    "\n",
    "# Number of items\n",
    "n = len(reports)\n",
    "print(f\"Total number of reports: {n}\\n\")\n",
    "\n",
    "# Function to compute average and CI (CI = 2*std/sqrt(n))\n",
    "def compute_avg_and_ci(values):\n",
    "    avg = np.mean(values)\n",
    "    std = np.std(values, ddof=1) if len(values) > 1 else 0.0\n",
    "    ci = 2 * std / np.sqrt(len(values)) if len(values) > 1 else 0.0\n",
    "    return avg, ci\n",
    "\n",
    "# Dictionary to hold our flattened average and CI values\n",
    "overall_stats = {}\n",
    "\n",
    "# Process each key in the first report as a template.\n",
    "for key in reports[0]:\n",
    "    if key == 'accuracy':\n",
    "        # Collect the accuracy values\n",
    "        values = [r[key] for r in reports]\n",
    "        avg, ci = compute_avg_and_ci(values)\n",
    "        print(f\"Metric '{key}':\")\n",
    "        print(f\"  Values: {values}\")\n",
    "        print(f\"  Average = {avg:.4f}, CI = {ci:.4f}\\n\")\n",
    "        overall_stats[f\"{key}_avg\"] = avg\n",
    "        overall_stats[f\"{key}_ci\"] = ci\n",
    "    else:\n",
    "        # For nested dictionary keys (like '1-49 %', '< 1 %', etc.)\n",
    "        for subkey in reports[0][key]:\n",
    "            values = [r[key][subkey] for r in reports]\n",
    "            avg, ci = compute_avg_and_ci(values)\n",
    "            print(f\"Metric '{key}' -> '{subkey}':\")\n",
    "            print(f\"  Values: {values}\")\n",
    "            print(f\"  Average = {avg:.4f}, CI = {ci:.4f}\\n\")\n",
    "            flat_key = f\"{key}_{subkey}\"\n",
    "            overall_stats[f\"{flat_key}_avg\"] = avg\n",
    "            overall_stats[f\"{flat_key}_ci\"] = ci\n",
    "\n",
    "# Create a DataFrame from the overall statistics dictionary.\n",
    "df = pd.DataFrame([overall_stats])\n",
    "print(\"Final DataFrame with overall averages and CIs:\")\n",
    "display(df)\n",
    "df.to_csv(\"pdl1-dummy-model-val.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Your list of dictionaries (using your provided sample; in your code include all items)\n",
    "reports = test_scores\n",
    "\n",
    "# Number of items\n",
    "n = len(reports)\n",
    "print(f\"Total number of reports: {n}\\n\")\n",
    "\n",
    "# Function to compute average and CI (CI = 2*std/sqrt(n))\n",
    "def compute_avg_and_ci(values):\n",
    "    avg = np.mean(values)\n",
    "    std = np.std(values, ddof=1) if len(values) > 1 else 0.0\n",
    "    ci = 2 * std / np.sqrt(len(values)) if len(values) > 1 else 0.0\n",
    "    return avg, ci\n",
    "\n",
    "# Dictionary to hold our flattened average and CI values\n",
    "overall_stats = {}\n",
    "\n",
    "# Process each key in the first report as a template.\n",
    "for key in reports[0]:\n",
    "    if key == 'accuracy':\n",
    "        # Collect the accuracy values\n",
    "        values = [r[key] for r in reports]\n",
    "        avg, ci = compute_avg_and_ci(values)\n",
    "        print(f\"Metric '{key}':\")\n",
    "        print(f\"  Values: {values}\")\n",
    "        print(f\"  Average = {avg:.4f}, CI = {ci:.4f}\\n\")\n",
    "        overall_stats[f\"{key}_avg\"] = avg\n",
    "        overall_stats[f\"{key}_ci\"] = ci\n",
    "    else:\n",
    "        # For nested dictionary keys (like '1-49 %', '< 1 %', etc.)\n",
    "        for subkey in reports[0][key]:\n",
    "            values = [r[key][subkey] for r in reports]\n",
    "            avg, ci = compute_avg_and_ci(values)\n",
    "            print(f\"Metric '{key}' -> '{subkey}':\")\n",
    "            print(f\"  Values: {values}\")\n",
    "            print(f\"  Average = {avg:.4f}, CI = {ci:.4f}\\n\")\n",
    "            flat_key = f\"{key}_{subkey}\"\n",
    "            overall_stats[f\"{flat_key}_avg\"] = avg\n",
    "            overall_stats[f\"{flat_key}_ci\"] = ci\n",
    "\n",
    "# Create a DataFrame from the overall statistics dictionary.\n",
    "df = pd.DataFrame([overall_stats])\n",
    "print(\"Final DataFrame with overall averages and CIs:\")\n",
    "display(df)\n",
    "df.to_csv(\"pdl1-dummy-model-test.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"pdl1-dummy-model.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
