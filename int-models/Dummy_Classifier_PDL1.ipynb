{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"my_library\")\n",
    "from my_library.config import *\n",
    "from my_library.metrics.cmp_metrics import *\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "import os\n",
    "\n",
    "#%run -i visualization/compute_metrics_single_run.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_df = pd.read_csv(working_directory+\"/projects/I3lung-sqadqc-project/annotations.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                slide  y_true   y_pred0   y_pred1   y_pred2\n",
      "0  DIG_PAT_1696325261       0  0.312480  0.371465  0.316055\n",
      "1  DIG_PAT_1696325298       0  0.352431  0.364249  0.283320\n",
      "2  DIG_PAT_1696325346       0  0.311576  0.400556  0.287867\n",
      "3  DIG_PAT_1696325556       2  0.242479  0.383431  0.374089\n",
      "4  DIG_PAT_1696325661       2  0.432698  0.288610  0.278692\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175 entries, 0 to 174\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   slide    175 non-null    object \n",
      " 1   y_true   175 non-null    int64  \n",
      " 2   y_pred0  175 non-null    float32\n",
      " 3   y_pred1  175 non-null    float32\n",
      " 4   y_pred2  175 non-null    float32\n",
      "dtypes: float32(3), int64(1), object(1)\n",
      "memory usage: 4.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred0</th>\n",
       "      <th>y_pred1</th>\n",
       "      <th>y_pred2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIG_PAT_1696325261</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312480</td>\n",
       "      <td>0.371465</td>\n",
       "      <td>0.316055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIG_PAT_1696325298</td>\n",
       "      <td>0</td>\n",
       "      <td>0.352431</td>\n",
       "      <td>0.364249</td>\n",
       "      <td>0.283320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIG_PAT_1696325346</td>\n",
       "      <td>0</td>\n",
       "      <td>0.311576</td>\n",
       "      <td>0.400556</td>\n",
       "      <td>0.287867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIG_PAT_1696325556</td>\n",
       "      <td>2</td>\n",
       "      <td>0.242479</td>\n",
       "      <td>0.383431</td>\n",
       "      <td>0.374089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIG_PAT_1696325661</td>\n",
       "      <td>2</td>\n",
       "      <td>0.432698</td>\n",
       "      <td>0.288610</td>\n",
       "      <td>0.278692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>DIG_PAT_1717056235</td>\n",
       "      <td>2</td>\n",
       "      <td>0.313555</td>\n",
       "      <td>0.285962</td>\n",
       "      <td>0.400482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>DIG_PAT_1717056286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.215645</td>\n",
       "      <td>0.434842</td>\n",
       "      <td>0.349513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>DIG_PAT_1717056457</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237989</td>\n",
       "      <td>0.405770</td>\n",
       "      <td>0.356241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>DIG_PAT_1717056563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261569</td>\n",
       "      <td>0.400006</td>\n",
       "      <td>0.338425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>DIG_PAT_1717056601</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350076</td>\n",
       "      <td>0.355176</td>\n",
       "      <td>0.294748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  slide  y_true   y_pred0   y_pred1   y_pred2\n",
       "0    DIG_PAT_1696325261       0  0.312480  0.371465  0.316055\n",
       "1    DIG_PAT_1696325298       0  0.352431  0.364249  0.283320\n",
       "2    DIG_PAT_1696325346       0  0.311576  0.400556  0.287867\n",
       "3    DIG_PAT_1696325556       2  0.242479  0.383431  0.374089\n",
       "4    DIG_PAT_1696325661       2  0.432698  0.288610  0.278692\n",
       "..                  ...     ...       ...       ...       ...\n",
       "170  DIG_PAT_1717056235       2  0.313555  0.285962  0.400482\n",
       "171  DIG_PAT_1717056286       0  0.215645  0.434842  0.349513\n",
       "172  DIG_PAT_1717056457       0  0.237989  0.405770  0.356241\n",
       "173  DIG_PAT_1717056563       1  0.261569  0.400006  0.338425\n",
       "174  DIG_PAT_1717056601       0  0.350076  0.355176  0.294748\n",
       "\n",
       "[175 rows x 5 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Install requirements if needed:\n",
    "# pip install pyarrow\n",
    "\n",
    "# Read the Parquet file\n",
    "path = working_directory+\"/eval/train/pdl1-3/inner_iteration_1/00000-attention_mil\"\n",
    "df_predictions = pd.read_parquet(path + \"/predictions.parquet\")\n",
    "\n",
    "# Explore the data\n",
    "print(df_predictions.head())\n",
    "print(df_predictions.info())\n",
    "\n",
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide</th>\n",
       "      <th>EXT</th>\n",
       "      <th>FULL_PATH</th>\n",
       "      <th>CENTER</th>\n",
       "      <th>patient</th>\n",
       "      <th>FULL_I3LUNG_NAME</th>\n",
       "      <th>NUM_SLIDES</th>\n",
       "      <th>STUDY_TYPE</th>\n",
       "      <th>SLIDE_TYPE</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>...</th>\n",
       "      <th>SITE_METS_IO_START</th>\n",
       "      <th>IO_START</th>\n",
       "      <th>IO_END</th>\n",
       "      <th>PROGRESSION_DATE</th>\n",
       "      <th>Z03_DATE</th>\n",
       "      <th>DEATH_EVENT_OC</th>\n",
       "      <th>PROGRESSION_EVENT_OC</th>\n",
       "      <th>THERAPY_END_EVENT_OC</th>\n",
       "      <th>I30_KRAS</th>\n",
       "      <th>I55_P53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIG_PAT_1696327666</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1696327666.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010133</td>\n",
       "      <td>INT1010133.svs</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrospective</td>\n",
       "      <td>h/e</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>lung,lymph nodes,bone</td>\n",
       "      <td>2022-07-04</td>\n",
       "      <td>2023-01-27</td>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>2023-04-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIG_PAT_1696327717</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1696327717.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010140</td>\n",
       "      <td>INT1010140.svs</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrospective</td>\n",
       "      <td>h/e</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-08-09</td>\n",
       "      <td>2023-07-14</td>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIG_PAT_1696325152</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1696325152.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010001</td>\n",
       "      <td>INT1010001.svs</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrospective</td>\n",
       "      <td>h/e</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>bone</td>\n",
       "      <td>2021-06-14</td>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIG_PAT_1696325185</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1696325185.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010002</td>\n",
       "      <td>INT1010002.svs</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrospective</td>\n",
       "      <td>h/e</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>lung</td>\n",
       "      <td>2021-07-21</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIG_PAT_1696325261</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1696325261.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010003</td>\n",
       "      <td>INT1010003.svs</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrospective</td>\n",
       "      <td>h/e</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>DIG_PAT_1728839427</td>\n",
       "      <td>tif</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1728839427.tif</td>\n",
       "      <td>MH</td>\n",
       "      <td>MH1040002</td>\n",
       "      <td>MH1040002_HE (2).tif</td>\n",
       "      <td>1</td>\n",
       "      <td>Prospective</td>\n",
       "      <td>h/e</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>DIG_PAT_1728843584</td>\n",
       "      <td>tif</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1728843584.tif</td>\n",
       "      <td>MH</td>\n",
       "      <td>MH1040073</td>\n",
       "      <td>MH1040073_HE (2).tif</td>\n",
       "      <td>1</td>\n",
       "      <td>Retrospective</td>\n",
       "      <td>h/e</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>lung,lymph nodes,adrenal</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>DIG_PAT_1728854618</td>\n",
       "      <td>tif</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1728854618.tif</td>\n",
       "      <td>MH</td>\n",
       "      <td>MH1040093</td>\n",
       "      <td>MH1040093_HE.tif</td>\n",
       "      <td>1</td>\n",
       "      <td>Prospective</td>\n",
       "      <td>h/e</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>DIG_PAT_1728911989</td>\n",
       "      <td>tif</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1728911989.tif</td>\n",
       "      <td>MH</td>\n",
       "      <td>MH1040120</td>\n",
       "      <td>MH1040120_HE (1).tif</td>\n",
       "      <td>1</td>\n",
       "      <td>Prospective</td>\n",
       "      <td>h/e</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>DIG_PAT_1728915991</td>\n",
       "      <td>tif</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1728915991.tif</td>\n",
       "      <td>MH</td>\n",
       "      <td>MH1040287</td>\n",
       "      <td>MH1040287_HE (A1).tif</td>\n",
       "      <td>1</td>\n",
       "      <td>Prospective</td>\n",
       "      <td>h/e</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1042 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   slide  EXT                               FULL_PATH CENTER  \\\n",
       "0     DIG_PAT_1696327666  svs  D:/Digital_path/DIG_PAT_1696327666.svs    INT   \n",
       "1     DIG_PAT_1696327717  svs  D:/Digital_path/DIG_PAT_1696327717.svs    INT   \n",
       "2     DIG_PAT_1696325152  svs  D:/Digital_path/DIG_PAT_1696325152.svs    INT   \n",
       "3     DIG_PAT_1696325185  svs  D:/Digital_path/DIG_PAT_1696325185.svs    INT   \n",
       "4     DIG_PAT_1696325261  svs  D:/Digital_path/DIG_PAT_1696325261.svs    INT   \n",
       "...                  ...  ...                                     ...    ...   \n",
       "1037  DIG_PAT_1728839427  tif  D:/Digital_path/DIG_PAT_1728839427.tif     MH   \n",
       "1038  DIG_PAT_1728843584  tif  D:/Digital_path/DIG_PAT_1728843584.tif     MH   \n",
       "1039  DIG_PAT_1728854618  tif  D:/Digital_path/DIG_PAT_1728854618.tif     MH   \n",
       "1040  DIG_PAT_1728911989  tif  D:/Digital_path/DIG_PAT_1728911989.tif     MH   \n",
       "1041  DIG_PAT_1728915991  tif  D:/Digital_path/DIG_PAT_1728915991.tif     MH   \n",
       "\n",
       "         patient       FULL_I3LUNG_NAME  NUM_SLIDES     STUDY_TYPE SLIDE_TYPE  \\\n",
       "0     INT1010133         INT1010133.svs           1  Retrospective        h/e   \n",
       "1     INT1010140         INT1010140.svs           1  Retrospective        h/e   \n",
       "2     INT1010001         INT1010001.svs           1  Retrospective        h/e   \n",
       "3     INT1010002         INT1010002.svs           1  Retrospective        h/e   \n",
       "4     INT1010003         INT1010003.svs           1  Retrospective        h/e   \n",
       "...          ...                    ...         ...            ...        ...   \n",
       "1037   MH1040002   MH1040002_HE (2).tif           1    Prospective        h/e   \n",
       "1038   MH1040073   MH1040073_HE (2).tif           1  Retrospective        h/e   \n",
       "1039   MH1040093       MH1040093_HE.tif           1    Prospective        h/e   \n",
       "1040   MH1040120   MH1040120_HE (1).tif           1    Prospective        h/e   \n",
       "1041   MH1040287  MH1040287_HE (A1).tif           1    Prospective        h/e   \n",
       "\n",
       "      COHORT  ...        SITE_METS_IO_START    IO_START      IO_END  \\\n",
       "0          2  ...     lung,lymph nodes,bone  2022-07-04  2023-01-27   \n",
       "1          1  ...                       NaN  2022-08-09  2023-07-14   \n",
       "2          2  ...                      bone  2021-06-14  2023-09-08   \n",
       "3          3  ...                      lung  2021-07-21  2023-08-17   \n",
       "4          1  ...                       NaN  2022-07-13  2023-06-06   \n",
       "...      ...  ...                       ...         ...         ...   \n",
       "1037       0  ...                       NaN         NaN         NaN   \n",
       "1038       3  ...  lung,lymph nodes,adrenal  2020-01-22  2021-03-22   \n",
       "1039       0  ...                       NaN         NaN         NaN   \n",
       "1040       0  ...                       NaN         NaN         NaN   \n",
       "1041       0  ...                       NaN         NaN         NaN   \n",
       "\n",
       "     PROGRESSION_DATE    Z03_DATE  DEATH_EVENT_OC  PROGRESSION_EVENT_OC  \\\n",
       "0          2023-02-13  2023-04-13             1.0                   1.0   \n",
       "1          2024-10-09  2024-10-09             0.0                   0.0   \n",
       "2          2023-09-08  2023-09-08             0.0                   0.0   \n",
       "3          2023-08-17  2023-08-17             0.0                   0.0   \n",
       "4          2024-10-02  2024-10-02             0.0                   0.0   \n",
       "...               ...         ...             ...                   ...   \n",
       "1037              NaN         NaN             NaN                   NaN   \n",
       "1038       2021-08-16  2023-01-25             0.0                   1.0   \n",
       "1039              NaN         NaN             NaN                   NaN   \n",
       "1040              NaN         NaN             NaN                   NaN   \n",
       "1041              NaN         NaN             NaN                   NaN   \n",
       "\n",
       "      THERAPY_END_EVENT_OC I30_KRAS I55_P53  \n",
       "0                      1.0      0.0     1.0  \n",
       "1                      1.0      NaN     NaN  \n",
       "2                      0.0      1.0     NaN  \n",
       "3                      0.0      NaN     NaN  \n",
       "4                      1.0      NaN     NaN  \n",
       "...                    ...      ...     ...  \n",
       "1037                   NaN      NaN     NaN  \n",
       "1038                   1.0      0.0     0.0  \n",
       "1039                   NaN      NaN     NaN  \n",
       "1040                   NaN      NaN     NaN  \n",
       "1041                   NaN      NaN     NaN  \n",
       "\n",
       "[1042 rows x 28 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = pd.merge(df_predictions, csv_df, on ='slide', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred0</th>\n",
       "      <th>y_pred1</th>\n",
       "      <th>y_pred2</th>\n",
       "      <th>EXT</th>\n",
       "      <th>FULL_PATH</th>\n",
       "      <th>CENTER</th>\n",
       "      <th>patient</th>\n",
       "      <th>FULL_I3LUNG_NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>SITE_METS_IO_START</th>\n",
       "      <th>IO_START</th>\n",
       "      <th>IO_END</th>\n",
       "      <th>PROGRESSION_DATE</th>\n",
       "      <th>Z03_DATE</th>\n",
       "      <th>DEATH_EVENT_OC</th>\n",
       "      <th>PROGRESSION_EVENT_OC</th>\n",
       "      <th>THERAPY_END_EVENT_OC</th>\n",
       "      <th>I30_KRAS</th>\n",
       "      <th>I55_P53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIG_PAT_1696325261</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312480</td>\n",
       "      <td>0.371465</td>\n",
       "      <td>0.316055</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1696325261.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010003</td>\n",
       "      <td>INT1010003.svs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIG_PAT_1696325298</td>\n",
       "      <td>0</td>\n",
       "      <td>0.352431</td>\n",
       "      <td>0.364249</td>\n",
       "      <td>0.283320</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1696325298.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010005</td>\n",
       "      <td>INT1010005.svs</td>\n",
       "      <td>...</td>\n",
       "      <td>lymph nodes,soft tissue,adrenal</td>\n",
       "      <td>2022-07-26</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIG_PAT_1696325346</td>\n",
       "      <td>0</td>\n",
       "      <td>0.311576</td>\n",
       "      <td>0.400556</td>\n",
       "      <td>0.287867</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1696325346.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010007</td>\n",
       "      <td>INT1010007.svs</td>\n",
       "      <td>...</td>\n",
       "      <td>bone</td>\n",
       "      <td>2022-08-16</td>\n",
       "      <td>2022-11-03</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIG_PAT_1696325556</td>\n",
       "      <td>2</td>\n",
       "      <td>0.242479</td>\n",
       "      <td>0.383431</td>\n",
       "      <td>0.374089</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1696325556.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010022</td>\n",
       "      <td>INT1010022.svs</td>\n",
       "      <td>...</td>\n",
       "      <td>pleura</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>2023-04-18</td>\n",
       "      <td>2023-04-18</td>\n",
       "      <td>2023-04-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIG_PAT_1696325661</td>\n",
       "      <td>2</td>\n",
       "      <td>0.432698</td>\n",
       "      <td>0.288610</td>\n",
       "      <td>0.278692</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1696325661.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010027</td>\n",
       "      <td>INT1010027.svs</td>\n",
       "      <td>...</td>\n",
       "      <td>bone</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>2023-10-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>DIG_PAT_1717056235</td>\n",
       "      <td>2</td>\n",
       "      <td>0.313555</td>\n",
       "      <td>0.285962</td>\n",
       "      <td>0.400482</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1717056235.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010187</td>\n",
       "      <td>INT1010187.svs</td>\n",
       "      <td>...</td>\n",
       "      <td>lung,lymph nodes,bone,pleural effusion,pericar...</td>\n",
       "      <td>2023-01-27</td>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>2023-03-17</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>DIG_PAT_1717056286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.215645</td>\n",
       "      <td>0.434842</td>\n",
       "      <td>0.349513</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1717056286.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010190</td>\n",
       "      <td>INT1010190.svs</td>\n",
       "      <td>...</td>\n",
       "      <td>lung,lymph nodes,bone</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>DIG_PAT_1717056457</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237989</td>\n",
       "      <td>0.405770</td>\n",
       "      <td>0.356241</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1717056457.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010766</td>\n",
       "      <td>INT1010766.svs</td>\n",
       "      <td>...</td>\n",
       "      <td>bone,lymph nodes</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>2023-09-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>DIG_PAT_1717056563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261569</td>\n",
       "      <td>0.400006</td>\n",
       "      <td>0.338425</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1717056563.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010800</td>\n",
       "      <td>INT1010800.svs</td>\n",
       "      <td>...</td>\n",
       "      <td>lung,lymph nodes</td>\n",
       "      <td>2022-11-05</td>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>2023-06-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>DIG_PAT_1717056601</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350076</td>\n",
       "      <td>0.355176</td>\n",
       "      <td>0.294748</td>\n",
       "      <td>svs</td>\n",
       "      <td>D:/Digital_path/DIG_PAT_1717056601.svs</td>\n",
       "      <td>INT</td>\n",
       "      <td>INT1010816</td>\n",
       "      <td>INT1010816.svs</td>\n",
       "      <td>...</td>\n",
       "      <td>lung,lymph nodes,liver,bone</td>\n",
       "      <td>2022-08-23</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>2023-03-03</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  slide  y_true   y_pred0   y_pred1   y_pred2  EXT  \\\n",
       "0    DIG_PAT_1696325261       0  0.312480  0.371465  0.316055  svs   \n",
       "1    DIG_PAT_1696325298       0  0.352431  0.364249  0.283320  svs   \n",
       "2    DIG_PAT_1696325346       0  0.311576  0.400556  0.287867  svs   \n",
       "3    DIG_PAT_1696325556       2  0.242479  0.383431  0.374089  svs   \n",
       "4    DIG_PAT_1696325661       2  0.432698  0.288610  0.278692  svs   \n",
       "..                  ...     ...       ...       ...       ...  ...   \n",
       "170  DIG_PAT_1717056235       2  0.313555  0.285962  0.400482  svs   \n",
       "171  DIG_PAT_1717056286       0  0.215645  0.434842  0.349513  svs   \n",
       "172  DIG_PAT_1717056457       0  0.237989  0.405770  0.356241  svs   \n",
       "173  DIG_PAT_1717056563       1  0.261569  0.400006  0.338425  svs   \n",
       "174  DIG_PAT_1717056601       0  0.350076  0.355176  0.294748  svs   \n",
       "\n",
       "                                  FULL_PATH CENTER     patient  \\\n",
       "0    D:/Digital_path/DIG_PAT_1696325261.svs    INT  INT1010003   \n",
       "1    D:/Digital_path/DIG_PAT_1696325298.svs    INT  INT1010005   \n",
       "2    D:/Digital_path/DIG_PAT_1696325346.svs    INT  INT1010007   \n",
       "3    D:/Digital_path/DIG_PAT_1696325556.svs    INT  INT1010022   \n",
       "4    D:/Digital_path/DIG_PAT_1696325661.svs    INT  INT1010027   \n",
       "..                                      ...    ...         ...   \n",
       "170  D:/Digital_path/DIG_PAT_1717056235.svs    INT  INT1010187   \n",
       "171  D:/Digital_path/DIG_PAT_1717056286.svs    INT  INT1010190   \n",
       "172  D:/Digital_path/DIG_PAT_1717056457.svs    INT  INT1010766   \n",
       "173  D:/Digital_path/DIG_PAT_1717056563.svs    INT  INT1010800   \n",
       "174  D:/Digital_path/DIG_PAT_1717056601.svs    INT  INT1010816   \n",
       "\n",
       "    FULL_I3LUNG_NAME  ...                                 SITE_METS_IO_START  \\\n",
       "0     INT1010003.svs  ...                                                NaN   \n",
       "1     INT1010005.svs  ...                    lymph nodes,soft tissue,adrenal   \n",
       "2     INT1010007.svs  ...                                               bone   \n",
       "3     INT1010022.svs  ...                                             pleura   \n",
       "4     INT1010027.svs  ...                                               bone   \n",
       "..               ...  ...                                                ...   \n",
       "170   INT1010187.svs  ...  lung,lymph nodes,bone,pleural effusion,pericar...   \n",
       "171   INT1010190.svs  ...                              lung,lymph nodes,bone   \n",
       "172   INT1010766.svs  ...                                   bone,lymph nodes   \n",
       "173   INT1010800.svs  ...                                   lung,lymph nodes   \n",
       "174   INT1010816.svs  ...                        lung,lymph nodes,liver,bone   \n",
       "\n",
       "       IO_START      IO_END  PROGRESSION_DATE    Z03_DATE DEATH_EVENT_OC  \\\n",
       "0    2022-07-13  2023-06-06        2024-10-02  2024-10-02            0.0   \n",
       "1    2022-07-26  2023-08-22        2023-01-10  2023-08-22            0.0   \n",
       "2    2022-08-16  2022-11-03        2023-02-22  2023-02-22            0.0   \n",
       "3    2022-07-13  2023-04-18        2023-04-18  2023-04-18            0.0   \n",
       "4    2022-03-25  2023-03-13        2023-03-23  2023-10-22            1.0   \n",
       "..          ...         ...               ...         ...            ...   \n",
       "170  2023-01-27  2023-02-17        2023-03-17  2023-04-14            0.0   \n",
       "171  2022-04-12  2023-05-16        2023-05-16  2023-05-16            0.0   \n",
       "172  2023-04-22  2023-07-27        2023-07-27  2023-09-03            1.0   \n",
       "173  2022-11-05  2023-04-03        2023-05-17  2023-06-18            1.0   \n",
       "174  2022-08-23  2023-05-08        2023-03-03  2023-09-10            1.0   \n",
       "\n",
       "    PROGRESSION_EVENT_OC THERAPY_END_EVENT_OC  I30_KRAS  I55_P53  \n",
       "0                    0.0                  1.0       NaN      NaN  \n",
       "1                    1.0                  0.0       1.0      0.0  \n",
       "2                    0.0                  1.0       1.0      1.0  \n",
       "3                    0.0                  0.0       0.0      1.0  \n",
       "4                    1.0                  1.0       0.0      0.0  \n",
       "..                   ...                  ...       ...      ...  \n",
       "170                  1.0                  1.0       0.0      NaN  \n",
       "171                  0.0                  0.0       1.0      1.0  \n",
       "172                  1.0                  0.0       NaN      NaN  \n",
       "173                  1.0                  1.0       1.0      0.0  \n",
       "174                  1.0                  1.0       NaN      NaN  \n",
       "\n",
       "[175 rows x 32 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDL1_CATHEGORY\n",
      "< 1 %     64\n",
      "1-49 %    60\n",
      ">=50 %    51\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Distribution of values in 'category'\n",
    "distribution = df_joined[\"PDL1_CATHEGORY\"].value_counts()\n",
    "print(distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_dir = \"../eval/train/pdl1-3\"\n",
    "\n",
    "train_parquet_paths = []\n",
    "val_parquet_paths = []\n",
    "test_parquet_paths = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    # Check if the folder name contains \"attention\"\n",
    "    if \"attention\" in os.path.basename(dirpath).lower():\n",
    "\n",
    "        # If you want to do something with each file inside those folders\n",
    "        for f in filenames:\n",
    "            file_path = os.path.join(dirpath, f)\n",
    "            if f.lower().endswith(\".parquet\"):\n",
    "                #print(f\"   This is a Parquet file: {file_path}\")\n",
    "                train_parquet_paths.append(file_path)\n",
    "train_parquet_paths.sort()\n",
    "\n",
    "#print(\"Sorted Parquet paths:\")\n",
    "#for path in train_parquet_paths:\n",
    "#    print(path)\n",
    "\n",
    "root_dir = \"../eval/val/pdl1-3\"\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    # Check if the folder name contains \"attention\"\n",
    "    if \"attention\" in os.path.basename(dirpath).lower():\n",
    "\n",
    "        # If you want to do something with each file inside those folders\n",
    "        for f in filenames:\n",
    "            file_path = os.path.join(dirpath, f)\n",
    "            if f.lower().endswith(\".parquet\"):\n",
    "                #print(f\"   This is a Parquet file: {file_path}\")\n",
    "                val_parquet_paths.append(file_path)\n",
    "val_parquet_paths.sort()\n",
    "\n",
    "\n",
    "root_dir = \"../eval/test-int/pdl1-3\"\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    # Check if the folder name contains \"attention\"\n",
    "    if \"attention\" in os.path.basename(dirpath).lower():\n",
    "\n",
    "        # If you want to do something with each file inside those folders\n",
    "        for f in filenames:\n",
    "            file_path = os.path.join(dirpath, f)\n",
    "            if f.lower().endswith(\".parquet\"):\n",
    "                #print(f\"   This is a Parquet file: {file_path}\")\n",
    "                test_parquet_paths.append(file_path)\n",
    "test_parquet_paths.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../eval/val/pdl1-3/inner_iteration_1/00000-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_1/00001-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_1/00002-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_1/00003-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_1/00004-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_2/00000-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_2/00001-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_2/00002-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_2/00003-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_2/00004-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_3/00000-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_3/00001-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_3/00002-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_3/00003-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_3/00004-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_4/00000-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_4/00001-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_4/00002-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_4/00003-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_4/00004-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_5/00000-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_5/00001-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_5/00002-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_5/00003-attention_mil/predictions.parquet',\n",
       " '../eval/val/pdl1-3/inner_iteration_5/00004-attention_mil/predictions.parquet']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_parquet_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../eval/test-int/pdl1-3/inner_iteration_1/00000-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_1/00001-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_1/00002-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_1/00003-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_1/00004-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_2/00000-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_2/00001-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_2/00002-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_2/00003-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_2/00004-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_3/00000-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_3/00001-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_3/00002-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_3/00003-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_3/00004-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_4/00000-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_4/00001-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_4/00002-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_4/00003-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_4/00004-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_5/00000-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_5/00001-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_5/00002-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_5/00003-attention_mil/predictions.parquet',\n",
       " '../eval/test-int/pdl1-3/inner_iteration_5/00004-attention_mil/predictions.parquet']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parquet_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the names of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = []\n",
    "numbers = []\n",
    "desired_order = [\"< 1 %\", \"1-49 %\", \">=50 %\"]\n",
    "\n",
    "train_models = []\n",
    "train_classification_reports = []\n",
    "for i in train_parquet_paths:\n",
    "    df_predictions = pd.read_parquet(i)\n",
    "    df_joined = pd.merge(df_predictions, csv_df, on ='slide', how = 'left')\n",
    "    #print(df_joined)\n",
    "    distribution = df_joined[[\"slide\", \"PDL1_CATHEGORY\"]]\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    x_list = np.ones((distribution.shape[0], 1))\n",
    "    y_list = df_joined[\"PDL1_CATHEGORY\"].to_numpy()\n",
    "\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy_clf.fit(x_list, y_list)\n",
    "\n",
    "    y_pred = dummy_clf.predict(x_list)\n",
    "\n",
    "    train_models.append(dummy_clf)\n",
    "\n",
    "    # Accuratezza generale\n",
    "    acc = accuracy_score(y_list, y_pred)\n",
    "    #print(acc)\n",
    "\n",
    "    # Report dettagliato per classe\n",
    "    report = classification_report(y_list, y_pred, digits=2, output_dict=True, zero_division=0)\n",
    "\n",
    "    #print(report)\n",
    "\n",
    "    train_classification_reports.append(report)\n",
    "\n",
    "#df_train = pd.DataFrame(metrics_list, numbers)\n",
    "#display(distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent'),\n",
       " DummyClassifier(strategy='most_frequent')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'1-49 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 60.0},\n",
       "  '< 1 %': {'precision': 0.3657142857142857,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5355648535564853,\n",
       "   'support': 64.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 51.0},\n",
       "  'accuracy': 0.3657142857142857,\n",
       "  'macro avg': {'precision': 0.1219047619047619,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17852161785216178,\n",
       "   'support': 175.0},\n",
       "  'weighted avg': {'precision': 0.1337469387755102,\n",
       "   'recall': 0.3657142857142857,\n",
       "   'f1-score': 0.19586371787208606,\n",
       "   'support': 175.0}},\n",
       " {'1-49 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 63.0},\n",
       "  '< 1 %': {'precision': 0.3672316384180791,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5371900826446281,\n",
       "   'support': 65.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 49.0},\n",
       "  'accuracy': 0.3672316384180791,\n",
       "  'macro avg': {'precision': 0.1224105461393597,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.1790633608815427,\n",
       "   'support': 177.0},\n",
       "  'weighted avg': {'precision': 0.13485907625522678,\n",
       "   'recall': 0.3672316384180791,\n",
       "   'f1-score': 0.19727319419153008,\n",
       "   'support': 177.0}},\n",
       " {'1-49 %': {'precision': 0.36363636363636365,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5333333333333333,\n",
       "   'support': 64.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 54.0},\n",
       "  'accuracy': 0.36363636363636365,\n",
       "  'macro avg': {'precision': 0.12121212121212122,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17777777777777778,\n",
       "   'support': 176.0},\n",
       "  'weighted avg': {'precision': 0.1322314049586777,\n",
       "   'recall': 0.36363636363636365,\n",
       "   'f1-score': 0.19393939393939394,\n",
       "   'support': 176.0}},\n",
       " {'1-49 %': {'precision': 0.35260115606936415,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5213675213675214,\n",
       "   'support': 61.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 59.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 53.0},\n",
       "  'accuracy': 0.35260115606936415,\n",
       "  'macro avg': {'precision': 0.11753371868978806,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.1737891737891738,\n",
       "   'support': 173.0},\n",
       "  'weighted avg': {'precision': 0.1243275752614521,\n",
       "   'recall': 0.35260115606936415,\n",
       "   'f1-score': 0.18383479077120696,\n",
       "   'support': 173.0}},\n",
       " {'1-49 %': {'precision': 0.3742690058479532,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5446808510638298,\n",
       "   'support': 64.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 49.0},\n",
       "  'accuracy': 0.3742690058479532,\n",
       "  'macro avg': {'precision': 0.12475633528265107,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.18156028368794327,\n",
       "   'support': 171.0},\n",
       "  'weighted avg': {'precision': 0.14007728873841524,\n",
       "   'recall': 0.3742690058479532,\n",
       "   'f1-score': 0.20385716063207665,\n",
       "   'support': 171.0}},\n",
       " {'1-49 %': {'precision': 0.37142857142857144,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5416666666666666,\n",
       "   'support': 65.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 59.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 51.0},\n",
       "  'accuracy': 0.37142857142857144,\n",
       "  'macro avg': {'precision': 0.12380952380952381,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.18055555555555555,\n",
       "   'support': 175.0},\n",
       "  'weighted avg': {'precision': 0.13795918367346938,\n",
       "   'recall': 0.37142857142857144,\n",
       "   'f1-score': 0.20119047619047617,\n",
       "   'support': 175.0}},\n",
       " {'1-49 %': {'precision': 0.3532608695652174,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5220883534136547,\n",
       "   'support': 65.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 64.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 55.0},\n",
       "  'accuracy': 0.3532608695652174,\n",
       "  'macro avg': {'precision': 0.1177536231884058,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.1740294511378849,\n",
       "   'support': 184.0},\n",
       "  'weighted avg': {'precision': 0.12479324196597355,\n",
       "   'recall': 0.3532608695652174,\n",
       "   'f1-score': 0.1844333857167802,\n",
       "   'support': 184.0}},\n",
       " {'1-49 %': {'precision': 0.3567567567567568,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5258964143426295,\n",
       "   'support': 66.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 63.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 56.0},\n",
       "  'accuracy': 0.3567567567567568,\n",
       "  'macro avg': {'precision': 0.11891891891891893,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17529880478087648,\n",
       "   'support': 185.0},\n",
       "  'weighted avg': {'precision': 0.12727538349159973,\n",
       "   'recall': 0.3567567567567568,\n",
       "   'f1-score': 0.187617099170884,\n",
       "   'support': 185.0}},\n",
       " {'1-49 %': {'precision': 0.39204545454545453,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.563265306122449,\n",
       "   'support': 69.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 57.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 50.0},\n",
       "  'accuracy': 0.39204545454545453,\n",
       "  'macro avg': {'precision': 0.13068181818181818,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.18775510204081633,\n",
       "   'support': 176.0},\n",
       "  'weighted avg': {'precision': 0.15369963842975207,\n",
       "   'recall': 0.39204545454545453,\n",
       "   'f1-score': 0.2208256029684601,\n",
       "   'support': 176.0}},\n",
       " {'1-49 %': {'precision': 0.3641304347826087,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5338645418326693,\n",
       "   'support': 67.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 52.0},\n",
       "  'accuracy': 0.3641304347826087,\n",
       "  'macro avg': {'precision': 0.1213768115942029,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17795484727755642,\n",
       "   'support': 184.0},\n",
       "  'weighted avg': {'precision': 0.13259097353497165,\n",
       "   'recall': 0.3641304347826087,\n",
       "   'f1-score': 0.19439632773254803,\n",
       "   'support': 184.0}},\n",
       " {'1-49 %': {'precision': 0.3465909090909091,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5147679324894515,\n",
       "   'support': 61.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 61.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 54.0},\n",
       "  'accuracy': 0.3465909090909091,\n",
       "  'macro avg': {'precision': 0.11553030303030304,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17158931082981718,\n",
       "   'support': 176.0},\n",
       "  'weighted avg': {'precision': 0.12012525826446283,\n",
       "   'recall': 0.3465909090909091,\n",
       "   'f1-score': 0.1784138856923667,\n",
       "   'support': 176.0}},\n",
       " {'1-49 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 61.0},\n",
       "  '< 1 %': {'precision': 0.3595505617977528,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5289256198347108,\n",
       "   'support': 64.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 53.0},\n",
       "  'accuracy': 0.3595505617977528,\n",
       "  'macro avg': {'precision': 0.1198501872659176,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.1763085399449036,\n",
       "   'support': 178.0},\n",
       "  'weighted avg': {'precision': 0.12927660648907965,\n",
       "   'recall': 0.3595505617977528,\n",
       "   'f1-score': 0.19017550376079487,\n",
       "   'support': 178.0}},\n",
       " {'1-49 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 61.0},\n",
       "  '< 1 %': {'precision': 0.3651685393258427,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5349794238683128,\n",
       "   'support': 65.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 52.0},\n",
       "  'accuracy': 0.3651685393258427,\n",
       "  'macro avg': {'precision': 0.12172284644194757,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17832647462277093,\n",
       "   'support': 178.0},\n",
       "  'weighted avg': {'precision': 0.13334806211336953,\n",
       "   'recall': 0.3651685393258427,\n",
       "   'f1-score': 0.19535765478337264,\n",
       "   'support': 178.0}},\n",
       " {'1-49 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 62.0},\n",
       "  '< 1 %': {'precision': 0.35,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5185185185185185,\n",
       "   'support': 63.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 55.0},\n",
       "  'accuracy': 0.35,\n",
       "  'macro avg': {'precision': 0.11666666666666665,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.1728395061728395,\n",
       "   'support': 180.0},\n",
       "  'weighted avg': {'precision': 0.12249999999999998,\n",
       "   'recall': 0.35,\n",
       "   'f1-score': 0.18148148148148147,\n",
       "   'support': 180.0}},\n",
       " {'1-49 %': {'precision': 0.35,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5185185185185185,\n",
       "   'support': 63.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 63.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 54.0},\n",
       "  'accuracy': 0.35,\n",
       "  'macro avg': {'precision': 0.11666666666666665,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.1728395061728395,\n",
       "   'support': 180.0},\n",
       "  'weighted avg': {'precision': 0.12249999999999998,\n",
       "   'recall': 0.35,\n",
       "   'f1-score': 0.18148148148148147,\n",
       "   'support': 180.0}},\n",
       " {'1-49 %': {'precision': 0.3641304347826087,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5338645418326693,\n",
       "   'support': 67.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 52.0},\n",
       "  'accuracy': 0.3641304347826087,\n",
       "  'macro avg': {'precision': 0.1213768115942029,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17795484727755642,\n",
       "   'support': 184.0},\n",
       "  'weighted avg': {'precision': 0.13259097353497165,\n",
       "   'recall': 0.3641304347826087,\n",
       "   'f1-score': 0.19439632773254803,\n",
       "   'support': 184.0}},\n",
       " {'1-49 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 62.0},\n",
       "  '< 1 %': {'precision': 0.36813186813186816,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5381526104417671,\n",
       "   'support': 67.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 53.0},\n",
       "  'accuracy': 0.36813186813186816,\n",
       "  'macro avg': {'precision': 0.12271062271062272,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17938420348058903,\n",
       "   'support': 182.0},\n",
       "  'weighted avg': {'precision': 0.13552107233425917,\n",
       "   'recall': 0.36813186813186816,\n",
       "   'f1-score': 0.19811112582196921,\n",
       "   'support': 182.0}},\n",
       " {'1-49 %': {'precision': 0.3615819209039548,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5311203319502075,\n",
       "   'support': 64.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 61.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 52.0},\n",
       "  'accuracy': 0.3615819209039548,\n",
       "  'macro avg': {'precision': 0.12052730696798493,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17704011065006917,\n",
       "   'support': 177.0},\n",
       "  'weighted avg': {'precision': 0.13074148552459383,\n",
       "   'recall': 0.3615819209039548,\n",
       "   'f1-score': 0.19204350985770213,\n",
       "   'support': 177.0}},\n",
       " {'1-49 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 62.0},\n",
       "  '< 1 %': {'precision': 0.36312849162011174,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5327868852459017,\n",
       "   'support': 65.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 52.0},\n",
       "  'accuracy': 0.36312849162011174,\n",
       "  'macro avg': {'precision': 0.12104283054003724,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17759562841530055,\n",
       "   'support': 179.0},\n",
       "  'weighted avg': {'precision': 0.13186230142629757,\n",
       "   'recall': 0.36312849162011174,\n",
       "   'f1-score': 0.19347009799432185,\n",
       "   'support': 179.0}},\n",
       " {'1-49 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 65.0},\n",
       "  '< 1 %': {'precision': 0.3626373626373626,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.532258064516129,\n",
       "   'support': 66.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 51.0},\n",
       "  'accuracy': 0.3626373626373626,\n",
       "  'macro avg': {'precision': 0.12087912087912088,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17741935483870966,\n",
       "   'support': 182.0},\n",
       "  'weighted avg': {'precision': 0.13150585678058205,\n",
       "   'recall': 0.3626373626373626,\n",
       "   'f1-score': 0.19301666075859622,\n",
       "   'support': 182.0}},\n",
       " {'1-49 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 61.0},\n",
       "  '< 1 %': {'precision': 0.37222222222222223,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5425101214574899,\n",
       "   'support': 67.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 52.0},\n",
       "  'accuracy': 0.37222222222222223,\n",
       "  'macro avg': {'precision': 0.12407407407407407,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.18083670715249664,\n",
       "   'support': 180.0},\n",
       "  'weighted avg': {'precision': 0.13854938271604939,\n",
       "   'recall': 0.37222222222222223,\n",
       "   'f1-score': 0.20193432298695457,\n",
       "   'support': 180.0}},\n",
       " {'1-49 %': {'precision': 0.3707865168539326,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5409836065573771,\n",
       "   'support': 66.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 62.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 50.0},\n",
       "  'accuracy': 0.3707865168539326,\n",
       "  'macro avg': {'precision': 0.12359550561797754,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.18032786885245902,\n",
       "   'support': 178.0},\n",
       "  'weighted avg': {'precision': 0.13748264108067165,\n",
       "   'recall': 0.3707865168539326,\n",
       "   'f1-score': 0.2005894271504881,\n",
       "   'support': 178.0}},\n",
       " {'1-49 %': {'precision': 0.36416184971098264,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5338983050847458,\n",
       "   'support': 63.0},\n",
       "  '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 62.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 48.0},\n",
       "  'accuracy': 0.36416184971098264,\n",
       "  'macro avg': {'precision': 0.12138728323699421,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17796610169491525,\n",
       "   'support': 173.0},\n",
       "  'weighted avg': {'precision': 0.13261385278492432,\n",
       "   'recall': 0.36416184971098264,\n",
       "   'f1-score': 0.19442539433721956,\n",
       "   'support': 173.0}},\n",
       " {'1-49 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 60.0},\n",
       "  '< 1 %': {'precision': 0.3630952380952381,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5327510917030568,\n",
       "   'support': 61.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 47.0},\n",
       "  'accuracy': 0.3630952380952381,\n",
       "  'macro avg': {'precision': 0.12103174603174603,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17758369723435227,\n",
       "   'support': 168.0},\n",
       "  'weighted avg': {'precision': 0.13183815192743764,\n",
       "   'recall': 0.3630952380952381,\n",
       "   'f1-score': 0.19343938448741943,\n",
       "   'support': 168.0}},\n",
       " {'1-49 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 62.0},\n",
       "  '< 1 %': {'precision': 0.3615819209039548,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.5311203319502075,\n",
       "   'support': 64.0},\n",
       "  '>=50 %': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 51.0},\n",
       "  'accuracy': 0.3615819209039548,\n",
       "  'macro avg': {'precision': 0.12052730696798493,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.17704011065006917,\n",
       "   'support': 177.0},\n",
       "  'weighted avg': {'precision': 0.13074148552459383,\n",
       "   'recall': 0.3615819209039548,\n",
       "   'f1-score': 0.19204350985770213,\n",
       "   'support': 177.0}}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classification_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'1-49 %': {'precision': 0.2181013051107362, 'recall': 0.6, 'f1-score': 0.31987634115293695, 'support': 62.4}, '< 1 %': {'precision': 0.14658918482647296, 'recall': 0.4, 'f1-score': 0.21455098724022265, 'support': 60.8}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 51.2}, 'accuracy': 0.36469048993720915, 'macro avg': {'precision': 0.1215634966457364, 'recall': 0.3333333333333333, 'f1-score': 0.17814244279771987, 'support': 174.4}, 'weighted avg': {'precision': 0.1330484567978564, 'recall': 0.36469048993720915, 'f1-score': 0.19495365148125873, 'support': 174.4}}, {'1-49 %': {'precision': 0.3675244174157218, 'recall': 1.0, 'f1-score': 0.5373562564756138, 'support': 66.4}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 61.6}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 52.8}, 'accuracy': 0.3675244174157218, 'macro avg': {'precision': 0.12250813913857392, 'recall': 0.3333333333333333, 'f1-score': 0.17911875215853795, 'support': 180.8}, 'weighted avg': {'precision': 0.13526368421915327, 'recall': 0.3675244174157218, 'f1-score': 0.1976925783558297, 'support': 180.8}}, {'1-49 %': {'precision': 0.1393181818181818, 'recall': 0.4, 'f1-score': 0.206657290201594, 'support': 61.6}, '< 1 %': {'precision': 0.21494382022471908, 'recall': 0.6, 'f1-score': 0.3164847124443084, 'support': 63.2}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 53.6}, 'accuracy': 0.354262002042901, 'macro avg': {'precision': 0.11808733401430031, 'recall': 0.3333333333333333, 'f1-score': 0.17438066754863416, 'support': 178.4}, 'weighted avg': {'precision': 0.12554998537338238, 'recall': 0.354262002042901, 'f1-score': 0.1853820014398994, 'support': 178.4}}, {'1-49 %': {'precision': 0.14514247113731268, 'recall': 0.4, 'f1-score': 0.21299697475657534, 'support': 64.0}, '< 1 %': {'precision': 0.2187795444778685, 'recall': 0.6, 'f1-score': 0.3206395120407596, 'support': 64.8}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 52.0}, 'accuracy': 0.3639220156151812, 'macro avg': {'precision': 0.12130733853839373, 'recall': 0.3333333333333333, 'f1-score': 0.17787882893244494, 'support': 180.8}, 'weighted avg': {'precision': 0.13244433792014085, 'recall': 0.3639220156151812, 'f1-score': 0.1942075444330275, 'support': 180.8}}, {'1-49 %': {'precision': 0.14698967331298304, 'recall': 0.4, 'f1-score': 0.2149763823284246, 'support': 62.4}, '< 1 %': {'precision': 0.21937987624428304, 'recall': 0.6, 'f1-score': 0.3212763090221508, 'support': 63.2}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 49.6}, 'accuracy': 0.3663695495572661, 'macro avg': {'precision': 0.12212318318575537, 'recall': 0.3333333333333333, 'f1-score': 0.1787508971168585, 'support': 175.2}, 'weighted avg': {'precision': 0.13424510280673538, 'recall': 0.3663695495572661, 'f1-score': 0.19648640776395673, 'support': 175.2}}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming your list of dictionaries is stored in the variable `reports`\n",
    "reports = train_classification_reports  # your list of dictionaries\n",
    "\n",
    "def average_report_group(group):\n",
    "    \"\"\"Average a group of report dictionaries.\"\"\"\n",
    "    avg_report = {}\n",
    "    # Loop over each key in the first dictionary of the group.\n",
    "    for key in group[0]:\n",
    "        if key == 'accuracy':\n",
    "            # Average the accuracy values directly.\n",
    "            avg_report[key] = np.mean([r[key] for r in group])\n",
    "        else:\n",
    "            # For keys that are nested dictionaries, average each inner metric.\n",
    "            inner_keys = group[0][key].keys()\n",
    "            avg_inner = {}\n",
    "            for metric in inner_keys:\n",
    "                avg_inner[metric] = np.mean([r[key][metric] for r in group])\n",
    "            avg_report[key] = avg_inner\n",
    "    return avg_report\n",
    "\n",
    "group_size = 5\n",
    "averaged_reports = []\n",
    "\n",
    "# Process the reports list in chunks of 5.\n",
    "for i in range(0, len(reports), group_size):\n",
    "    group = reports[i:i + group_size]\n",
    "    avg = average_report_group(group)\n",
    "    averaged_reports.append(avg)\n",
    "\n",
    "# Now `averaged_reports` contains the averaged dictionary for each group of 5 items.\n",
    "print(averaged_reports)\n",
    "\n",
    "df_averaged_pred = pd.DataFrame(averaged_reports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-49 %_precision_avg</th>\n",
       "      <th>1-49 %_precision_ci</th>\n",
       "      <th>1-49 %_recall_avg</th>\n",
       "      <th>1-49 %_recall_ci</th>\n",
       "      <th>1-49 %_f1-score_avg</th>\n",
       "      <th>1-49 %_f1-score_ci</th>\n",
       "      <th>1-49 %_support_avg</th>\n",
       "      <th>1-49 %_support_ci</th>\n",
       "      <th>&lt; 1 %_precision_avg</th>\n",
       "      <th>&lt; 1 %_precision_ci</th>\n",
       "      <th>...</th>\n",
       "      <th>macro avg_support_avg</th>\n",
       "      <th>macro avg_support_ci</th>\n",
       "      <th>weighted avg_precision_avg</th>\n",
       "      <th>weighted avg_precision_ci</th>\n",
       "      <th>weighted avg_recall_avg</th>\n",
       "      <th>weighted avg_recall_ci</th>\n",
       "      <th>weighted avg_f1-score_avg</th>\n",
       "      <th>weighted avg_f1-score_ci</th>\n",
       "      <th>weighted avg_support_avg</th>\n",
       "      <th>weighted avg_support_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.203415</td>\n",
       "      <td>0.073691</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.202649</td>\n",
       "      <td>0.298373</td>\n",
       "      <td>0.108036</td>\n",
       "      <td>63.36</td>\n",
       "      <td>0.965263</td>\n",
       "      <td>0.159938</td>\n",
       "      <td>0.073677</td>\n",
       "      <td>...</td>\n",
       "      <td>177.92</td>\n",
       "      <td>1.700667</td>\n",
       "      <td>0.13211</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.363354</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.193744</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>177.92</td>\n",
       "      <td>1.700667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1-49 %_precision_avg  1-49 %_precision_ci  1-49 %_recall_avg  \\\n",
       "0              0.203415             0.073691               0.56   \n",
       "\n",
       "   1-49 %_recall_ci  1-49 %_f1-score_avg  1-49 %_f1-score_ci  \\\n",
       "0          0.202649             0.298373            0.108036   \n",
       "\n",
       "   1-49 %_support_avg  1-49 %_support_ci  < 1 %_precision_avg  \\\n",
       "0               63.36           0.965263             0.159938   \n",
       "\n",
       "   < 1 %_precision_ci  ...  macro avg_support_avg  macro avg_support_ci  \\\n",
       "0            0.073677  ...                 177.92              1.700667   \n",
       "\n",
       "   weighted avg_precision_avg  weighted avg_precision_ci  \\\n",
       "0                     0.13211                   0.002752   \n",
       "\n",
       "   weighted avg_recall_avg  weighted avg_recall_ci  weighted avg_f1-score_avg  \\\n",
       "0                 0.363354                0.003751                   0.193744   \n",
       "\n",
       "   weighted avg_f1-score_ci  weighted avg_support_avg  weighted avg_support_ci  \n",
       "0                  0.003486                    177.92                 1.700667  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4186046511627907\n",
      "{'1-49 %': {'precision': 0.4186046511627907, 'recall': 1.0, 'f1-score': 0.5901639344262295, 'support': 18.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13.0}, 'accuracy': 0.4186046511627907, 'macro avg': {'precision': 0.13953488372093023, 'recall': 0.3333333333333333, 'f1-score': 0.19672131147540983, 'support': 43.0}, 'weighted avg': {'precision': 0.1752298539751217, 'recall': 0.4186046511627907, 'f1-score': 0.24704536789935186, 'support': 43.0}}\n",
      "0.36585365853658536\n",
      "{'1-49 %': {'precision': 0.36585365853658536, 'recall': 1.0, 'f1-score': 0.5357142857142857, 'support': 15.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 11.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, 'accuracy': 0.36585365853658536, 'macro avg': {'precision': 0.12195121951219512, 'recall': 0.3333333333333333, 'f1-score': 0.17857142857142858, 'support': 41.0}, 'weighted avg': {'precision': 0.1338488994646044, 'recall': 0.36585365853658536, 'f1-score': 0.195993031358885, 'support': 41.0}}\n",
      "0.42857142857142855\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, '< 1 %': {'precision': 0.42857142857142855, 'recall': 1.0, 'f1-score': 0.6, 'support': 18.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10.0}, 'accuracy': 0.42857142857142855, 'macro avg': {'precision': 0.14285714285714285, 'recall': 0.3333333333333333, 'f1-score': 0.19999999999999998, 'support': 42.0}, 'weighted avg': {'precision': 0.18367346938775508, 'recall': 0.42857142857142855, 'f1-score': 0.2571428571428571, 'support': 42.0}}\n",
      "0.37777777777777777\n",
      "{'1-49 %': {'precision': 0.37777777777777777, 'recall': 1.0, 'f1-score': 0.5483870967741935, 'support': 17.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 17.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 11.0}, 'accuracy': 0.37777777777777777, 'macro avg': {'precision': 0.1259259259259259, 'recall': 0.3333333333333333, 'f1-score': 0.18279569892473116, 'support': 45.0}, 'weighted avg': {'precision': 0.14271604938271606, 'recall': 0.37777777777777777, 'f1-score': 0.207168458781362, 'support': 45.0}}\n",
      "0.3829787234042553\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, '< 1 %': {'precision': 0.3829787234042553, 'recall': 1.0, 'f1-score': 0.5538461538461539, 'support': 18.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, 'accuracy': 0.3829787234042553, 'macro avg': {'precision': 0.1276595744680851, 'recall': 0.3333333333333333, 'f1-score': 0.18461538461538463, 'support': 47.0}, 'weighted avg': {'precision': 0.1466727025803531, 'recall': 0.3829787234042553, 'f1-score': 0.21211129296235678, 'support': 47.0}}\n",
      "0.35294117647058826\n",
      "{'1-49 %': {'precision': 0.35294117647058826, 'recall': 1.0, 'f1-score': 0.5217391304347826, 'support': 18.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 18.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, 'accuracy': 0.35294117647058826, 'macro avg': {'precision': 0.11764705882352942, 'recall': 0.3333333333333333, 'f1-score': 0.17391304347826086, 'support': 51.0}, 'weighted avg': {'precision': 0.12456747404844291, 'recall': 0.35294117647058826, 'f1-score': 0.18414322250639384, 'support': 51.0}}\n",
      "0.42857142857142855\n",
      "{'1-49 %': {'precision': 0.42857142857142855, 'recall': 1.0, 'f1-score': 0.6, 'support': 18.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 11.0}, 'accuracy': 0.42857142857142855, 'macro avg': {'precision': 0.14285714285714285, 'recall': 0.3333333333333333, 'f1-score': 0.19999999999999998, 'support': 42.0}, 'weighted avg': {'precision': 0.18367346938775508, 'recall': 0.42857142857142855, 'f1-score': 0.2571428571428571, 'support': 42.0}}\n",
      "0.4146341463414634\n",
      "{'1-49 %': {'precision': 0.4146341463414634, 'recall': 1.0, 'f1-score': 0.5862068965517241, 'support': 17.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10.0}, 'accuracy': 0.4146341463414634, 'macro avg': {'precision': 0.13821138211382114, 'recall': 0.3333333333333333, 'f1-score': 0.1954022988505747, 'support': 41.0}, 'weighted avg': {'precision': 0.1719214753123141, 'recall': 0.4146341463414634, 'f1-score': 0.24306139613120267, 'support': 41.0}}\n",
      "0.4\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, '< 1 %': {'precision': 0.4, 'recall': 1.0, 'f1-score': 0.5714285714285714, 'support': 20.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 16.0}, 'accuracy': 0.4, 'macro avg': {'precision': 0.13333333333333333, 'recall': 0.3333333333333333, 'f1-score': 0.19047619047619047, 'support': 50.0}, 'weighted avg': {'precision': 0.16, 'recall': 0.4, 'f1-score': 0.22857142857142854, 'support': 50.0}}\n",
      "0.38095238095238093\n",
      "{'1-49 %': {'precision': 0.38095238095238093, 'recall': 1.0, 'f1-score': 0.5517241379310345, 'support': 16.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, 'accuracy': 0.38095238095238093, 'macro avg': {'precision': 0.12698412698412698, 'recall': 0.3333333333333333, 'f1-score': 0.1839080459770115, 'support': 42.0}, 'weighted avg': {'precision': 0.14512471655328799, 'recall': 0.38095238095238093, 'f1-score': 0.21018062397372742, 'support': 42.0}}\n",
      "0.3829787234042553\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 16.0}, '< 1 %': {'precision': 0.3829787234042553, 'recall': 1.0, 'f1-score': 0.5538461538461539, 'support': 18.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13.0}, 'accuracy': 0.3829787234042553, 'macro avg': {'precision': 0.1276595744680851, 'recall': 0.3333333333333333, 'f1-score': 0.18461538461538463, 'support': 47.0}, 'weighted avg': {'precision': 0.1466727025803531, 'recall': 0.3829787234042553, 'f1-score': 0.21211129296235678, 'support': 47.0}}\n",
      "0.35555555555555557\n",
      "{'1-49 %': {'precision': 0.35555555555555557, 'recall': 1.0, 'f1-score': 0.5245901639344263, 'support': 16.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, 'accuracy': 0.35555555555555557, 'macro avg': {'precision': 0.11851851851851852, 'recall': 0.3333333333333333, 'f1-score': 0.17486338797814208, 'support': 45.0}, 'weighted avg': {'precision': 0.12641975308641976, 'recall': 0.35555555555555557, 'f1-score': 0.18652094717668488, 'support': 45.0}}\n",
      "0.35555555555555557\n",
      "{'1-49 %': {'precision': 0.35555555555555557, 'recall': 1.0, 'f1-score': 0.5245901639344263, 'support': 16.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, 'accuracy': 0.35555555555555557, 'macro avg': {'precision': 0.11851851851851852, 'recall': 0.3333333333333333, 'f1-score': 0.17486338797814208, 'support': 45.0}, 'weighted avg': {'precision': 0.12641975308641976, 'recall': 0.35555555555555557, 'f1-score': 0.18652094717668488, 'support': 45.0}}\n",
      "0.37209302325581395\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, '< 1 %': {'precision': 0.37209302325581395, 'recall': 1.0, 'f1-score': 0.5423728813559322, 'support': 16.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12.0}, 'accuracy': 0.37209302325581395, 'macro avg': {'precision': 0.12403100775193798, 'recall': 0.3333333333333333, 'f1-score': 0.1807909604519774, 'support': 43.0}, 'weighted avg': {'precision': 0.13845321795565171, 'recall': 0.37209302325581395, 'f1-score': 0.2018131651556957, 'support': 43.0}}\n",
      "0.37209302325581395\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, '< 1 %': {'precision': 0.37209302325581395, 'recall': 1.0, 'f1-score': 0.5423728813559322, 'support': 16.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13.0}, 'accuracy': 0.37209302325581395, 'macro avg': {'precision': 0.12403100775193798, 'recall': 0.3333333333333333, 'f1-score': 0.1807909604519774, 'support': 43.0}, 'weighted avg': {'precision': 0.13845321795565171, 'recall': 0.37209302325581395, 'f1-score': 0.2018131651556957, 'support': 43.0}}\n",
      "0.38095238095238093\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13.0}, '< 1 %': {'precision': 0.38095238095238093, 'recall': 1.0, 'f1-score': 0.5517241379310345, 'support': 16.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13.0}, 'accuracy': 0.38095238095238093, 'macro avg': {'precision': 0.12698412698412698, 'recall': 0.3333333333333333, 'f1-score': 0.1839080459770115, 'support': 42.0}, 'weighted avg': {'precision': 0.14512471655328799, 'recall': 0.38095238095238093, 'f1-score': 0.21018062397372742, 'support': 42.0}}\n",
      "0.4090909090909091\n",
      "{'1-49 %': {'precision': 0.4090909090909091, 'recall': 1.0, 'f1-score': 0.5806451612903226, 'support': 18.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12.0}, 'accuracy': 0.4090909090909091, 'macro avg': {'precision': 0.13636363636363638, 'recall': 0.3333333333333333, 'f1-score': 0.19354838709677422, 'support': 44.0}, 'weighted avg': {'precision': 0.16735537190082647, 'recall': 0.4090909090909091, 'f1-score': 0.23753665689149564, 'support': 44.0}}\n",
      "0.40816326530612246\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 16.0}, '< 1 %': {'precision': 0.40816326530612246, 'recall': 1.0, 'f1-score': 0.5797101449275363, 'support': 20.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13.0}, 'accuracy': 0.40816326530612246, 'macro avg': {'precision': 0.1360544217687075, 'recall': 0.3333333333333333, 'f1-score': 0.1932367149758454, 'support': 49.0}, 'weighted avg': {'precision': 0.16659725114535612, 'recall': 0.40816326530612246, 'f1-score': 0.23661638568470866, 'support': 49.0}}\n",
      "0.3829787234042553\n",
      "{'1-49 %': {'precision': 0.3829787234042553, 'recall': 1.0, 'f1-score': 0.5538461538461539, 'support': 18.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 16.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13.0}, 'accuracy': 0.3829787234042553, 'macro avg': {'precision': 0.1276595744680851, 'recall': 0.3333333333333333, 'f1-score': 0.18461538461538463, 'support': 47.0}, 'weighted avg': {'precision': 0.1466727025803531, 'recall': 0.3829787234042553, 'f1-score': 0.21211129296235678, 'support': 47.0}}\n",
      "0.3409090909090909\n",
      "{'1-49 %': {'precision': 0.3409090909090909, 'recall': 1.0, 'f1-score': 0.5084745762711864, 'support': 15.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, 'accuracy': 0.3409090909090909, 'macro avg': {'precision': 0.11363636363636363, 'recall': 0.3333333333333333, 'f1-score': 0.1694915254237288, 'support': 44.0}, 'weighted avg': {'precision': 0.1162190082644628, 'recall': 0.3409090909090909, 'f1-score': 0.17334360554699535, 'support': 44.0}}\n",
      "0.4358974358974359\n",
      "{'1-49 %': {'precision': 0.4358974358974359, 'recall': 1.0, 'f1-score': 0.6071428571428571, 'support': 17.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10.0}, 'accuracy': 0.4358974358974359, 'macro avg': {'precision': 0.1452991452991453, 'recall': 0.3333333333333333, 'f1-score': 0.20238095238095236, 'support': 39.0}, 'weighted avg': {'precision': 0.19000657462195925, 'recall': 0.4358974358974359, 'f1-score': 0.26465201465201466, 'support': 39.0}}\n",
      "0.4146341463414634\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12.0}, '< 1 %': {'precision': 0.4146341463414634, 'recall': 1.0, 'f1-score': 0.5862068965517241, 'support': 17.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12.0}, 'accuracy': 0.4146341463414634, 'macro avg': {'precision': 0.13821138211382114, 'recall': 0.3333333333333333, 'f1-score': 0.1954022988505747, 'support': 41.0}, 'weighted avg': {'precision': 0.1719214753123141, 'recall': 0.4146341463414634, 'f1-score': 0.24306139613120267, 'support': 41.0}}\n",
      "0.3695652173913043\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, '< 1 %': {'precision': 0.3695652173913043, 'recall': 1.0, 'f1-score': 0.5396825396825397, 'support': 17.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, 'accuracy': 0.3695652173913043, 'macro avg': {'precision': 0.12318840579710144, 'recall': 0.3333333333333333, 'f1-score': 0.17989417989417988, 'support': 46.0}, 'weighted avg': {'precision': 0.13657844990548204, 'recall': 0.3695652173913043, 'f1-score': 0.199447895100069, 'support': 46.0}}\n",
      "0.35294117647058826\n",
      "{'1-49 %': {'precision': 0.35294117647058826, 'recall': 1.0, 'f1-score': 0.5217391304347826, 'support': 18.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 18.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, 'accuracy': 0.35294117647058826, 'macro avg': {'precision': 0.11764705882352942, 'recall': 0.3333333333333333, 'f1-score': 0.17391304347826086, 'support': 51.0}, 'weighted avg': {'precision': 0.12456747404844291, 'recall': 0.35294117647058826, 'f1-score': 0.18414322250639384, 'support': 51.0}}\n",
      "0.38095238095238093\n",
      "{'1-49 %': {'precision': 0.38095238095238093, 'recall': 1.0, 'f1-score': 0.5517241379310345, 'support': 16.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 11.0}, 'accuracy': 0.38095238095238093, 'macro avg': {'precision': 0.12698412698412698, 'recall': 0.3333333333333333, 'f1-score': 0.1839080459770115, 'support': 42.0}, 'weighted avg': {'precision': 0.14512471655328799, 'recall': 0.38095238095238093, 'f1-score': 0.21018062397372742, 'support': 42.0}}\n"
     ]
    }
   ],
   "source": [
    "metrics_list = []\n",
    "numbers = []\n",
    "desired_order = [\"< 1 %\", \"1-49 %\", \">=50 %\"]\n",
    "\n",
    "val_models = []\n",
    "val_classification_reports = []\n",
    "for i in val_parquet_paths:\n",
    "    df_predictions = pd.read_parquet(i)\n",
    "    df_joined = pd.merge(df_predictions, csv_df, on ='slide', how = 'left')\n",
    "    #print(df_joined)\n",
    "    distribution = df_joined[[\"slide\", \"PDL1_CATHEGORY\"]]\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    x_list = np.ones((distribution.shape[0], 1))\n",
    "    y_list = df_joined[\"PDL1_CATHEGORY\"].to_numpy()\n",
    "\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy_clf.fit(x_list, y_list)\n",
    "\n",
    "    y_pred = dummy_clf.predict(x_list)\n",
    "\n",
    "    val_models.append(dummy_clf)\n",
    "\n",
    "    # Accuratezza generale\n",
    "    acc = accuracy_score(y_list, y_pred)\n",
    "    print(acc)\n",
    "\n",
    "    # Report dettagliato per classe\n",
    "    report = classification_report(y_list, y_pred, digits=2, output_dict=True, zero_division=0)\n",
    "\n",
    "    print(report)\n",
    "\n",
    "    val_classification_reports.append(report)\n",
    "\n",
    "#df_train = pd.DataFrame(metrics_list, numbers)\n",
    "#display(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21.0}, '< 1 %': {'precision': 0.36666666666666664, 'recall': 1.0, 'f1-score': 0.5365853658536586, 'support': 22.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 17.0}, 'accuracy': 0.36666666666666664, 'macro avg': {'precision': 0.12222222222222222, 'recall': 0.3333333333333333, 'f1-score': 0.17886178861788618, 'support': 60.0}, 'weighted avg': {'precision': 0.13444444444444445, 'recall': 0.36666666666666664, 'f1-score': 0.1967479674796748, 'support': 60.0}}\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21.0}, '< 1 %': {'precision': 0.36666666666666664, 'recall': 1.0, 'f1-score': 0.5365853658536586, 'support': 22.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 17.0}, 'accuracy': 0.36666666666666664, 'macro avg': {'precision': 0.12222222222222222, 'recall': 0.3333333333333333, 'f1-score': 0.17886178861788618, 'support': 60.0}, 'weighted avg': {'precision': 0.13444444444444445, 'recall': 0.36666666666666664, 'f1-score': 0.1967479674796748, 'support': 60.0}}\n",
      "{'1-49 %': {'precision': 0.35, 'recall': 1.0, 'f1-score': 0.5185185185185185, 'support': 21.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 17.0}, 'accuracy': 0.35, 'macro avg': {'precision': 0.11666666666666665, 'recall': 0.3333333333333333, 'f1-score': 0.1728395061728395, 'support': 60.0}, 'weighted avg': {'precision': 0.1225, 'recall': 0.35, 'f1-score': 0.18148148148148147, 'support': 60.0}}\n",
      "{'1-49 %': {'precision': 0.35, 'recall': 1.0, 'f1-score': 0.5185185185185185, 'support': 21.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 17.0}, 'accuracy': 0.35, 'macro avg': {'precision': 0.11666666666666665, 'recall': 0.3333333333333333, 'f1-score': 0.1728395061728395, 'support': 60.0}, 'weighted avg': {'precision': 0.1225, 'recall': 0.35, 'f1-score': 0.18148148148148147, 'support': 60.0}}\n",
      "{'1-49 %': {'precision': 0.35, 'recall': 1.0, 'f1-score': 0.5185185185185185, 'support': 21.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 17.0}, 'accuracy': 0.35, 'macro avg': {'precision': 0.11666666666666665, 'recall': 0.3333333333333333, 'f1-score': 0.1728395061728395, 'support': 60.0}, 'weighted avg': {'precision': 0.1225, 'recall': 0.35, 'f1-score': 0.18148148148148147, 'support': 60.0}}\n",
      "{'1-49 %': {'precision': 0.3076923076923077, 'recall': 1.0, 'f1-score': 0.47058823529411764, 'support': 16.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, 'accuracy': 0.3076923076923077, 'macro avg': {'precision': 0.10256410256410257, 'recall': 0.3333333333333333, 'f1-score': 0.1568627450980392, 'support': 52.0}, 'weighted avg': {'precision': 0.09467455621301776, 'recall': 0.3076923076923077, 'f1-score': 0.14479638009049772, 'support': 52.0}}\n",
      "{'1-49 %': {'precision': 0.3076923076923077, 'recall': 1.0, 'f1-score': 0.47058823529411764, 'support': 16.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, 'accuracy': 0.3076923076923077, 'macro avg': {'precision': 0.10256410256410257, 'recall': 0.3333333333333333, 'f1-score': 0.1568627450980392, 'support': 52.0}, 'weighted avg': {'precision': 0.09467455621301776, 'recall': 0.3076923076923077, 'f1-score': 0.14479638009049772, 'support': 52.0}}\n",
      "{'1-49 %': {'precision': 0.3076923076923077, 'recall': 1.0, 'f1-score': 0.47058823529411764, 'support': 16.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, 'accuracy': 0.3076923076923077, 'macro avg': {'precision': 0.10256410256410257, 'recall': 0.3333333333333333, 'f1-score': 0.1568627450980392, 'support': 52.0}, 'weighted avg': {'precision': 0.09467455621301776, 'recall': 0.3076923076923077, 'f1-score': 0.14479638009049772, 'support': 52.0}}\n",
      "{'1-49 %': {'precision': 0.3076923076923077, 'recall': 1.0, 'f1-score': 0.47058823529411764, 'support': 16.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, 'accuracy': 0.3076923076923077, 'macro avg': {'precision': 0.10256410256410257, 'recall': 0.3333333333333333, 'f1-score': 0.1568627450980392, 'support': 52.0}, 'weighted avg': {'precision': 0.09467455621301776, 'recall': 0.3076923076923077, 'f1-score': 0.14479638009049772, 'support': 52.0}}\n",
      "{'1-49 %': {'precision': 0.3076923076923077, 'recall': 1.0, 'f1-score': 0.47058823529411764, 'support': 16.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, 'accuracy': 0.3076923076923077, 'macro avg': {'precision': 0.10256410256410257, 'recall': 0.3333333333333333, 'f1-score': 0.1568627450980392, 'support': 52.0}, 'weighted avg': {'precision': 0.09467455621301776, 'recall': 0.3076923076923077, 'f1-score': 0.14479638009049772, 'support': 52.0}}\n",
      "{'1-49 %': {'precision': 0.4, 'recall': 1.0, 'f1-score': 0.5714285714285714, 'support': 22.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, 'accuracy': 0.4, 'macro avg': {'precision': 0.13333333333333333, 'recall': 0.3333333333333333, 'f1-score': 0.19047619047619047, 'support': 55.0}, 'weighted avg': {'precision': 0.16, 'recall': 0.4, 'f1-score': 0.22857142857142856, 'support': 55.0}}\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22.0}, '< 1 %': {'precision': 0.34545454545454546, 'recall': 1.0, 'f1-score': 0.5135135135135135, 'support': 19.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, 'accuracy': 0.34545454545454546, 'macro avg': {'precision': 0.11515151515151516, 'recall': 0.3333333333333333, 'f1-score': 0.17117117117117117, 'support': 55.0}, 'weighted avg': {'precision': 0.11933884297520661, 'recall': 0.34545454545454546, 'f1-score': 0.17739557739557738, 'support': 55.0}}\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22.0}, '< 1 %': {'precision': 0.34545454545454546, 'recall': 1.0, 'f1-score': 0.5135135135135135, 'support': 19.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, 'accuracy': 0.34545454545454546, 'macro avg': {'precision': 0.11515151515151516, 'recall': 0.3333333333333333, 'f1-score': 0.17117117117117117, 'support': 55.0}, 'weighted avg': {'precision': 0.11933884297520661, 'recall': 0.34545454545454546, 'f1-score': 0.17739557739557738, 'support': 55.0}}\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22.0}, '< 1 %': {'precision': 0.34545454545454546, 'recall': 1.0, 'f1-score': 0.5135135135135135, 'support': 19.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, 'accuracy': 0.34545454545454546, 'macro avg': {'precision': 0.11515151515151516, 'recall': 0.3333333333333333, 'f1-score': 0.17117117117117117, 'support': 55.0}, 'weighted avg': {'precision': 0.11933884297520661, 'recall': 0.34545454545454546, 'f1-score': 0.17739557739557738, 'support': 55.0}}\n",
      "{'1-49 %': {'precision': 0.4, 'recall': 1.0, 'f1-score': 0.5714285714285714, 'support': 22.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 14.0}, 'accuracy': 0.4, 'macro avg': {'precision': 0.13333333333333333, 'recall': 0.3333333333333333, 'f1-score': 0.19047619047619047, 'support': 55.0}, 'weighted avg': {'precision': 0.16, 'recall': 0.4, 'f1-score': 0.22857142857142856, 'support': 55.0}}\n",
      "{'1-49 %': {'precision': 0.36538461538461536, 'recall': 1.0, 'f1-score': 0.5352112676056338, 'support': 19.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 17.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 16.0}, 'accuracy': 0.36538461538461536, 'macro avg': {'precision': 0.12179487179487179, 'recall': 0.3333333333333333, 'f1-score': 0.1784037558685446, 'support': 52.0}, 'weighted avg': {'precision': 0.1335059171597633, 'recall': 0.36538461538461536, 'f1-score': 0.19555796316359697, 'support': 52.0}}\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, '< 1 %': {'precision': 0.3269230769230769, 'recall': 1.0, 'f1-score': 0.4927536231884058, 'support': 17.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 16.0}, 'accuracy': 0.3269230769230769, 'macro avg': {'precision': 0.10897435897435898, 'recall': 0.3333333333333333, 'f1-score': 0.1642512077294686, 'support': 52.0}, 'weighted avg': {'precision': 0.10687869822485206, 'recall': 0.3269230769230769, 'f1-score': 0.16109253065774803, 'support': 52.0}}\n",
      "{'1-49 %': {'precision': 0.36538461538461536, 'recall': 1.0, 'f1-score': 0.5352112676056338, 'support': 19.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 17.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 16.0}, 'accuracy': 0.36538461538461536, 'macro avg': {'precision': 0.12179487179487179, 'recall': 0.3333333333333333, 'f1-score': 0.1784037558685446, 'support': 52.0}, 'weighted avg': {'precision': 0.1335059171597633, 'recall': 0.36538461538461536, 'f1-score': 0.19555796316359697, 'support': 52.0}}\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, '< 1 %': {'precision': 0.3269230769230769, 'recall': 1.0, 'f1-score': 0.4927536231884058, 'support': 17.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 16.0}, 'accuracy': 0.3269230769230769, 'macro avg': {'precision': 0.10897435897435898, 'recall': 0.3333333333333333, 'f1-score': 0.1642512077294686, 'support': 52.0}, 'weighted avg': {'precision': 0.10687869822485206, 'recall': 0.3269230769230769, 'f1-score': 0.16109253065774803, 'support': 52.0}}\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, '< 1 %': {'precision': 0.3269230769230769, 'recall': 1.0, 'f1-score': 0.4927536231884058, 'support': 17.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 16.0}, 'accuracy': 0.3269230769230769, 'macro avg': {'precision': 0.10897435897435898, 'recall': 0.3333333333333333, 'f1-score': 0.1642512077294686, 'support': 52.0}, 'weighted avg': {'precision': 0.10687869822485206, 'recall': 0.3269230769230769, 'f1-score': 0.16109253065774803, 'support': 52.0}}\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21.0}, '< 1 %': {'precision': 0.3220338983050847, 'recall': 1.0, 'f1-score': 0.48717948717948717, 'support': 19.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, 'accuracy': 0.3220338983050847, 'macro avg': {'precision': 0.10734463276836158, 'recall': 0.3333333333333333, 'f1-score': 0.1623931623931624, 'support': 59.0}, 'weighted avg': {'precision': 0.10370583165756966, 'recall': 0.3220338983050847, 'f1-score': 0.1568883094306823, 'support': 59.0}}\n",
      "{'1-49 %': {'precision': 0.3559322033898305, 'recall': 1.0, 'f1-score': 0.525, 'support': 21.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, 'accuracy': 0.3559322033898305, 'macro avg': {'precision': 0.11864406779661017, 'recall': 0.3333333333333333, 'f1-score': 0.17500000000000002, 'support': 59.0}, 'weighted avg': {'precision': 0.12668773340993966, 'recall': 0.3559322033898305, 'f1-score': 0.186864406779661, 'support': 59.0}}\n",
      "{'1-49 %': {'precision': 0.3559322033898305, 'recall': 1.0, 'f1-score': 0.525, 'support': 21.0}, '< 1 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, 'accuracy': 0.3559322033898305, 'macro avg': {'precision': 0.11864406779661017, 'recall': 0.3333333333333333, 'f1-score': 0.17500000000000002, 'support': 59.0}, 'weighted avg': {'precision': 0.12668773340993966, 'recall': 0.3559322033898305, 'f1-score': 0.186864406779661, 'support': 59.0}}\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21.0}, '< 1 %': {'precision': 0.3220338983050847, 'recall': 1.0, 'f1-score': 0.48717948717948717, 'support': 19.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, 'accuracy': 0.3220338983050847, 'macro avg': {'precision': 0.10734463276836158, 'recall': 0.3333333333333333, 'f1-score': 0.1623931623931624, 'support': 59.0}, 'weighted avg': {'precision': 0.10370583165756966, 'recall': 0.3220338983050847, 'f1-score': 0.1568883094306823, 'support': 59.0}}\n",
      "{'1-49 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21.0}, '< 1 %': {'precision': 0.3220338983050847, 'recall': 1.0, 'f1-score': 0.48717948717948717, 'support': 19.0}, '>=50 %': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19.0}, 'accuracy': 0.3220338983050847, 'macro avg': {'precision': 0.10734463276836158, 'recall': 0.3333333333333333, 'f1-score': 0.1623931623931624, 'support': 59.0}, 'weighted avg': {'precision': 0.10370583165756966, 'recall': 0.3220338983050847, 'f1-score': 0.1568883094306823, 'support': 59.0}}\n"
     ]
    }
   ],
   "source": [
    "metrics_list = []\n",
    "numbers = []\n",
    "desired_order = [\"< 1 %\", \"1-49 %\", \">=50 %\"]\n",
    "\n",
    "test_scores = []\n",
    "\n",
    "for i, path in enumerate(test_parquet_paths):\n",
    "    df_predictions = pd.read_parquet(path)\n",
    "    dummy_clf = train_models[i]\n",
    "    df_joined = pd.merge(df_predictions, csv_df, on ='slide', how = 'left')\n",
    "    #print(df_joined)\n",
    "    distribution = df_joined[[\"slide\",\"PDL1_CATHEGORY\"]]\n",
    "\n",
    "    y_true = df_joined[\"PDL1_CATHEGORY\"].to_numpy()\n",
    "    x_list = np.ones((distribution.shape[0], 1))\n",
    "\n",
    "    #print(distribution)\n",
    "\n",
    "    y_pred = dummy_clf.predict(x_list)\n",
    "\n",
    "    #val_models.append(dummy_clf)\n",
    "\n",
    "    # Accuratezza generale\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    #print(acc)\n",
    "\n",
    "    # Report dettagliato per classe\n",
    "    report = classification_report(y_true, y_pred, digits=2, output_dict=True, zero_division=0)\n",
    "    test_scores.append(report)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing group 0 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.0, 0.0, 0.36363636363636365, 0.35260115606936415, 0.3742690058479532], average = 0.2181\n",
      "  1-49 % -> recall: values = [0.0, 0.0, 1.0, 1.0, 1.0], average = 0.6000\n",
      "  1-49 % -> f1-score: values = [0.0, 0.0, 0.5333333333333333, 0.5213675213675214, 0.5446808510638298], average = 0.3199\n",
      "  1-49 % -> support: values = [60.0, 63.0, 64.0, 61.0, 64.0], average = 62.4000\n",
      "  < 1 % -> precision: values = [0.3657142857142857, 0.3672316384180791, 0.0, 0.0, 0.0], average = 0.1466\n",
      "  < 1 % -> recall: values = [1.0, 1.0, 0.0, 0.0, 0.0], average = 0.4000\n",
      "  < 1 % -> f1-score: values = [0.5355648535564853, 0.5371900826446281, 0.0, 0.0, 0.0], average = 0.2146\n",
      "  < 1 % -> support: values = [64.0, 65.0, 58.0, 59.0, 58.0], average = 60.8000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [51.0, 49.0, 54.0, 53.0, 49.0], average = 51.2000\n",
      "  accuracy: values = [0.3657142857142857, 0.3672316384180791, 0.36363636363636365, 0.35260115606936415, 0.3742690058479532], average = 0.3647\n",
      "  macro avg -> precision: values = [0.1219047619047619, 0.1224105461393597, 0.12121212121212122, 0.11753371868978806, 0.12475633528265107], average = 0.1216\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.17852161785216178, 0.1790633608815427, 0.17777777777777778, 0.1737891737891738, 0.18156028368794327], average = 0.1781\n",
      "  macro avg -> support: values = [175.0, 177.0, 176.0, 173.0, 171.0], average = 174.4000\n",
      "  weighted avg -> precision: values = [0.1337469387755102, 0.13485907625522678, 0.1322314049586777, 0.1243275752614521, 0.14007728873841524], average = 0.1330\n",
      "  weighted avg -> recall: values = [0.3657142857142857, 0.3672316384180791, 0.36363636363636365, 0.35260115606936415, 0.3742690058479532], average = 0.3647\n",
      "  weighted avg -> f1-score: values = [0.19586371787208606, 0.19727319419153008, 0.19393939393939394, 0.18383479077120696, 0.20385716063207665], average = 0.1950\n",
      "  weighted avg -> support: values = [175.0, 177.0, 176.0, 173.0, 171.0], average = 174.4000\n",
      "\n",
      "Processing group 1 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.37142857142857144, 0.3532608695652174, 0.3567567567567568, 0.39204545454545453, 0.3641304347826087], average = 0.3675\n",
      "  1-49 % -> recall: values = [1.0, 1.0, 1.0, 1.0, 1.0], average = 1.0000\n",
      "  1-49 % -> f1-score: values = [0.5416666666666666, 0.5220883534136547, 0.5258964143426295, 0.563265306122449, 0.5338645418326693], average = 0.5374\n",
      "  1-49 % -> support: values = [65.0, 65.0, 66.0, 69.0, 67.0], average = 66.4000\n",
      "  < 1 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  < 1 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  < 1 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  < 1 % -> support: values = [59.0, 64.0, 63.0, 57.0, 65.0], average = 61.6000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [51.0, 55.0, 56.0, 50.0, 52.0], average = 52.8000\n",
      "  accuracy: values = [0.37142857142857144, 0.3532608695652174, 0.3567567567567568, 0.39204545454545453, 0.3641304347826087], average = 0.3675\n",
      "  macro avg -> precision: values = [0.12380952380952381, 0.1177536231884058, 0.11891891891891893, 0.13068181818181818, 0.1213768115942029], average = 0.1225\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.18055555555555555, 0.1740294511378849, 0.17529880478087648, 0.18775510204081633, 0.17795484727755642], average = 0.1791\n",
      "  macro avg -> support: values = [175.0, 184.0, 185.0, 176.0, 184.0], average = 180.8000\n",
      "  weighted avg -> precision: values = [0.13795918367346938, 0.12479324196597355, 0.12727538349159973, 0.15369963842975207, 0.13259097353497165], average = 0.1353\n",
      "  weighted avg -> recall: values = [0.37142857142857144, 0.3532608695652174, 0.3567567567567568, 0.39204545454545453, 0.3641304347826087], average = 0.3675\n",
      "  weighted avg -> f1-score: values = [0.20119047619047617, 0.1844333857167802, 0.187617099170884, 0.2208256029684601, 0.19439632773254803], average = 0.1977\n",
      "  weighted avg -> support: values = [175.0, 184.0, 185.0, 176.0, 184.0], average = 180.8000\n",
      "\n",
      "Processing group 2 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.3465909090909091, 0.0, 0.0, 0.0, 0.35], average = 0.1393\n",
      "  1-49 % -> recall: values = [1.0, 0.0, 0.0, 0.0, 1.0], average = 0.4000\n",
      "  1-49 % -> f1-score: values = [0.5147679324894515, 0.0, 0.0, 0.0, 0.5185185185185185], average = 0.2067\n",
      "  1-49 % -> support: values = [61.0, 61.0, 61.0, 62.0, 63.0], average = 61.6000\n",
      "  < 1 % -> precision: values = [0.0, 0.3595505617977528, 0.3651685393258427, 0.35, 0.0], average = 0.2149\n",
      "  < 1 % -> recall: values = [0.0, 1.0, 1.0, 1.0, 0.0], average = 0.6000\n",
      "  < 1 % -> f1-score: values = [0.0, 0.5289256198347108, 0.5349794238683128, 0.5185185185185185, 0.0], average = 0.3165\n",
      "  < 1 % -> support: values = [61.0, 64.0, 65.0, 63.0, 63.0], average = 63.2000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [54.0, 53.0, 52.0, 55.0, 54.0], average = 53.6000\n",
      "  accuracy: values = [0.3465909090909091, 0.3595505617977528, 0.3651685393258427, 0.35, 0.35], average = 0.3543\n",
      "  macro avg -> precision: values = [0.11553030303030304, 0.1198501872659176, 0.12172284644194757, 0.11666666666666665, 0.11666666666666665], average = 0.1181\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.17158931082981718, 0.1763085399449036, 0.17832647462277093, 0.1728395061728395, 0.1728395061728395], average = 0.1744\n",
      "  macro avg -> support: values = [176.0, 178.0, 178.0, 180.0, 180.0], average = 178.4000\n",
      "  weighted avg -> precision: values = [0.12012525826446283, 0.12927660648907965, 0.13334806211336953, 0.12249999999999998, 0.12249999999999998], average = 0.1255\n",
      "  weighted avg -> recall: values = [0.3465909090909091, 0.3595505617977528, 0.3651685393258427, 0.35, 0.35], average = 0.3543\n",
      "  weighted avg -> f1-score: values = [0.1784138856923667, 0.19017550376079487, 0.19535765478337264, 0.18148148148148147, 0.18148148148148147], average = 0.1854\n",
      "  weighted avg -> support: values = [176.0, 178.0, 178.0, 180.0, 180.0], average = 178.4000\n",
      "\n",
      "Processing group 3 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.3641304347826087, 0.0, 0.3615819209039548, 0.0, 0.0], average = 0.1451\n",
      "  1-49 % -> recall: values = [1.0, 0.0, 1.0, 0.0, 0.0], average = 0.4000\n",
      "  1-49 % -> f1-score: values = [0.5338645418326693, 0.0, 0.5311203319502075, 0.0, 0.0], average = 0.2130\n",
      "  1-49 % -> support: values = [67.0, 62.0, 64.0, 62.0, 65.0], average = 64.0000\n",
      "  < 1 % -> precision: values = [0.0, 0.36813186813186816, 0.0, 0.36312849162011174, 0.3626373626373626], average = 0.2188\n",
      "  < 1 % -> recall: values = [0.0, 1.0, 0.0, 1.0, 1.0], average = 0.6000\n",
      "  < 1 % -> f1-score: values = [0.0, 0.5381526104417671, 0.0, 0.5327868852459017, 0.532258064516129], average = 0.3206\n",
      "  < 1 % -> support: values = [65.0, 67.0, 61.0, 65.0, 66.0], average = 64.8000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [52.0, 53.0, 52.0, 52.0, 51.0], average = 52.0000\n",
      "  accuracy: values = [0.3641304347826087, 0.36813186813186816, 0.3615819209039548, 0.36312849162011174, 0.3626373626373626], average = 0.3639\n",
      "  macro avg -> precision: values = [0.1213768115942029, 0.12271062271062272, 0.12052730696798493, 0.12104283054003724, 0.12087912087912088], average = 0.1213\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.17795484727755642, 0.17938420348058903, 0.17704011065006917, 0.17759562841530055, 0.17741935483870966], average = 0.1779\n",
      "  macro avg -> support: values = [184.0, 182.0, 177.0, 179.0, 182.0], average = 180.8000\n",
      "  weighted avg -> precision: values = [0.13259097353497165, 0.13552107233425917, 0.13074148552459383, 0.13186230142629757, 0.13150585678058205], average = 0.1324\n",
      "  weighted avg -> recall: values = [0.3641304347826087, 0.36813186813186816, 0.3615819209039548, 0.36312849162011174, 0.3626373626373626], average = 0.3639\n",
      "  weighted avg -> f1-score: values = [0.19439632773254803, 0.19811112582196921, 0.19204350985770213, 0.19347009799432185, 0.19301666075859622], average = 0.1942\n",
      "  weighted avg -> support: values = [184.0, 182.0, 177.0, 179.0, 182.0], average = 180.8000\n",
      "\n",
      "Processing group 4 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.0, 0.3707865168539326, 0.36416184971098264, 0.0, 0.0], average = 0.1470\n",
      "  1-49 % -> recall: values = [0.0, 1.0, 1.0, 0.0, 0.0], average = 0.4000\n",
      "  1-49 % -> f1-score: values = [0.0, 0.5409836065573771, 0.5338983050847458, 0.0, 0.0], average = 0.2150\n",
      "  1-49 % -> support: values = [61.0, 66.0, 63.0, 60.0, 62.0], average = 62.4000\n",
      "  < 1 % -> precision: values = [0.37222222222222223, 0.0, 0.0, 0.3630952380952381, 0.3615819209039548], average = 0.2194\n",
      "  < 1 % -> recall: values = [1.0, 0.0, 0.0, 1.0, 1.0], average = 0.6000\n",
      "  < 1 % -> f1-score: values = [0.5425101214574899, 0.0, 0.0, 0.5327510917030568, 0.5311203319502075], average = 0.3213\n",
      "  < 1 % -> support: values = [67.0, 62.0, 62.0, 61.0, 64.0], average = 63.2000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [52.0, 50.0, 48.0, 47.0, 51.0], average = 49.6000\n",
      "  accuracy: values = [0.37222222222222223, 0.3707865168539326, 0.36416184971098264, 0.3630952380952381, 0.3615819209039548], average = 0.3664\n",
      "  macro avg -> precision: values = [0.12407407407407407, 0.12359550561797754, 0.12138728323699421, 0.12103174603174603, 0.12052730696798493], average = 0.1221\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.18083670715249664, 0.18032786885245902, 0.17796610169491525, 0.17758369723435227, 0.17704011065006917], average = 0.1788\n",
      "  macro avg -> support: values = [180.0, 178.0, 173.0, 168.0, 177.0], average = 175.2000\n",
      "  weighted avg -> precision: values = [0.13854938271604939, 0.13748264108067165, 0.13261385278492432, 0.13183815192743764, 0.13074148552459383], average = 0.1342\n",
      "  weighted avg -> recall: values = [0.37222222222222223, 0.3707865168539326, 0.36416184971098264, 0.3630952380952381, 0.3615819209039548], average = 0.3664\n",
      "  weighted avg -> f1-score: values = [0.20193432298695457, 0.2005894271504881, 0.19442539433721956, 0.19343938448741943, 0.19204350985770213], average = 0.1965\n",
      "  weighted avg -> support: values = [180.0, 178.0, 173.0, 168.0, 177.0], average = 175.2000\n",
      "\n",
      "Final DataFrame with averaged values:\n",
      "   1-49 %_precision_avg  1-49 %_recall_avg  1-49 %_f1-score_avg  \\\n",
      "0              0.218101                0.6             0.319876   \n",
      "1              0.367524                1.0             0.537356   \n",
      "2              0.139318                0.4             0.206657   \n",
      "3              0.145142                0.4             0.212997   \n",
      "4              0.146990                0.4             0.214976   \n",
      "\n",
      "   1-49 %_support_avg  < 1 %_precision_avg  < 1 %_recall_avg  \\\n",
      "0                62.4             0.146589               0.4   \n",
      "1                66.4             0.000000               0.0   \n",
      "2                61.6             0.214944               0.6   \n",
      "3                64.0             0.218780               0.6   \n",
      "4                62.4             0.219380               0.6   \n",
      "\n",
      "   < 1 %_f1-score_avg  < 1 %_support_avg  >=50 %_precision_avg  \\\n",
      "0            0.214551               60.8                   0.0   \n",
      "1            0.000000               61.6                   0.0   \n",
      "2            0.316485               63.2                   0.0   \n",
      "3            0.320640               64.8                   0.0   \n",
      "4            0.321276               63.2                   0.0   \n",
      "\n",
      "   >=50 %_recall_avg  ...  >=50 %_support_avg  accuracy_avg  \\\n",
      "0                0.0  ...                51.2      0.364690   \n",
      "1                0.0  ...                52.8      0.367524   \n",
      "2                0.0  ...                53.6      0.354262   \n",
      "3                0.0  ...                52.0      0.363922   \n",
      "4                0.0  ...                49.6      0.366370   \n",
      "\n",
      "   macro avg_precision_avg  macro avg_recall_avg  macro avg_f1-score_avg  \\\n",
      "0                 0.121563              0.333333                0.178142   \n",
      "1                 0.122508              0.333333                0.179119   \n",
      "2                 0.118087              0.333333                0.174381   \n",
      "3                 0.121307              0.333333                0.177879   \n",
      "4                 0.122123              0.333333                0.178751   \n",
      "\n",
      "   macro avg_support_avg  weighted avg_precision_avg  weighted avg_recall_avg  \\\n",
      "0                  174.4                    0.133048                 0.364690   \n",
      "1                  180.8                    0.135264                 0.367524   \n",
      "2                  178.4                    0.125550                 0.354262   \n",
      "3                  180.8                    0.132444                 0.363922   \n",
      "4                  175.2                    0.134245                 0.366370   \n",
      "\n",
      "   weighted avg_f1-score_avg  weighted avg_support_avg  \n",
      "0                   0.194954                     174.4  \n",
      "1                   0.197693                     180.8  \n",
      "2                   0.185382                     178.4  \n",
      "3                   0.194208                     180.8  \n",
      "4                   0.196486                     175.2  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Your list of dictionaries (only a few items are shown for brevity; include all in your actual code)\n",
    "report = train_classification_reports\n",
    "\n",
    "def average_report_group_with_print(group, group_index):\n",
    "    print(f\"\\nProcessing group {group_index} (with {len(group)} items):\")\n",
    "    group_stats = {}\n",
    "    for key in group[0]:\n",
    "        if key == 'accuracy':\n",
    "            values = [r[key] for r in group]\n",
    "            avg_val = np.mean(values)\n",
    "            print(f\"  {key}: values = {values}, average = {avg_val:.4f}\")\n",
    "            group_stats[f\"{key}_avg\"] = avg_val\n",
    "        else:\n",
    "            # For nested dictionary keys (like '1-49 %', '< 1 %', etc.)\n",
    "            for subkey in group[0][key]:\n",
    "                values = [r[key][subkey] for r in group]\n",
    "                avg_val = np.mean(values)\n",
    "                print(f\"  {key} -> {subkey}: values = {values}, average = {avg_val:.4f}\")\n",
    "                flat_key = f\"{key}_{subkey}\"\n",
    "                group_stats[f\"{flat_key}_avg\"] = avg_val\n",
    "    return group_stats\n",
    "\n",
    "group_size = 5\n",
    "averaged_stats = []\n",
    "\n",
    "for i in range(0, len(reports), group_size):\n",
    "    group = reports[i:i+group_size]\n",
    "    group_index = i // group_size\n",
    "    group_stats = average_report_group_with_print(group, group_index)\n",
    "    averaged_stats.append(group_stats)\n",
    "\n",
    "# Create a DataFrame from the averaged statistics.\n",
    "df_train = pd.DataFrame(averaged_stats)\n",
    "\n",
    "print(\"\\nFinal DataFrame with averaged values:\")\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing group 0 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.0, 0.0, 0.36363636363636365, 0.35260115606936415, 0.3742690058479532], average = 0.2181\n",
      "  1-49 % -> recall: values = [0.0, 0.0, 1.0, 1.0, 1.0], average = 0.6000\n",
      "  1-49 % -> f1-score: values = [0.0, 0.0, 0.5333333333333333, 0.5213675213675214, 0.5446808510638298], average = 0.3199\n",
      "  1-49 % -> support: values = [60.0, 63.0, 64.0, 61.0, 64.0], average = 62.4000\n",
      "  < 1 % -> precision: values = [0.3657142857142857, 0.3672316384180791, 0.0, 0.0, 0.0], average = 0.1466\n",
      "  < 1 % -> recall: values = [1.0, 1.0, 0.0, 0.0, 0.0], average = 0.4000\n",
      "  < 1 % -> f1-score: values = [0.5355648535564853, 0.5371900826446281, 0.0, 0.0, 0.0], average = 0.2146\n",
      "  < 1 % -> support: values = [64.0, 65.0, 58.0, 59.0, 58.0], average = 60.8000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [51.0, 49.0, 54.0, 53.0, 49.0], average = 51.2000\n",
      "  accuracy: values = [0.3657142857142857, 0.3672316384180791, 0.36363636363636365, 0.35260115606936415, 0.3742690058479532], average = 0.3647\n",
      "  macro avg -> precision: values = [0.1219047619047619, 0.1224105461393597, 0.12121212121212122, 0.11753371868978806, 0.12475633528265107], average = 0.1216\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.17852161785216178, 0.1790633608815427, 0.17777777777777778, 0.1737891737891738, 0.18156028368794327], average = 0.1781\n",
      "  macro avg -> support: values = [175.0, 177.0, 176.0, 173.0, 171.0], average = 174.4000\n",
      "  weighted avg -> precision: values = [0.1337469387755102, 0.13485907625522678, 0.1322314049586777, 0.1243275752614521, 0.14007728873841524], average = 0.1330\n",
      "  weighted avg -> recall: values = [0.3657142857142857, 0.3672316384180791, 0.36363636363636365, 0.35260115606936415, 0.3742690058479532], average = 0.3647\n",
      "  weighted avg -> f1-score: values = [0.19586371787208606, 0.19727319419153008, 0.19393939393939394, 0.18383479077120696, 0.20385716063207665], average = 0.1950\n",
      "  weighted avg -> support: values = [175.0, 177.0, 176.0, 173.0, 171.0], average = 174.4000\n",
      "\n",
      "Processing group 1 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.37142857142857144, 0.3532608695652174, 0.3567567567567568, 0.39204545454545453, 0.3641304347826087], average = 0.3675\n",
      "  1-49 % -> recall: values = [1.0, 1.0, 1.0, 1.0, 1.0], average = 1.0000\n",
      "  1-49 % -> f1-score: values = [0.5416666666666666, 0.5220883534136547, 0.5258964143426295, 0.563265306122449, 0.5338645418326693], average = 0.5374\n",
      "  1-49 % -> support: values = [65.0, 65.0, 66.0, 69.0, 67.0], average = 66.4000\n",
      "  < 1 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  < 1 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  < 1 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  < 1 % -> support: values = [59.0, 64.0, 63.0, 57.0, 65.0], average = 61.6000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [51.0, 55.0, 56.0, 50.0, 52.0], average = 52.8000\n",
      "  accuracy: values = [0.37142857142857144, 0.3532608695652174, 0.3567567567567568, 0.39204545454545453, 0.3641304347826087], average = 0.3675\n",
      "  macro avg -> precision: values = [0.12380952380952381, 0.1177536231884058, 0.11891891891891893, 0.13068181818181818, 0.1213768115942029], average = 0.1225\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.18055555555555555, 0.1740294511378849, 0.17529880478087648, 0.18775510204081633, 0.17795484727755642], average = 0.1791\n",
      "  macro avg -> support: values = [175.0, 184.0, 185.0, 176.0, 184.0], average = 180.8000\n",
      "  weighted avg -> precision: values = [0.13795918367346938, 0.12479324196597355, 0.12727538349159973, 0.15369963842975207, 0.13259097353497165], average = 0.1353\n",
      "  weighted avg -> recall: values = [0.37142857142857144, 0.3532608695652174, 0.3567567567567568, 0.39204545454545453, 0.3641304347826087], average = 0.3675\n",
      "  weighted avg -> f1-score: values = [0.20119047619047617, 0.1844333857167802, 0.187617099170884, 0.2208256029684601, 0.19439632773254803], average = 0.1977\n",
      "  weighted avg -> support: values = [175.0, 184.0, 185.0, 176.0, 184.0], average = 180.8000\n",
      "\n",
      "Processing group 2 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.3465909090909091, 0.0, 0.0, 0.0, 0.35], average = 0.1393\n",
      "  1-49 % -> recall: values = [1.0, 0.0, 0.0, 0.0, 1.0], average = 0.4000\n",
      "  1-49 % -> f1-score: values = [0.5147679324894515, 0.0, 0.0, 0.0, 0.5185185185185185], average = 0.2067\n",
      "  1-49 % -> support: values = [61.0, 61.0, 61.0, 62.0, 63.0], average = 61.6000\n",
      "  < 1 % -> precision: values = [0.0, 0.3595505617977528, 0.3651685393258427, 0.35, 0.0], average = 0.2149\n",
      "  < 1 % -> recall: values = [0.0, 1.0, 1.0, 1.0, 0.0], average = 0.6000\n",
      "  < 1 % -> f1-score: values = [0.0, 0.5289256198347108, 0.5349794238683128, 0.5185185185185185, 0.0], average = 0.3165\n",
      "  < 1 % -> support: values = [61.0, 64.0, 65.0, 63.0, 63.0], average = 63.2000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [54.0, 53.0, 52.0, 55.0, 54.0], average = 53.6000\n",
      "  accuracy: values = [0.3465909090909091, 0.3595505617977528, 0.3651685393258427, 0.35, 0.35], average = 0.3543\n",
      "  macro avg -> precision: values = [0.11553030303030304, 0.1198501872659176, 0.12172284644194757, 0.11666666666666665, 0.11666666666666665], average = 0.1181\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.17158931082981718, 0.1763085399449036, 0.17832647462277093, 0.1728395061728395, 0.1728395061728395], average = 0.1744\n",
      "  macro avg -> support: values = [176.0, 178.0, 178.0, 180.0, 180.0], average = 178.4000\n",
      "  weighted avg -> precision: values = [0.12012525826446283, 0.12927660648907965, 0.13334806211336953, 0.12249999999999998, 0.12249999999999998], average = 0.1255\n",
      "  weighted avg -> recall: values = [0.3465909090909091, 0.3595505617977528, 0.3651685393258427, 0.35, 0.35], average = 0.3543\n",
      "  weighted avg -> f1-score: values = [0.1784138856923667, 0.19017550376079487, 0.19535765478337264, 0.18148148148148147, 0.18148148148148147], average = 0.1854\n",
      "  weighted avg -> support: values = [176.0, 178.0, 178.0, 180.0, 180.0], average = 178.4000\n",
      "\n",
      "Processing group 3 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.3641304347826087, 0.0, 0.3615819209039548, 0.0, 0.0], average = 0.1451\n",
      "  1-49 % -> recall: values = [1.0, 0.0, 1.0, 0.0, 0.0], average = 0.4000\n",
      "  1-49 % -> f1-score: values = [0.5338645418326693, 0.0, 0.5311203319502075, 0.0, 0.0], average = 0.2130\n",
      "  1-49 % -> support: values = [67.0, 62.0, 64.0, 62.0, 65.0], average = 64.0000\n",
      "  < 1 % -> precision: values = [0.0, 0.36813186813186816, 0.0, 0.36312849162011174, 0.3626373626373626], average = 0.2188\n",
      "  < 1 % -> recall: values = [0.0, 1.0, 0.0, 1.0, 1.0], average = 0.6000\n",
      "  < 1 % -> f1-score: values = [0.0, 0.5381526104417671, 0.0, 0.5327868852459017, 0.532258064516129], average = 0.3206\n",
      "  < 1 % -> support: values = [65.0, 67.0, 61.0, 65.0, 66.0], average = 64.8000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [52.0, 53.0, 52.0, 52.0, 51.0], average = 52.0000\n",
      "  accuracy: values = [0.3641304347826087, 0.36813186813186816, 0.3615819209039548, 0.36312849162011174, 0.3626373626373626], average = 0.3639\n",
      "  macro avg -> precision: values = [0.1213768115942029, 0.12271062271062272, 0.12052730696798493, 0.12104283054003724, 0.12087912087912088], average = 0.1213\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.17795484727755642, 0.17938420348058903, 0.17704011065006917, 0.17759562841530055, 0.17741935483870966], average = 0.1779\n",
      "  macro avg -> support: values = [184.0, 182.0, 177.0, 179.0, 182.0], average = 180.8000\n",
      "  weighted avg -> precision: values = [0.13259097353497165, 0.13552107233425917, 0.13074148552459383, 0.13186230142629757, 0.13150585678058205], average = 0.1324\n",
      "  weighted avg -> recall: values = [0.3641304347826087, 0.36813186813186816, 0.3615819209039548, 0.36312849162011174, 0.3626373626373626], average = 0.3639\n",
      "  weighted avg -> f1-score: values = [0.19439632773254803, 0.19811112582196921, 0.19204350985770213, 0.19347009799432185, 0.19301666075859622], average = 0.1942\n",
      "  weighted avg -> support: values = [184.0, 182.0, 177.0, 179.0, 182.0], average = 180.8000\n",
      "\n",
      "Processing group 4 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.0, 0.3707865168539326, 0.36416184971098264, 0.0, 0.0], average = 0.1470\n",
      "  1-49 % -> recall: values = [0.0, 1.0, 1.0, 0.0, 0.0], average = 0.4000\n",
      "  1-49 % -> f1-score: values = [0.0, 0.5409836065573771, 0.5338983050847458, 0.0, 0.0], average = 0.2150\n",
      "  1-49 % -> support: values = [61.0, 66.0, 63.0, 60.0, 62.0], average = 62.4000\n",
      "  < 1 % -> precision: values = [0.37222222222222223, 0.0, 0.0, 0.3630952380952381, 0.3615819209039548], average = 0.2194\n",
      "  < 1 % -> recall: values = [1.0, 0.0, 0.0, 1.0, 1.0], average = 0.6000\n",
      "  < 1 % -> f1-score: values = [0.5425101214574899, 0.0, 0.0, 0.5327510917030568, 0.5311203319502075], average = 0.3213\n",
      "  < 1 % -> support: values = [67.0, 62.0, 62.0, 61.0, 64.0], average = 63.2000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [52.0, 50.0, 48.0, 47.0, 51.0], average = 49.6000\n",
      "  accuracy: values = [0.37222222222222223, 0.3707865168539326, 0.36416184971098264, 0.3630952380952381, 0.3615819209039548], average = 0.3664\n",
      "  macro avg -> precision: values = [0.12407407407407407, 0.12359550561797754, 0.12138728323699421, 0.12103174603174603, 0.12052730696798493], average = 0.1221\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.18083670715249664, 0.18032786885245902, 0.17796610169491525, 0.17758369723435227, 0.17704011065006917], average = 0.1788\n",
      "  macro avg -> support: values = [180.0, 178.0, 173.0, 168.0, 177.0], average = 175.2000\n",
      "  weighted avg -> precision: values = [0.13854938271604939, 0.13748264108067165, 0.13261385278492432, 0.13183815192743764, 0.13074148552459383], average = 0.1342\n",
      "  weighted avg -> recall: values = [0.37222222222222223, 0.3707865168539326, 0.36416184971098264, 0.3630952380952381, 0.3615819209039548], average = 0.3664\n",
      "  weighted avg -> f1-score: values = [0.20193432298695457, 0.2005894271504881, 0.19442539433721956, 0.19343938448741943, 0.19204350985770213], average = 0.1965\n",
      "  weighted avg -> support: values = [180.0, 178.0, 173.0, 168.0, 177.0], average = 175.2000\n",
      "\n",
      "Final DataFrame with averaged values:\n",
      "   1-49 %_precision_avg  1-49 %_recall_avg  1-49 %_f1-score_avg  \\\n",
      "0              0.218101                0.6             0.319876   \n",
      "1              0.367524                1.0             0.537356   \n",
      "2              0.139318                0.4             0.206657   \n",
      "3              0.145142                0.4             0.212997   \n",
      "4              0.146990                0.4             0.214976   \n",
      "\n",
      "   1-49 %_support_avg  < 1 %_precision_avg  < 1 %_recall_avg  \\\n",
      "0                62.4             0.146589               0.4   \n",
      "1                66.4             0.000000               0.0   \n",
      "2                61.6             0.214944               0.6   \n",
      "3                64.0             0.218780               0.6   \n",
      "4                62.4             0.219380               0.6   \n",
      "\n",
      "   < 1 %_f1-score_avg  < 1 %_support_avg  >=50 %_precision_avg  \\\n",
      "0            0.214551               60.8                   0.0   \n",
      "1            0.000000               61.6                   0.0   \n",
      "2            0.316485               63.2                   0.0   \n",
      "3            0.320640               64.8                   0.0   \n",
      "4            0.321276               63.2                   0.0   \n",
      "\n",
      "   >=50 %_recall_avg  ...  >=50 %_support_avg  accuracy_avg  \\\n",
      "0                0.0  ...                51.2      0.364690   \n",
      "1                0.0  ...                52.8      0.367524   \n",
      "2                0.0  ...                53.6      0.354262   \n",
      "3                0.0  ...                52.0      0.363922   \n",
      "4                0.0  ...                49.6      0.366370   \n",
      "\n",
      "   macro avg_precision_avg  macro avg_recall_avg  macro avg_f1-score_avg  \\\n",
      "0                 0.121563              0.333333                0.178142   \n",
      "1                 0.122508              0.333333                0.179119   \n",
      "2                 0.118087              0.333333                0.174381   \n",
      "3                 0.121307              0.333333                0.177879   \n",
      "4                 0.122123              0.333333                0.178751   \n",
      "\n",
      "   macro avg_support_avg  weighted avg_precision_avg  weighted avg_recall_avg  \\\n",
      "0                  174.4                    0.133048                 0.364690   \n",
      "1                  180.8                    0.135264                 0.367524   \n",
      "2                  178.4                    0.125550                 0.354262   \n",
      "3                  180.8                    0.132444                 0.363922   \n",
      "4                  175.2                    0.134245                 0.366370   \n",
      "\n",
      "   weighted avg_f1-score_avg  weighted avg_support_avg  \n",
      "0                   0.194954                     174.4  \n",
      "1                   0.197693                     180.8  \n",
      "2                   0.185382                     178.4  \n",
      "3                   0.194208                     180.8  \n",
      "4                   0.196486                     175.2  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Your list of dictionaries (only a few items are shown for brevity; include all in your actual code)\n",
    "report = val_classification_reports\n",
    "\n",
    "def average_report_group_with_print(group, group_index):\n",
    "    print(f\"\\nProcessing group {group_index} (with {len(group)} items):\")\n",
    "    group_stats = {}\n",
    "    for key in group[0]:\n",
    "        if key == 'accuracy':\n",
    "            values = [r[key] for r in group]\n",
    "            avg_val = np.mean(values)\n",
    "            print(f\"  {key}: values = {values}, average = {avg_val:.4f}\")\n",
    "            group_stats[f\"{key}_avg\"] = avg_val\n",
    "        else:\n",
    "            # For nested dictionary keys (like '1-49 %', '< 1 %', etc.)\n",
    "            for subkey in group[0][key]:\n",
    "                values = [r[key][subkey] for r in group]\n",
    "                avg_val = np.mean(values)\n",
    "                print(f\"  {key} -> {subkey}: values = {values}, average = {avg_val:.4f}\")\n",
    "                flat_key = f\"{key}_{subkey}\"\n",
    "                group_stats[f\"{flat_key}_avg\"] = avg_val\n",
    "    return group_stats\n",
    "\n",
    "group_size = 5\n",
    "averaged_stats = []\n",
    "\n",
    "for i in range(0, len(reports), group_size):\n",
    "    group = reports[i:i+group_size]\n",
    "    group_index = i // group_size\n",
    "    group_stats = average_report_group_with_print(group, group_index)\n",
    "    averaged_stats.append(group_stats)\n",
    "\n",
    "# Create a DataFrame from the averaged statistics.\n",
    "df_val = pd.DataFrame(averaged_stats)\n",
    "\n",
    "print(\"\\nFinal DataFrame with averaged values:\")\n",
    "print(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing group 0 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.0, 0.0, 0.36363636363636365, 0.35260115606936415, 0.3742690058479532], average = 0.2181\n",
      "  1-49 % -> recall: values = [0.0, 0.0, 1.0, 1.0, 1.0], average = 0.6000\n",
      "  1-49 % -> f1-score: values = [0.0, 0.0, 0.5333333333333333, 0.5213675213675214, 0.5446808510638298], average = 0.3199\n",
      "  1-49 % -> support: values = [60.0, 63.0, 64.0, 61.0, 64.0], average = 62.4000\n",
      "  < 1 % -> precision: values = [0.3657142857142857, 0.3672316384180791, 0.0, 0.0, 0.0], average = 0.1466\n",
      "  < 1 % -> recall: values = [1.0, 1.0, 0.0, 0.0, 0.0], average = 0.4000\n",
      "  < 1 % -> f1-score: values = [0.5355648535564853, 0.5371900826446281, 0.0, 0.0, 0.0], average = 0.2146\n",
      "  < 1 % -> support: values = [64.0, 65.0, 58.0, 59.0, 58.0], average = 60.8000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [51.0, 49.0, 54.0, 53.0, 49.0], average = 51.2000\n",
      "  accuracy: values = [0.3657142857142857, 0.3672316384180791, 0.36363636363636365, 0.35260115606936415, 0.3742690058479532], average = 0.3647\n",
      "  macro avg -> precision: values = [0.1219047619047619, 0.1224105461393597, 0.12121212121212122, 0.11753371868978806, 0.12475633528265107], average = 0.1216\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.17852161785216178, 0.1790633608815427, 0.17777777777777778, 0.1737891737891738, 0.18156028368794327], average = 0.1781\n",
      "  macro avg -> support: values = [175.0, 177.0, 176.0, 173.0, 171.0], average = 174.4000\n",
      "  weighted avg -> precision: values = [0.1337469387755102, 0.13485907625522678, 0.1322314049586777, 0.1243275752614521, 0.14007728873841524], average = 0.1330\n",
      "  weighted avg -> recall: values = [0.3657142857142857, 0.3672316384180791, 0.36363636363636365, 0.35260115606936415, 0.3742690058479532], average = 0.3647\n",
      "  weighted avg -> f1-score: values = [0.19586371787208606, 0.19727319419153008, 0.19393939393939394, 0.18383479077120696, 0.20385716063207665], average = 0.1950\n",
      "  weighted avg -> support: values = [175.0, 177.0, 176.0, 173.0, 171.0], average = 174.4000\n",
      "\n",
      "Processing group 1 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.37142857142857144, 0.3532608695652174, 0.3567567567567568, 0.39204545454545453, 0.3641304347826087], average = 0.3675\n",
      "  1-49 % -> recall: values = [1.0, 1.0, 1.0, 1.0, 1.0], average = 1.0000\n",
      "  1-49 % -> f1-score: values = [0.5416666666666666, 0.5220883534136547, 0.5258964143426295, 0.563265306122449, 0.5338645418326693], average = 0.5374\n",
      "  1-49 % -> support: values = [65.0, 65.0, 66.0, 69.0, 67.0], average = 66.4000\n",
      "  < 1 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  < 1 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  < 1 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  < 1 % -> support: values = [59.0, 64.0, 63.0, 57.0, 65.0], average = 61.6000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [51.0, 55.0, 56.0, 50.0, 52.0], average = 52.8000\n",
      "  accuracy: values = [0.37142857142857144, 0.3532608695652174, 0.3567567567567568, 0.39204545454545453, 0.3641304347826087], average = 0.3675\n",
      "  macro avg -> precision: values = [0.12380952380952381, 0.1177536231884058, 0.11891891891891893, 0.13068181818181818, 0.1213768115942029], average = 0.1225\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.18055555555555555, 0.1740294511378849, 0.17529880478087648, 0.18775510204081633, 0.17795484727755642], average = 0.1791\n",
      "  macro avg -> support: values = [175.0, 184.0, 185.0, 176.0, 184.0], average = 180.8000\n",
      "  weighted avg -> precision: values = [0.13795918367346938, 0.12479324196597355, 0.12727538349159973, 0.15369963842975207, 0.13259097353497165], average = 0.1353\n",
      "  weighted avg -> recall: values = [0.37142857142857144, 0.3532608695652174, 0.3567567567567568, 0.39204545454545453, 0.3641304347826087], average = 0.3675\n",
      "  weighted avg -> f1-score: values = [0.20119047619047617, 0.1844333857167802, 0.187617099170884, 0.2208256029684601, 0.19439632773254803], average = 0.1977\n",
      "  weighted avg -> support: values = [175.0, 184.0, 185.0, 176.0, 184.0], average = 180.8000\n",
      "\n",
      "Processing group 2 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.3465909090909091, 0.0, 0.0, 0.0, 0.35], average = 0.1393\n",
      "  1-49 % -> recall: values = [1.0, 0.0, 0.0, 0.0, 1.0], average = 0.4000\n",
      "  1-49 % -> f1-score: values = [0.5147679324894515, 0.0, 0.0, 0.0, 0.5185185185185185], average = 0.2067\n",
      "  1-49 % -> support: values = [61.0, 61.0, 61.0, 62.0, 63.0], average = 61.6000\n",
      "  < 1 % -> precision: values = [0.0, 0.3595505617977528, 0.3651685393258427, 0.35, 0.0], average = 0.2149\n",
      "  < 1 % -> recall: values = [0.0, 1.0, 1.0, 1.0, 0.0], average = 0.6000\n",
      "  < 1 % -> f1-score: values = [0.0, 0.5289256198347108, 0.5349794238683128, 0.5185185185185185, 0.0], average = 0.3165\n",
      "  < 1 % -> support: values = [61.0, 64.0, 65.0, 63.0, 63.0], average = 63.2000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [54.0, 53.0, 52.0, 55.0, 54.0], average = 53.6000\n",
      "  accuracy: values = [0.3465909090909091, 0.3595505617977528, 0.3651685393258427, 0.35, 0.35], average = 0.3543\n",
      "  macro avg -> precision: values = [0.11553030303030304, 0.1198501872659176, 0.12172284644194757, 0.11666666666666665, 0.11666666666666665], average = 0.1181\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.17158931082981718, 0.1763085399449036, 0.17832647462277093, 0.1728395061728395, 0.1728395061728395], average = 0.1744\n",
      "  macro avg -> support: values = [176.0, 178.0, 178.0, 180.0, 180.0], average = 178.4000\n",
      "  weighted avg -> precision: values = [0.12012525826446283, 0.12927660648907965, 0.13334806211336953, 0.12249999999999998, 0.12249999999999998], average = 0.1255\n",
      "  weighted avg -> recall: values = [0.3465909090909091, 0.3595505617977528, 0.3651685393258427, 0.35, 0.35], average = 0.3543\n",
      "  weighted avg -> f1-score: values = [0.1784138856923667, 0.19017550376079487, 0.19535765478337264, 0.18148148148148147, 0.18148148148148147], average = 0.1854\n",
      "  weighted avg -> support: values = [176.0, 178.0, 178.0, 180.0, 180.0], average = 178.4000\n",
      "\n",
      "Processing group 3 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.3641304347826087, 0.0, 0.3615819209039548, 0.0, 0.0], average = 0.1451\n",
      "  1-49 % -> recall: values = [1.0, 0.0, 1.0, 0.0, 0.0], average = 0.4000\n",
      "  1-49 % -> f1-score: values = [0.5338645418326693, 0.0, 0.5311203319502075, 0.0, 0.0], average = 0.2130\n",
      "  1-49 % -> support: values = [67.0, 62.0, 64.0, 62.0, 65.0], average = 64.0000\n",
      "  < 1 % -> precision: values = [0.0, 0.36813186813186816, 0.0, 0.36312849162011174, 0.3626373626373626], average = 0.2188\n",
      "  < 1 % -> recall: values = [0.0, 1.0, 0.0, 1.0, 1.0], average = 0.6000\n",
      "  < 1 % -> f1-score: values = [0.0, 0.5381526104417671, 0.0, 0.5327868852459017, 0.532258064516129], average = 0.3206\n",
      "  < 1 % -> support: values = [65.0, 67.0, 61.0, 65.0, 66.0], average = 64.8000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [52.0, 53.0, 52.0, 52.0, 51.0], average = 52.0000\n",
      "  accuracy: values = [0.3641304347826087, 0.36813186813186816, 0.3615819209039548, 0.36312849162011174, 0.3626373626373626], average = 0.3639\n",
      "  macro avg -> precision: values = [0.1213768115942029, 0.12271062271062272, 0.12052730696798493, 0.12104283054003724, 0.12087912087912088], average = 0.1213\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.17795484727755642, 0.17938420348058903, 0.17704011065006917, 0.17759562841530055, 0.17741935483870966], average = 0.1779\n",
      "  macro avg -> support: values = [184.0, 182.0, 177.0, 179.0, 182.0], average = 180.8000\n",
      "  weighted avg -> precision: values = [0.13259097353497165, 0.13552107233425917, 0.13074148552459383, 0.13186230142629757, 0.13150585678058205], average = 0.1324\n",
      "  weighted avg -> recall: values = [0.3641304347826087, 0.36813186813186816, 0.3615819209039548, 0.36312849162011174, 0.3626373626373626], average = 0.3639\n",
      "  weighted avg -> f1-score: values = [0.19439632773254803, 0.19811112582196921, 0.19204350985770213, 0.19347009799432185, 0.19301666075859622], average = 0.1942\n",
      "  weighted avg -> support: values = [184.0, 182.0, 177.0, 179.0, 182.0], average = 180.8000\n",
      "\n",
      "Processing group 4 (with 5 items):\n",
      "  1-49 % -> precision: values = [0.0, 0.3707865168539326, 0.36416184971098264, 0.0, 0.0], average = 0.1470\n",
      "  1-49 % -> recall: values = [0.0, 1.0, 1.0, 0.0, 0.0], average = 0.4000\n",
      "  1-49 % -> f1-score: values = [0.0, 0.5409836065573771, 0.5338983050847458, 0.0, 0.0], average = 0.2150\n",
      "  1-49 % -> support: values = [61.0, 66.0, 63.0, 60.0, 62.0], average = 62.4000\n",
      "  < 1 % -> precision: values = [0.37222222222222223, 0.0, 0.0, 0.3630952380952381, 0.3615819209039548], average = 0.2194\n",
      "  < 1 % -> recall: values = [1.0, 0.0, 0.0, 1.0, 1.0], average = 0.6000\n",
      "  < 1 % -> f1-score: values = [0.5425101214574899, 0.0, 0.0, 0.5327510917030568, 0.5311203319502075], average = 0.3213\n",
      "  < 1 % -> support: values = [67.0, 62.0, 62.0, 61.0, 64.0], average = 63.2000\n",
      "  >=50 % -> precision: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> recall: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> f1-score: values = [0.0, 0.0, 0.0, 0.0, 0.0], average = 0.0000\n",
      "  >=50 % -> support: values = [52.0, 50.0, 48.0, 47.0, 51.0], average = 49.6000\n",
      "  accuracy: values = [0.37222222222222223, 0.3707865168539326, 0.36416184971098264, 0.3630952380952381, 0.3615819209039548], average = 0.3664\n",
      "  macro avg -> precision: values = [0.12407407407407407, 0.12359550561797754, 0.12138728323699421, 0.12103174603174603, 0.12052730696798493], average = 0.1221\n",
      "  macro avg -> recall: values = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], average = 0.3333\n",
      "  macro avg -> f1-score: values = [0.18083670715249664, 0.18032786885245902, 0.17796610169491525, 0.17758369723435227, 0.17704011065006917], average = 0.1788\n",
      "  macro avg -> support: values = [180.0, 178.0, 173.0, 168.0, 177.0], average = 175.2000\n",
      "  weighted avg -> precision: values = [0.13854938271604939, 0.13748264108067165, 0.13261385278492432, 0.13183815192743764, 0.13074148552459383], average = 0.1342\n",
      "  weighted avg -> recall: values = [0.37222222222222223, 0.3707865168539326, 0.36416184971098264, 0.3630952380952381, 0.3615819209039548], average = 0.3664\n",
      "  weighted avg -> f1-score: values = [0.20193432298695457, 0.2005894271504881, 0.19442539433721956, 0.19343938448741943, 0.19204350985770213], average = 0.1965\n",
      "  weighted avg -> support: values = [180.0, 178.0, 173.0, 168.0, 177.0], average = 175.2000\n",
      "\n",
      "Final DataFrame with averaged values:\n",
      "   1-49 %_precision_avg  1-49 %_recall_avg  1-49 %_f1-score_avg  \\\n",
      "0              0.218101                0.6             0.319876   \n",
      "1              0.367524                1.0             0.537356   \n",
      "2              0.139318                0.4             0.206657   \n",
      "3              0.145142                0.4             0.212997   \n",
      "4              0.146990                0.4             0.214976   \n",
      "\n",
      "   1-49 %_support_avg  < 1 %_precision_avg  < 1 %_recall_avg  \\\n",
      "0                62.4             0.146589               0.4   \n",
      "1                66.4             0.000000               0.0   \n",
      "2                61.6             0.214944               0.6   \n",
      "3                64.0             0.218780               0.6   \n",
      "4                62.4             0.219380               0.6   \n",
      "\n",
      "   < 1 %_f1-score_avg  < 1 %_support_avg  >=50 %_precision_avg  \\\n",
      "0            0.214551               60.8                   0.0   \n",
      "1            0.000000               61.6                   0.0   \n",
      "2            0.316485               63.2                   0.0   \n",
      "3            0.320640               64.8                   0.0   \n",
      "4            0.321276               63.2                   0.0   \n",
      "\n",
      "   >=50 %_recall_avg  ...  >=50 %_support_avg  accuracy_avg  \\\n",
      "0                0.0  ...                51.2      0.364690   \n",
      "1                0.0  ...                52.8      0.367524   \n",
      "2                0.0  ...                53.6      0.354262   \n",
      "3                0.0  ...                52.0      0.363922   \n",
      "4                0.0  ...                49.6      0.366370   \n",
      "\n",
      "   macro avg_precision_avg  macro avg_recall_avg  macro avg_f1-score_avg  \\\n",
      "0                 0.121563              0.333333                0.178142   \n",
      "1                 0.122508              0.333333                0.179119   \n",
      "2                 0.118087              0.333333                0.174381   \n",
      "3                 0.121307              0.333333                0.177879   \n",
      "4                 0.122123              0.333333                0.178751   \n",
      "\n",
      "   macro avg_support_avg  weighted avg_precision_avg  weighted avg_recall_avg  \\\n",
      "0                  174.4                    0.133048                 0.364690   \n",
      "1                  180.8                    0.135264                 0.367524   \n",
      "2                  178.4                    0.125550                 0.354262   \n",
      "3                  180.8                    0.132444                 0.363922   \n",
      "4                  175.2                    0.134245                 0.366370   \n",
      "\n",
      "   weighted avg_f1-score_avg  weighted avg_support_avg  \n",
      "0                   0.194954                     174.4  \n",
      "1                   0.197693                     180.8  \n",
      "2                   0.185382                     178.4  \n",
      "3                   0.194208                     180.8  \n",
      "4                   0.196486                     175.2  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Your list of dictionaries (only a few items are shown for brevity; include all in your actual code)\n",
    "report = test_scores\n",
    "\n",
    "def average_report_group_with_print(group, group_index):\n",
    "    print(f\"\\nProcessing group {group_index} (with {len(group)} items):\")\n",
    "    group_stats = {}\n",
    "    for key in group[0]:\n",
    "        if key == 'accuracy':\n",
    "            values = [r[key] for r in group]\n",
    "            avg_val = np.mean(values)\n",
    "            print(f\"  {key}: values = {values}, average = {avg_val:.4f}\")\n",
    "            group_stats[f\"{key}_avg\"] = avg_val\n",
    "        else:\n",
    "            # For nested dictionary keys (like '1-49 %', '< 1 %', etc.)\n",
    "            for subkey in group[0][key]:\n",
    "                values = [r[key][subkey] for r in group]\n",
    "                avg_val = np.mean(values)\n",
    "                print(f\"  {key} -> {subkey}: values = {values}, average = {avg_val:.4f}\")\n",
    "                flat_key = f\"{key}_{subkey}\"\n",
    "                group_stats[f\"{flat_key}_avg\"] = avg_val\n",
    "    return group_stats\n",
    "\n",
    "group_size = 5\n",
    "averaged_stats = []\n",
    "\n",
    "for i in range(0, len(reports), group_size):\n",
    "    group = reports[i:i+group_size]\n",
    "    group_index = i // group_size\n",
    "    group_stats = average_report_group_with_print(group, group_index)\n",
    "    averaged_stats.append(group_stats)\n",
    "\n",
    "# Create a DataFrame from the averaged statistics.\n",
    "df_test = pd.DataFrame(averaged_stats)\n",
    "\n",
    "print(\"\\nFinal DataFrame with averaged values:\")\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index_train  1-49 %_precision_avg_train  1-49 %_recall_avg_train  \\\n",
      "0            0                    0.218101                      0.6   \n",
      "1            1                    0.367524                      1.0   \n",
      "2            2                    0.139318                      0.4   \n",
      "3            3                    0.145142                      0.4   \n",
      "4            4                    0.146990                      0.4   \n",
      "\n",
      "   1-49 %_f1-score_avg_train  1-49 %_support_avg_train  \\\n",
      "0                   0.319876                      62.4   \n",
      "1                   0.537356                      66.4   \n",
      "2                   0.206657                      61.6   \n",
      "3                   0.212997                      64.0   \n",
      "4                   0.214976                      62.4   \n",
      "\n",
      "   < 1 %_precision_avg_train  < 1 %_recall_avg_train  \\\n",
      "0                   0.146589                     0.4   \n",
      "1                   0.000000                     0.0   \n",
      "2                   0.214944                     0.6   \n",
      "3                   0.218780                     0.6   \n",
      "4                   0.219380                     0.6   \n",
      "\n",
      "   < 1 %_f1-score_avg_train  < 1 %_support_avg_train  \\\n",
      "0                  0.214551                     60.8   \n",
      "1                  0.000000                     61.6   \n",
      "2                  0.316485                     63.2   \n",
      "3                  0.320640                     64.8   \n",
      "4                  0.321276                     63.2   \n",
      "\n",
      "   >=50 %_precision_avg_train  ...  >=50 %_support_avg_test  \\\n",
      "0                         0.0  ...                     51.2   \n",
      "1                         0.0  ...                     52.8   \n",
      "2                         0.0  ...                     53.6   \n",
      "3                         0.0  ...                     52.0   \n",
      "4                         0.0  ...                     49.6   \n",
      "\n",
      "   accuracy_avg_test  macro avg_precision_avg_test  macro avg_recall_avg_test  \\\n",
      "0           0.364690                      0.121563                   0.333333   \n",
      "1           0.367524                      0.122508                   0.333333   \n",
      "2           0.354262                      0.118087                   0.333333   \n",
      "3           0.363922                      0.121307                   0.333333   \n",
      "4           0.366370                      0.122123                   0.333333   \n",
      "\n",
      "   macro avg_f1-score_avg_test  macro avg_support_avg_test  \\\n",
      "0                     0.178142                       174.4   \n",
      "1                     0.179119                       180.8   \n",
      "2                     0.174381                       178.4   \n",
      "3                     0.177879                       180.8   \n",
      "4                     0.178751                       175.2   \n",
      "\n",
      "   weighted avg_precision_avg_test  weighted avg_recall_avg_test  \\\n",
      "0                         0.133048                      0.364690   \n",
      "1                         0.135264                      0.367524   \n",
      "2                         0.125550                      0.354262   \n",
      "3                         0.132444                      0.363922   \n",
      "4                         0.134245                      0.366370   \n",
      "\n",
      "   weighted avg_f1-score_avg_test  weighted avg_support_avg_test  \n",
      "0                        0.194954                          174.4  \n",
      "1                        0.197693                          180.8  \n",
      "2                        0.185382                          178.4  \n",
      "3                        0.194208                          180.8  \n",
      "4                        0.196486                          175.2  \n",
      "\n",
      "[5 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train=df_train.reset_index()\n",
    "df_val=df_val.reset_index()\n",
    "df_test=df_test.reset_index()\n",
    "'''\n",
    "df_train.columns = [\"Total number of patients\", \"< 1 %\", \"1-49 %\", \">=50 %\"]\n",
    "df_val .columns = [\"Total number of patients\", \"< 1 %\", \"1-49 %\", \">=50 %\"]\n",
    "df_test.columns = [\"Total number of patients\", \"< 1 %\", \"1-49 %\", \">=50 %\"]\n",
    "'''\n",
    "\n",
    "\n",
    "df_train_prefixed = df_train.add_suffix(\"_train\")\n",
    "df_val_prefixed   = df_val.add_suffix(\"_val\")\n",
    "df_test_prefixed  = df_test.add_suffix(\"_test\")\n",
    "\n",
    "df_final = pd.concat([df_train_prefixed, df_val_prefixed, df_test_prefixed], axis=1)\n",
    "print(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reports: 25\n",
      "\n",
      "Metric '1-49 %' -> 'precision':\n",
      "  Values: [0.0, 0.0, 0.36363636363636365, 0.35260115606936415, 0.3742690058479532, 0.37142857142857144, 0.3532608695652174, 0.3567567567567568, 0.39204545454545453, 0.3641304347826087, 0.3465909090909091, 0.0, 0.0, 0.0, 0.35, 0.3641304347826087, 0.0, 0.3615819209039548, 0.0, 0.0, 0.0, 0.3707865168539326, 0.36416184971098264, 0.0, 0.0]\n",
      "  Average = 0.2034, CI = 0.0737\n",
      "\n",
      "Metric '1-49 %' -> 'recall':\n",
      "  Values: [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "  Average = 0.5600, CI = 0.2026\n",
      "\n",
      "Metric '1-49 %' -> 'f1-score':\n",
      "  Values: [0.0, 0.0, 0.5333333333333333, 0.5213675213675214, 0.5446808510638298, 0.5416666666666666, 0.5220883534136547, 0.5258964143426295, 0.563265306122449, 0.5338645418326693, 0.5147679324894515, 0.0, 0.0, 0.0, 0.5185185185185185, 0.5338645418326693, 0.0, 0.5311203319502075, 0.0, 0.0, 0.0, 0.5409836065573771, 0.5338983050847458, 0.0, 0.0]\n",
      "  Average = 0.2984, CI = 0.1080\n",
      "\n",
      "Metric '1-49 %' -> 'support':\n",
      "  Values: [60.0, 63.0, 64.0, 61.0, 64.0, 65.0, 65.0, 66.0, 69.0, 67.0, 61.0, 61.0, 61.0, 62.0, 63.0, 67.0, 62.0, 64.0, 62.0, 65.0, 61.0, 66.0, 63.0, 60.0, 62.0]\n",
      "  Average = 63.3600, CI = 0.9653\n",
      "\n",
      "Metric '< 1 %' -> 'precision':\n",
      "  Values: [0.3657142857142857, 0.3672316384180791, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3595505617977528, 0.3651685393258427, 0.35, 0.0, 0.0, 0.36813186813186816, 0.0, 0.36312849162011174, 0.3626373626373626, 0.37222222222222223, 0.0, 0.0, 0.3630952380952381, 0.3615819209039548]\n",
      "  Average = 0.1599, CI = 0.0737\n",
      "\n",
      "Metric '< 1 %' -> 'recall':\n",
      "  Values: [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]\n",
      "  Average = 0.4400, CI = 0.2026\n",
      "\n",
      "Metric '< 1 %' -> 'f1-score':\n",
      "  Values: [0.5355648535564853, 0.5371900826446281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5289256198347108, 0.5349794238683128, 0.5185185185185185, 0.0, 0.0, 0.5381526104417671, 0.0, 0.5327868852459017, 0.532258064516129, 0.5425101214574899, 0.0, 0.0, 0.5327510917030568, 0.5311203319502075]\n",
      "  Average = 0.2346, CI = 0.1081\n",
      "\n",
      "Metric '< 1 %' -> 'support':\n",
      "  Values: [64.0, 65.0, 58.0, 59.0, 58.0, 59.0, 64.0, 63.0, 57.0, 65.0, 61.0, 64.0, 65.0, 63.0, 63.0, 65.0, 67.0, 61.0, 65.0, 66.0, 67.0, 62.0, 62.0, 61.0, 64.0]\n",
      "  Average = 62.7200, CI = 1.1403\n",
      "\n",
      "Metric '>=50 %' -> 'precision':\n",
      "  Values: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Average = 0.0000, CI = 0.0000\n",
      "\n",
      "Metric '>=50 %' -> 'recall':\n",
      "  Values: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Average = 0.0000, CI = 0.0000\n",
      "\n",
      "Metric '>=50 %' -> 'f1-score':\n",
      "  Values: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Average = 0.0000, CI = 0.0000\n",
      "\n",
      "Metric '>=50 %' -> 'support':\n",
      "  Values: [51.0, 49.0, 54.0, 53.0, 49.0, 51.0, 55.0, 56.0, 50.0, 52.0, 54.0, 53.0, 52.0, 55.0, 54.0, 52.0, 53.0, 52.0, 52.0, 51.0, 52.0, 50.0, 48.0, 47.0, 51.0]\n",
      "  Average = 51.8400, CI = 0.8920\n",
      "\n",
      "Metric 'accuracy':\n",
      "  Values: [0.3657142857142857, 0.3672316384180791, 0.36363636363636365, 0.35260115606936415, 0.3742690058479532, 0.37142857142857144, 0.3532608695652174, 0.3567567567567568, 0.39204545454545453, 0.3641304347826087, 0.3465909090909091, 0.3595505617977528, 0.3651685393258427, 0.35, 0.35, 0.3641304347826087, 0.36813186813186816, 0.3615819209039548, 0.36312849162011174, 0.3626373626373626, 0.37222222222222223, 0.3707865168539326, 0.36416184971098264, 0.3630952380952381, 0.3615819209039548]\n",
      "  Average = 0.3634, CI = 0.0038\n",
      "\n",
      "Metric 'macro avg' -> 'precision':\n",
      "  Values: [0.1219047619047619, 0.1224105461393597, 0.12121212121212122, 0.11753371868978806, 0.12475633528265107, 0.12380952380952381, 0.1177536231884058, 0.11891891891891893, 0.13068181818181818, 0.1213768115942029, 0.11553030303030304, 0.1198501872659176, 0.12172284644194757, 0.11666666666666665, 0.11666666666666665, 0.1213768115942029, 0.12271062271062272, 0.12052730696798493, 0.12104283054003724, 0.12087912087912088, 0.12407407407407407, 0.12359550561797754, 0.12138728323699421, 0.12103174603174603, 0.12052730696798493]\n",
      "  Average = 0.1211, CI = 0.0013\n",
      "\n",
      "Metric 'macro avg' -> 'recall':\n",
      "  Values: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "  Average = 0.3333, CI = 0.0000\n",
      "\n",
      "Metric 'macro avg' -> 'f1-score':\n",
      "  Values: [0.17852161785216178, 0.1790633608815427, 0.17777777777777778, 0.1737891737891738, 0.18156028368794327, 0.18055555555555555, 0.1740294511378849, 0.17529880478087648, 0.18775510204081633, 0.17795484727755642, 0.17158931082981718, 0.1763085399449036, 0.17832647462277093, 0.1728395061728395, 0.1728395061728395, 0.17795484727755642, 0.17938420348058903, 0.17704011065006917, 0.17759562841530055, 0.17741935483870966, 0.18083670715249664, 0.18032786885245902, 0.17796610169491525, 0.17758369723435227, 0.17704011065006917]\n",
      "  Average = 0.1777, CI = 0.0013\n",
      "\n",
      "Metric 'macro avg' -> 'support':\n",
      "  Values: [175.0, 177.0, 176.0, 173.0, 171.0, 175.0, 184.0, 185.0, 176.0, 184.0, 176.0, 178.0, 178.0, 180.0, 180.0, 184.0, 182.0, 177.0, 179.0, 182.0, 180.0, 178.0, 173.0, 168.0, 177.0]\n",
      "  Average = 177.9200, CI = 1.7007\n",
      "\n",
      "Metric 'weighted avg' -> 'precision':\n",
      "  Values: [0.1337469387755102, 0.13485907625522678, 0.1322314049586777, 0.1243275752614521, 0.14007728873841524, 0.13795918367346938, 0.12479324196597355, 0.12727538349159973, 0.15369963842975207, 0.13259097353497165, 0.12012525826446283, 0.12927660648907965, 0.13334806211336953, 0.12249999999999998, 0.12249999999999998, 0.13259097353497165, 0.13552107233425917, 0.13074148552459383, 0.13186230142629757, 0.13150585678058205, 0.13854938271604939, 0.13748264108067165, 0.13261385278492432, 0.13183815192743764, 0.13074148552459383]\n",
      "  Average = 0.1321, CI = 0.0028\n",
      "\n",
      "Metric 'weighted avg' -> 'recall':\n",
      "  Values: [0.3657142857142857, 0.3672316384180791, 0.36363636363636365, 0.35260115606936415, 0.3742690058479532, 0.37142857142857144, 0.3532608695652174, 0.3567567567567568, 0.39204545454545453, 0.3641304347826087, 0.3465909090909091, 0.3595505617977528, 0.3651685393258427, 0.35, 0.35, 0.3641304347826087, 0.36813186813186816, 0.3615819209039548, 0.36312849162011174, 0.3626373626373626, 0.37222222222222223, 0.3707865168539326, 0.36416184971098264, 0.3630952380952381, 0.3615819209039548]\n",
      "  Average = 0.3634, CI = 0.0038\n",
      "\n",
      "Metric 'weighted avg' -> 'f1-score':\n",
      "  Values: [0.19586371787208606, 0.19727319419153008, 0.19393939393939394, 0.18383479077120696, 0.20385716063207665, 0.20119047619047617, 0.1844333857167802, 0.187617099170884, 0.2208256029684601, 0.19439632773254803, 0.1784138856923667, 0.19017550376079487, 0.19535765478337264, 0.18148148148148147, 0.18148148148148147, 0.19439632773254803, 0.19811112582196921, 0.19204350985770213, 0.19347009799432185, 0.19301666075859622, 0.20193432298695457, 0.2005894271504881, 0.19442539433721956, 0.19343938448741943, 0.19204350985770213]\n",
      "  Average = 0.1937, CI = 0.0035\n",
      "\n",
      "Metric 'weighted avg' -> 'support':\n",
      "  Values: [175.0, 177.0, 176.0, 173.0, 171.0, 175.0, 184.0, 185.0, 176.0, 184.0, 176.0, 178.0, 178.0, 180.0, 180.0, 184.0, 182.0, 177.0, 179.0, 182.0, 180.0, 178.0, 173.0, 168.0, 177.0]\n",
      "  Average = 177.9200, CI = 1.7007\n",
      "\n",
      "Final DataFrame with overall averages and CIs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-49 %_precision_avg</th>\n",
       "      <th>1-49 %_precision_ci</th>\n",
       "      <th>1-49 %_recall_avg</th>\n",
       "      <th>1-49 %_recall_ci</th>\n",
       "      <th>1-49 %_f1-score_avg</th>\n",
       "      <th>1-49 %_f1-score_ci</th>\n",
       "      <th>1-49 %_support_avg</th>\n",
       "      <th>1-49 %_support_ci</th>\n",
       "      <th>&lt; 1 %_precision_avg</th>\n",
       "      <th>&lt; 1 %_precision_ci</th>\n",
       "      <th>...</th>\n",
       "      <th>macro avg_support_avg</th>\n",
       "      <th>macro avg_support_ci</th>\n",
       "      <th>weighted avg_precision_avg</th>\n",
       "      <th>weighted avg_precision_ci</th>\n",
       "      <th>weighted avg_recall_avg</th>\n",
       "      <th>weighted avg_recall_ci</th>\n",
       "      <th>weighted avg_f1-score_avg</th>\n",
       "      <th>weighted avg_f1-score_ci</th>\n",
       "      <th>weighted avg_support_avg</th>\n",
       "      <th>weighted avg_support_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.203415</td>\n",
       "      <td>0.073691</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.202649</td>\n",
       "      <td>0.298373</td>\n",
       "      <td>0.108036</td>\n",
       "      <td>63.36</td>\n",
       "      <td>0.965263</td>\n",
       "      <td>0.159938</td>\n",
       "      <td>0.073677</td>\n",
       "      <td>...</td>\n",
       "      <td>177.92</td>\n",
       "      <td>1.700667</td>\n",
       "      <td>0.13211</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.363354</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.193744</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>177.92</td>\n",
       "      <td>1.700667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1-49 %_precision_avg  1-49 %_precision_ci  1-49 %_recall_avg  \\\n",
       "0              0.203415             0.073691               0.56   \n",
       "\n",
       "   1-49 %_recall_ci  1-49 %_f1-score_avg  1-49 %_f1-score_ci  \\\n",
       "0          0.202649             0.298373            0.108036   \n",
       "\n",
       "   1-49 %_support_avg  1-49 %_support_ci  < 1 %_precision_avg  \\\n",
       "0               63.36           0.965263             0.159938   \n",
       "\n",
       "   < 1 %_precision_ci  ...  macro avg_support_avg  macro avg_support_ci  \\\n",
       "0            0.073677  ...                 177.92              1.700667   \n",
       "\n",
       "   weighted avg_precision_avg  weighted avg_precision_ci  \\\n",
       "0                     0.13211                   0.002752   \n",
       "\n",
       "   weighted avg_recall_avg  weighted avg_recall_ci  weighted avg_f1-score_avg  \\\n",
       "0                 0.363354                0.003751                   0.193744   \n",
       "\n",
       "   weighted avg_f1-score_ci  weighted avg_support_avg  weighted avg_support_ci  \n",
       "0                  0.003486                    177.92                 1.700667  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Your list of dictionaries (using your provided sample; in your code include all items)\n",
    "reports = train_classification_reports\n",
    "\n",
    "# Number of items\n",
    "n = len(reports)\n",
    "print(f\"Total number of reports: {n}\\n\")\n",
    "\n",
    "# Function to compute average and CI (CI = 2*std/sqrt(n))\n",
    "def compute_avg_and_ci(values):\n",
    "    avg = np.mean(values)\n",
    "    std = np.std(values, ddof=1) if len(values) > 1 else 0.0\n",
    "    ci = 2 * std / np.sqrt(len(values)) if len(values) > 1 else 0.0\n",
    "    return avg, ci\n",
    "\n",
    "# Dictionary to hold our flattened average and CI values\n",
    "overall_stats = {}\n",
    "\n",
    "# Process each key in the first report as a template.\n",
    "for key in reports[0]:\n",
    "    if key == 'accuracy':\n",
    "        # Collect the accuracy values\n",
    "        values = [r[key] for r in reports]\n",
    "        avg, ci = compute_avg_and_ci(values)\n",
    "        print(f\"Metric '{key}':\")\n",
    "        print(f\"  Values: {values}\")\n",
    "        print(f\"  Average = {avg:.4f}, CI = {ci:.4f}\\n\")\n",
    "        overall_stats[f\"{key}_avg\"] = avg\n",
    "        overall_stats[f\"{key}_ci\"] = ci\n",
    "    else:\n",
    "        # For nested dictionary keys (like '1-49 %', '< 1 %', etc.)\n",
    "        for subkey in reports[0][key]:\n",
    "            values = [r[key][subkey] for r in reports]\n",
    "            avg, ci = compute_avg_and_ci(values)\n",
    "            print(f\"Metric '{key}' -> '{subkey}':\")\n",
    "            print(f\"  Values: {values}\")\n",
    "            print(f\"  Average = {avg:.4f}, CI = {ci:.4f}\\n\")\n",
    "            flat_key = f\"{key}_{subkey}\"\n",
    "            overall_stats[f\"{flat_key}_avg\"] = avg\n",
    "            overall_stats[f\"{flat_key}_ci\"] = ci\n",
    "\n",
    "# Create a DataFrame from the overall statistics dictionary.\n",
    "df = pd.DataFrame([overall_stats])\n",
    "print(\"Final DataFrame with overall averages and CIs:\")\n",
    "display(df)\n",
    "df.to_csv(\"pdl1-dummy-model-train.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reports: 25\n",
      "\n",
      "Metric '1-49 %' -> 'precision':\n",
      "  Values: [0.4186046511627907, 0.36585365853658536, 0.0, 0.37777777777777777, 0.0, 0.35294117647058826, 0.42857142857142855, 0.4146341463414634, 0.0, 0.38095238095238093, 0.0, 0.35555555555555557, 0.35555555555555557, 0.0, 0.0, 0.0, 0.4090909090909091, 0.0, 0.3829787234042553, 0.3409090909090909, 0.4358974358974359, 0.0, 0.0, 0.35294117647058826, 0.38095238095238093]\n",
      "  Average = 0.2301, CI = 0.0773\n",
      "\n",
      "Metric '1-49 %' -> 'recall':\n",
      "  Values: [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]\n",
      "  Average = 0.6000, CI = 0.2000\n",
      "\n",
      "Metric '1-49 %' -> 'f1-score':\n",
      "  Values: [0.5901639344262295, 0.5357142857142857, 0.0, 0.5483870967741935, 0.0, 0.5217391304347826, 0.6, 0.5862068965517241, 0.0, 0.5517241379310345, 0.0, 0.5245901639344263, 0.5245901639344263, 0.0, 0.0, 0.0, 0.5806451612903226, 0.0, 0.5538461538461539, 0.5084745762711864, 0.6071428571428571, 0.0, 0.0, 0.5217391304347826, 0.5517241379310345]\n",
      "  Average = 0.3323, CI = 0.1112\n",
      "\n",
      "Metric '1-49 %' -> 'support':\n",
      "  Values: [18.0, 15.0, 14.0, 17.0, 14.0, 18.0, 18.0, 17.0, 14.0, 16.0, 16.0, 16.0, 16.0, 15.0, 14.0, 13.0, 18.0, 16.0, 18.0, 15.0, 17.0, 12.0, 15.0, 18.0, 16.0]\n",
      "  Average = 15.8400, CI = 0.6897\n",
      "\n",
      "Metric '< 1 %' -> 'precision':\n",
      "  Values: [0.0, 0.0, 0.42857142857142855, 0.0, 0.3829787234042553, 0.0, 0.0, 0.0, 0.4, 0.0, 0.3829787234042553, 0.0, 0.0, 0.37209302325581395, 0.37209302325581395, 0.38095238095238093, 0.0, 0.40816326530612246, 0.0, 0.0, 0.0, 0.4146341463414634, 0.3695652173913043, 0.0, 0.0]\n",
      "  Average = 0.1565, CI = 0.0784\n",
      "\n",
      "Metric '< 1 %' -> 'recall':\n",
      "  Values: [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "  Average = 0.4000, CI = 0.2000\n",
      "\n",
      "Metric '< 1 %' -> 'f1-score':\n",
      "  Values: [0.0, 0.0, 0.6, 0.0, 0.5538461538461539, 0.0, 0.0, 0.0, 0.5714285714285714, 0.0, 0.5538461538461539, 0.0, 0.0, 0.5423728813559322, 0.5423728813559322, 0.5517241379310345, 0.0, 0.5797101449275363, 0.0, 0.0, 0.0, 0.5862068965517241, 0.5396825396825397, 0.0, 0.0]\n",
      "  Average = 0.2248, CI = 0.1125\n",
      "\n",
      "Metric '< 1 %' -> 'support':\n",
      "  Values: [12.0, 11.0, 18.0, 17.0, 18.0, 18.0, 13.0, 14.0, 20.0, 12.0, 18.0, 15.0, 14.0, 16.0, 16.0, 16.0, 14.0, 20.0, 16.0, 15.0, 12.0, 17.0, 17.0, 18.0, 15.0]\n",
      "  Average = 15.6800, CI = 0.9981\n",
      "\n",
      "Metric '>=50 %' -> 'precision':\n",
      "  Values: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Average = 0.0000, CI = 0.0000\n",
      "\n",
      "Metric '>=50 %' -> 'recall':\n",
      "  Values: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Average = 0.0000, CI = 0.0000\n",
      "\n",
      "Metric '>=50 %' -> 'f1-score':\n",
      "  Values: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Average = 0.0000, CI = 0.0000\n",
      "\n",
      "Metric '>=50 %' -> 'support':\n",
      "  Values: [13.0, 15.0, 10.0, 11.0, 15.0, 15.0, 11.0, 10.0, 16.0, 14.0, 13.0, 14.0, 15.0, 12.0, 13.0, 13.0, 12.0, 13.0, 13.0, 14.0, 10.0, 12.0, 14.0, 15.0, 11.0]\n",
      "  Average = 12.9600, CI = 0.7069\n",
      "\n",
      "Metric 'accuracy':\n",
      "  Values: [0.4186046511627907, 0.36585365853658536, 0.42857142857142855, 0.37777777777777777, 0.3829787234042553, 0.35294117647058826, 0.42857142857142855, 0.4146341463414634, 0.4, 0.38095238095238093, 0.3829787234042553, 0.35555555555555557, 0.35555555555555557, 0.37209302325581395, 0.37209302325581395, 0.38095238095238093, 0.4090909090909091, 0.40816326530612246, 0.3829787234042553, 0.3409090909090909, 0.4358974358974359, 0.4146341463414634, 0.3695652173913043, 0.35294117647058826, 0.38095238095238093]\n",
      "  Average = 0.3866, CI = 0.0108\n",
      "\n",
      "Metric 'macro avg' -> 'precision':\n",
      "  Values: [0.13953488372093023, 0.12195121951219512, 0.14285714285714285, 0.1259259259259259, 0.1276595744680851, 0.11764705882352942, 0.14285714285714285, 0.13821138211382114, 0.13333333333333333, 0.12698412698412698, 0.1276595744680851, 0.11851851851851852, 0.11851851851851852, 0.12403100775193798, 0.12403100775193798, 0.12698412698412698, 0.13636363636363638, 0.1360544217687075, 0.1276595744680851, 0.11363636363636363, 0.1452991452991453, 0.13821138211382114, 0.12318840579710144, 0.11764705882352942, 0.12698412698412698]\n",
      "  Average = 0.1289, CI = 0.0036\n",
      "\n",
      "Metric 'macro avg' -> 'recall':\n",
      "  Values: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "  Average = 0.3333, CI = 0.0000\n",
      "\n",
      "Metric 'macro avg' -> 'f1-score':\n",
      "  Values: [0.19672131147540983, 0.17857142857142858, 0.19999999999999998, 0.18279569892473116, 0.18461538461538463, 0.17391304347826086, 0.19999999999999998, 0.1954022988505747, 0.19047619047619047, 0.1839080459770115, 0.18461538461538463, 0.17486338797814208, 0.17486338797814208, 0.1807909604519774, 0.1807909604519774, 0.1839080459770115, 0.19354838709677422, 0.1932367149758454, 0.18461538461538463, 0.1694915254237288, 0.20238095238095236, 0.1954022988505747, 0.17989417989417988, 0.17391304347826086, 0.1839080459770115]\n",
      "  Average = 0.1857, CI = 0.0037\n",
      "\n",
      "Metric 'macro avg' -> 'support':\n",
      "  Values: [43.0, 41.0, 42.0, 45.0, 47.0, 51.0, 42.0, 41.0, 50.0, 42.0, 47.0, 45.0, 45.0, 43.0, 43.0, 42.0, 44.0, 49.0, 47.0, 44.0, 39.0, 41.0, 46.0, 51.0, 42.0]\n",
      "  Average = 44.4800, CI = 1.3222\n",
      "\n",
      "Metric 'weighted avg' -> 'precision':\n",
      "  Values: [0.1752298539751217, 0.1338488994646044, 0.18367346938775508, 0.14271604938271606, 0.1466727025803531, 0.12456747404844291, 0.18367346938775508, 0.1719214753123141, 0.16, 0.14512471655328799, 0.1466727025803531, 0.12641975308641976, 0.12641975308641976, 0.13845321795565171, 0.13845321795565171, 0.14512471655328799, 0.16735537190082647, 0.16659725114535612, 0.1466727025803531, 0.1162190082644628, 0.19000657462195925, 0.1719214753123141, 0.13657844990548204, 0.12456747404844291, 0.14512471655328799]\n",
      "  Average = 0.1502, CI = 0.0084\n",
      "\n",
      "Metric 'weighted avg' -> 'recall':\n",
      "  Values: [0.4186046511627907, 0.36585365853658536, 0.42857142857142855, 0.37777777777777777, 0.3829787234042553, 0.35294117647058826, 0.42857142857142855, 0.4146341463414634, 0.4, 0.38095238095238093, 0.3829787234042553, 0.35555555555555557, 0.35555555555555557, 0.37209302325581395, 0.37209302325581395, 0.38095238095238093, 0.4090909090909091, 0.40816326530612246, 0.3829787234042553, 0.3409090909090909, 0.4358974358974359, 0.4146341463414634, 0.3695652173913043, 0.35294117647058826, 0.38095238095238093]\n",
      "  Average = 0.3866, CI = 0.0108\n",
      "\n",
      "Metric 'weighted avg' -> 'f1-score':\n",
      "  Values: [0.24704536789935186, 0.195993031358885, 0.2571428571428571, 0.207168458781362, 0.21211129296235678, 0.18414322250639384, 0.2571428571428571, 0.24306139613120267, 0.22857142857142854, 0.21018062397372742, 0.21211129296235678, 0.18652094717668488, 0.18652094717668488, 0.2018131651556957, 0.2018131651556957, 0.21018062397372742, 0.23753665689149564, 0.23661638568470866, 0.21211129296235678, 0.17334360554699535, 0.26465201465201466, 0.24306139613120267, 0.199447895100069, 0.18414322250639384, 0.21018062397372742]\n",
      "  Average = 0.2161, CI = 0.0104\n",
      "\n",
      "Metric 'weighted avg' -> 'support':\n",
      "  Values: [43.0, 41.0, 42.0, 45.0, 47.0, 51.0, 42.0, 41.0, 50.0, 42.0, 47.0, 45.0, 45.0, 43.0, 43.0, 42.0, 44.0, 49.0, 47.0, 44.0, 39.0, 41.0, 46.0, 51.0, 42.0]\n",
      "  Average = 44.4800, CI = 1.3222\n",
      "\n",
      "Final DataFrame with overall averages and CIs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-49 %_precision_avg</th>\n",
       "      <th>1-49 %_precision_ci</th>\n",
       "      <th>1-49 %_recall_avg</th>\n",
       "      <th>1-49 %_recall_ci</th>\n",
       "      <th>1-49 %_f1-score_avg</th>\n",
       "      <th>1-49 %_f1-score_ci</th>\n",
       "      <th>1-49 %_support_avg</th>\n",
       "      <th>1-49 %_support_ci</th>\n",
       "      <th>&lt; 1 %_precision_avg</th>\n",
       "      <th>&lt; 1 %_precision_ci</th>\n",
       "      <th>...</th>\n",
       "      <th>macro avg_support_avg</th>\n",
       "      <th>macro avg_support_ci</th>\n",
       "      <th>weighted avg_precision_avg</th>\n",
       "      <th>weighted avg_precision_ci</th>\n",
       "      <th>weighted avg_recall_avg</th>\n",
       "      <th>weighted avg_recall_ci</th>\n",
       "      <th>weighted avg_f1-score_avg</th>\n",
       "      <th>weighted avg_f1-score_ci</th>\n",
       "      <th>weighted avg_support_avg</th>\n",
       "      <th>weighted avg_support_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230129</td>\n",
       "      <td>0.077282</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.332268</td>\n",
       "      <td>0.111184</td>\n",
       "      <td>15.84</td>\n",
       "      <td>0.689734</td>\n",
       "      <td>0.156481</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>...</td>\n",
       "      <td>44.48</td>\n",
       "      <td>1.32222</td>\n",
       "      <td>0.150161</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.38661</td>\n",
       "      <td>0.01075</td>\n",
       "      <td>0.216105</td>\n",
       "      <td>0.010366</td>\n",
       "      <td>44.48</td>\n",
       "      <td>1.32222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1-49 %_precision_avg  1-49 %_precision_ci  1-49 %_recall_avg  \\\n",
       "0              0.230129             0.077282                0.6   \n",
       "\n",
       "   1-49 %_recall_ci  1-49 %_f1-score_avg  1-49 %_f1-score_ci  \\\n",
       "0               0.2             0.332268            0.111184   \n",
       "\n",
       "   1-49 %_support_avg  1-49 %_support_ci  < 1 %_precision_avg  \\\n",
       "0               15.84           0.689734             0.156481   \n",
       "\n",
       "   < 1 %_precision_ci  ...  macro avg_support_avg  macro avg_support_ci  \\\n",
       "0              0.0784  ...                  44.48               1.32222   \n",
       "\n",
       "   weighted avg_precision_avg  weighted avg_precision_ci  \\\n",
       "0                    0.150161                   0.008388   \n",
       "\n",
       "   weighted avg_recall_avg  weighted avg_recall_ci  weighted avg_f1-score_avg  \\\n",
       "0                  0.38661                 0.01075                   0.216105   \n",
       "\n",
       "   weighted avg_f1-score_ci  weighted avg_support_avg  weighted avg_support_ci  \n",
       "0                  0.010366                     44.48                  1.32222  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Your list of dictionaries (using your provided sample; in your code include all items)\n",
    "reports = val_classification_reports\n",
    "\n",
    "# Number of items\n",
    "n = len(reports)\n",
    "print(f\"Total number of reports: {n}\\n\")\n",
    "\n",
    "# Function to compute average and CI (CI = 2*std/sqrt(n))\n",
    "def compute_avg_and_ci(values):\n",
    "    avg = np.mean(values)\n",
    "    std = np.std(values, ddof=1) if len(values) > 1 else 0.0\n",
    "    ci = 2 * std / np.sqrt(len(values)) if len(values) > 1 else 0.0\n",
    "    return avg, ci\n",
    "\n",
    "# Dictionary to hold our flattened average and CI values\n",
    "overall_stats = {}\n",
    "\n",
    "# Process each key in the first report as a template.\n",
    "for key in reports[0]:\n",
    "    if key == 'accuracy':\n",
    "        # Collect the accuracy values\n",
    "        values = [r[key] for r in reports]\n",
    "        avg, ci = compute_avg_and_ci(values)\n",
    "        print(f\"Metric '{key}':\")\n",
    "        print(f\"  Values: {values}\")\n",
    "        print(f\"  Average = {avg:.4f}, CI = {ci:.4f}\\n\")\n",
    "        overall_stats[f\"{key}_avg\"] = avg\n",
    "        overall_stats[f\"{key}_ci\"] = ci\n",
    "    else:\n",
    "        # For nested dictionary keys (like '1-49 %', '< 1 %', etc.)\n",
    "        for subkey in reports[0][key]:\n",
    "            values = [r[key][subkey] for r in reports]\n",
    "            avg, ci = compute_avg_and_ci(values)\n",
    "            print(f\"Metric '{key}' -> '{subkey}':\")\n",
    "            print(f\"  Values: {values}\")\n",
    "            print(f\"  Average = {avg:.4f}, CI = {ci:.4f}\\n\")\n",
    "            flat_key = f\"{key}_{subkey}\"\n",
    "            overall_stats[f\"{flat_key}_avg\"] = avg\n",
    "            overall_stats[f\"{flat_key}_ci\"] = ci\n",
    "\n",
    "# Create a DataFrame from the overall statistics dictionary.\n",
    "df = pd.DataFrame([overall_stats])\n",
    "print(\"Final DataFrame with overall averages and CIs:\")\n",
    "display(df)\n",
    "df.to_csv(\"pdl1-dummy-model-val.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reports: 25\n",
      "\n",
      "Metric '1-49 %' -> 'precision':\n",
      "  Values: [0.0, 0.0, 0.35, 0.35, 0.35, 0.3076923076923077, 0.3076923076923077, 0.3076923076923077, 0.3076923076923077, 0.3076923076923077, 0.4, 0.0, 0.0, 0.0, 0.4, 0.36538461538461536, 0.0, 0.36538461538461536, 0.0, 0.0, 0.0, 0.3559322033898305, 0.3559322033898305, 0.0, 0.0]\n",
      "  Average = 0.1932, CI = 0.0706\n",
      "\n",
      "Metric '1-49 %' -> 'recall':\n",
      "  Values: [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "  Average = 0.5600, CI = 0.2026\n",
      "\n",
      "Metric '1-49 %' -> 'f1-score':\n",
      "  Values: [0.0, 0.0, 0.5185185185185185, 0.5185185185185185, 0.5185185185185185, 0.47058823529411764, 0.47058823529411764, 0.47058823529411764, 0.47058823529411764, 0.47058823529411764, 0.5714285714285714, 0.0, 0.0, 0.0, 0.5714285714285714, 0.5352112676056338, 0.0, 0.5352112676056338, 0.0, 0.0, 0.0, 0.525, 0.525, 0.0, 0.0]\n",
      "  Average = 0.2869, CI = 0.1044\n",
      "\n",
      "Metric '1-49 %' -> 'support':\n",
      "  Values: [21.0, 21.0, 21.0, 21.0, 21.0, 16.0, 16.0, 16.0, 16.0, 16.0, 22.0, 22.0, 22.0, 22.0, 22.0, 19.0, 19.0, 19.0, 19.0, 19.0, 21.0, 21.0, 21.0, 21.0, 21.0]\n",
      "  Average = 19.8000, CI = 0.8718\n",
      "\n",
      "Metric '< 1 %' -> 'precision':\n",
      "  Values: [0.36666666666666664, 0.36666666666666664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34545454545454546, 0.34545454545454546, 0.34545454545454546, 0.0, 0.0, 0.3269230769230769, 0.0, 0.3269230769230769, 0.3269230769230769, 0.3220338983050847, 0.0, 0.0, 0.3220338983050847, 0.3220338983050847]\n",
      "  Average = 0.1487, CI = 0.0686\n",
      "\n",
      "Metric '< 1 %' -> 'recall':\n",
      "  Values: [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]\n",
      "  Average = 0.4400, CI = 0.2026\n",
      "\n",
      "Metric '< 1 %' -> 'f1-score':\n",
      "  Values: [0.5365853658536586, 0.5365853658536586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5135135135135135, 0.5135135135135135, 0.5135135135135135, 0.0, 0.0, 0.4927536231884058, 0.0, 0.4927536231884058, 0.4927536231884058, 0.48717948717948717, 0.0, 0.0, 0.48717948717948717, 0.48717948717948717]\n",
      "  Average = 0.2221, CI = 0.1024\n",
      "\n",
      "Metric '< 1 %' -> 'support':\n",
      "  Values: [22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 21.0, 21.0, 21.0, 21.0, 19.0, 19.0, 19.0, 19.0, 19.0, 17.0, 17.0, 17.0, 17.0, 17.0, 19.0, 19.0, 19.0, 19.0, 19.0]\n",
      "  Average = 19.6000, CI = 0.7118\n",
      "\n",
      "Metric '>=50 %' -> 'precision':\n",
      "  Values: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Average = 0.0000, CI = 0.0000\n",
      "\n",
      "Metric '>=50 %' -> 'recall':\n",
      "  Values: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Average = 0.0000, CI = 0.0000\n",
      "\n",
      "Metric '>=50 %' -> 'f1-score':\n",
      "  Values: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  Average = 0.0000, CI = 0.0000\n",
      "\n",
      "Metric '>=50 %' -> 'support':\n",
      "  Values: [17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 15.0, 15.0, 15.0, 15.0, 14.0, 14.0, 14.0, 14.0, 14.0, 16.0, 16.0, 16.0, 16.0, 16.0, 19.0, 19.0, 19.0, 19.0, 19.0]\n",
      "  Average = 16.2000, CI = 0.7024\n",
      "\n",
      "Metric 'accuracy':\n",
      "  Values: [0.36666666666666664, 0.36666666666666664, 0.35, 0.35, 0.35, 0.3076923076923077, 0.3076923076923077, 0.3076923076923077, 0.3076923076923077, 0.3076923076923077, 0.4, 0.34545454545454546, 0.34545454545454546, 0.34545454545454546, 0.4, 0.36538461538461536, 0.3269230769230769, 0.36538461538461536, 0.3269230769230769, 0.3269230769230769, 0.3220338983050847, 0.3559322033898305, 0.3559322033898305, 0.3220338983050847, 0.3220338983050847]\n",
      "  Average = 0.3419, CI = 0.0108\n",
      "\n",
      "Metric 'macro avg' -> 'precision':\n",
      "  Values: [0.12222222222222222, 0.12222222222222222, 0.11666666666666665, 0.11666666666666665, 0.11666666666666665, 0.10256410256410257, 0.10256410256410257, 0.10256410256410257, 0.10256410256410257, 0.10256410256410257, 0.13333333333333333, 0.11515151515151516, 0.11515151515151516, 0.11515151515151516, 0.13333333333333333, 0.12179487179487179, 0.10897435897435898, 0.12179487179487179, 0.10897435897435898, 0.10897435897435898, 0.10734463276836158, 0.11864406779661017, 0.11864406779661017, 0.10734463276836158, 0.10734463276836158]\n",
      "  Average = 0.1140, CI = 0.0036\n",
      "\n",
      "Metric 'macro avg' -> 'recall':\n",
      "  Values: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "  Average = 0.3333, CI = 0.0000\n",
      "\n",
      "Metric 'macro avg' -> 'f1-score':\n",
      "  Values: [0.17886178861788618, 0.17886178861788618, 0.1728395061728395, 0.1728395061728395, 0.1728395061728395, 0.1568627450980392, 0.1568627450980392, 0.1568627450980392, 0.1568627450980392, 0.1568627450980392, 0.19047619047619047, 0.17117117117117117, 0.17117117117117117, 0.17117117117117117, 0.19047619047619047, 0.1784037558685446, 0.1642512077294686, 0.1784037558685446, 0.1642512077294686, 0.1642512077294686, 0.1623931623931624, 0.17500000000000002, 0.17500000000000002, 0.1623931623931624, 0.1623931623931624]\n",
      "  Average = 0.1697, CI = 0.0040\n",
      "\n",
      "Metric 'macro avg' -> 'support':\n",
      "  Values: [60.0, 60.0, 60.0, 60.0, 60.0, 52.0, 52.0, 52.0, 52.0, 52.0, 55.0, 55.0, 55.0, 55.0, 55.0, 52.0, 52.0, 52.0, 52.0, 52.0, 59.0, 59.0, 59.0, 59.0, 59.0]\n",
      "  Average = 55.6000, CI = 1.3808\n",
      "\n",
      "Metric 'weighted avg' -> 'precision':\n",
      "  Values: [0.13444444444444445, 0.13444444444444445, 0.1225, 0.1225, 0.1225, 0.09467455621301776, 0.09467455621301776, 0.09467455621301776, 0.09467455621301776, 0.09467455621301776, 0.16, 0.11933884297520661, 0.11933884297520661, 0.11933884297520661, 0.16, 0.1335059171597633, 0.10687869822485206, 0.1335059171597633, 0.10687869822485206, 0.10687869822485206, 0.10370583165756966, 0.12668773340993966, 0.12668773340993966, 0.10370583165756966, 0.10370583165756966]\n",
      "  Average = 0.1176, CI = 0.0075\n",
      "\n",
      "Metric 'weighted avg' -> 'recall':\n",
      "  Values: [0.36666666666666664, 0.36666666666666664, 0.35, 0.35, 0.35, 0.3076923076923077, 0.3076923076923077, 0.3076923076923077, 0.3076923076923077, 0.3076923076923077, 0.4, 0.34545454545454546, 0.34545454545454546, 0.34545454545454546, 0.4, 0.36538461538461536, 0.3269230769230769, 0.36538461538461536, 0.3269230769230769, 0.3269230769230769, 0.3220338983050847, 0.3559322033898305, 0.3559322033898305, 0.3220338983050847, 0.3220338983050847]\n",
      "  Average = 0.3419, CI = 0.0108\n",
      "\n",
      "Metric 'weighted avg' -> 'f1-score':\n",
      "  Values: [0.1967479674796748, 0.1967479674796748, 0.18148148148148147, 0.18148148148148147, 0.18148148148148147, 0.14479638009049772, 0.14479638009049772, 0.14479638009049772, 0.14479638009049772, 0.14479638009049772, 0.22857142857142856, 0.17739557739557738, 0.17739557739557738, 0.17739557739557738, 0.22857142857142856, 0.19555796316359697, 0.16109253065774803, 0.19555796316359697, 0.16109253065774803, 0.16109253065774803, 0.1568883094306823, 0.186864406779661, 0.186864406779661, 0.1568883094306823, 0.1568883094306823]\n",
      "  Average = 0.1748, CI = 0.0097\n",
      "\n",
      "Metric 'weighted avg' -> 'support':\n",
      "  Values: [60.0, 60.0, 60.0, 60.0, 60.0, 52.0, 52.0, 52.0, 52.0, 52.0, 55.0, 55.0, 55.0, 55.0, 55.0, 52.0, 52.0, 52.0, 52.0, 52.0, 59.0, 59.0, 59.0, 59.0, 59.0]\n",
      "  Average = 55.6000, CI = 1.3808\n",
      "\n",
      "Final DataFrame with overall averages and CIs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-49 %_precision_avg</th>\n",
       "      <th>1-49 %_precision_ci</th>\n",
       "      <th>1-49 %_recall_avg</th>\n",
       "      <th>1-49 %_recall_ci</th>\n",
       "      <th>1-49 %_f1-score_avg</th>\n",
       "      <th>1-49 %_f1-score_ci</th>\n",
       "      <th>1-49 %_support_avg</th>\n",
       "      <th>1-49 %_support_ci</th>\n",
       "      <th>&lt; 1 %_precision_avg</th>\n",
       "      <th>&lt; 1 %_precision_ci</th>\n",
       "      <th>...</th>\n",
       "      <th>macro avg_support_avg</th>\n",
       "      <th>macro avg_support_ci</th>\n",
       "      <th>weighted avg_precision_avg</th>\n",
       "      <th>weighted avg_precision_ci</th>\n",
       "      <th>weighted avg_recall_avg</th>\n",
       "      <th>weighted avg_recall_ci</th>\n",
       "      <th>weighted avg_f1-score_avg</th>\n",
       "      <th>weighted avg_f1-score_ci</th>\n",
       "      <th>weighted avg_support_avg</th>\n",
       "      <th>weighted avg_support_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.193244</td>\n",
       "      <td>0.070601</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.202649</td>\n",
       "      <td>0.286871</td>\n",
       "      <td>0.104361</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.87178</td>\n",
       "      <td>0.148663</td>\n",
       "      <td>0.068612</td>\n",
       "      <td>...</td>\n",
       "      <td>55.6</td>\n",
       "      <td>1.380821</td>\n",
       "      <td>0.117597</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.341907</td>\n",
       "      <td>0.010776</td>\n",
       "      <td>0.174802</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>55.6</td>\n",
       "      <td>1.380821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1-49 %_precision_avg  1-49 %_precision_ci  1-49 %_recall_avg  \\\n",
       "0              0.193244             0.070601               0.56   \n",
       "\n",
       "   1-49 %_recall_ci  1-49 %_f1-score_avg  1-49 %_f1-score_ci  \\\n",
       "0          0.202649             0.286871            0.104361   \n",
       "\n",
       "   1-49 %_support_avg  1-49 %_support_ci  < 1 %_precision_avg  \\\n",
       "0                19.8            0.87178             0.148663   \n",
       "\n",
       "   < 1 %_precision_ci  ...  macro avg_support_avg  macro avg_support_ci  \\\n",
       "0            0.068612  ...                   55.6              1.380821   \n",
       "\n",
       "   weighted avg_precision_avg  weighted avg_precision_ci  \\\n",
       "0                    0.117597                   0.007513   \n",
       "\n",
       "   weighted avg_recall_avg  weighted avg_recall_ci  weighted avg_f1-score_avg  \\\n",
       "0                 0.341907                0.010776                   0.174802   \n",
       "\n",
       "   weighted avg_f1-score_ci  weighted avg_support_avg  weighted avg_support_ci  \n",
       "0                  0.009689                      55.6                 1.380821  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Your list of dictionaries (using your provided sample; in your code include all items)\n",
    "reports = test_scores\n",
    "\n",
    "# Number of items\n",
    "n = len(reports)\n",
    "print(f\"Total number of reports: {n}\\n\")\n",
    "\n",
    "# Function to compute average and CI (CI = 2*std/sqrt(n))\n",
    "def compute_avg_and_ci(values):\n",
    "    avg = np.mean(values)\n",
    "    std = np.std(values, ddof=1) if len(values) > 1 else 0.0\n",
    "    ci = 2 * std / np.sqrt(len(values)) if len(values) > 1 else 0.0\n",
    "    return avg, ci\n",
    "\n",
    "# Dictionary to hold our flattened average and CI values\n",
    "overall_stats = {}\n",
    "\n",
    "# Process each key in the first report as a template.\n",
    "for key in reports[0]:\n",
    "    if key == 'accuracy':\n",
    "        # Collect the accuracy values\n",
    "        values = [r[key] for r in reports]\n",
    "        avg, ci = compute_avg_and_ci(values)\n",
    "        print(f\"Metric '{key}':\")\n",
    "        print(f\"  Values: {values}\")\n",
    "        print(f\"  Average = {avg:.4f}, CI = {ci:.4f}\\n\")\n",
    "        overall_stats[f\"{key}_avg\"] = avg\n",
    "        overall_stats[f\"{key}_ci\"] = ci\n",
    "    else:\n",
    "        # For nested dictionary keys (like '1-49 %', '< 1 %', etc.)\n",
    "        for subkey in reports[0][key]:\n",
    "            values = [r[key][subkey] for r in reports]\n",
    "            avg, ci = compute_avg_and_ci(values)\n",
    "            print(f\"Metric '{key}' -> '{subkey}':\")\n",
    "            print(f\"  Values: {values}\")\n",
    "            print(f\"  Average = {avg:.4f}, CI = {ci:.4f}\\n\")\n",
    "            flat_key = f\"{key}_{subkey}\"\n",
    "            overall_stats[f\"{flat_key}_avg\"] = avg\n",
    "            overall_stats[f\"{flat_key}_ci\"] = ci\n",
    "\n",
    "# Create a DataFrame from the overall statistics dictionary.\n",
    "df = pd.DataFrame([overall_stats])\n",
    "print(\"Final DataFrame with overall averages and CIs:\")\n",
    "display(df)\n",
    "df.to_csv(\"pdl1-dummy-model-test.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_train</th>\n",
       "      <th>1-49 %_precision_avg_train</th>\n",
       "      <th>1-49 %_recall_avg_train</th>\n",
       "      <th>1-49 %_f1-score_avg_train</th>\n",
       "      <th>1-49 %_support_avg_train</th>\n",
       "      <th>&lt; 1 %_precision_avg_train</th>\n",
       "      <th>&lt; 1 %_recall_avg_train</th>\n",
       "      <th>&lt; 1 %_f1-score_avg_train</th>\n",
       "      <th>&lt; 1 %_support_avg_train</th>\n",
       "      <th>&gt;=50 %_precision_avg_train</th>\n",
       "      <th>...</th>\n",
       "      <th>&gt;=50 %_support_avg_test</th>\n",
       "      <th>accuracy_avg_test</th>\n",
       "      <th>macro avg_precision_avg_test</th>\n",
       "      <th>macro avg_recall_avg_test</th>\n",
       "      <th>macro avg_f1-score_avg_test</th>\n",
       "      <th>macro avg_support_avg_test</th>\n",
       "      <th>weighted avg_precision_avg_test</th>\n",
       "      <th>weighted avg_recall_avg_test</th>\n",
       "      <th>weighted avg_f1-score_avg_test</th>\n",
       "      <th>weighted avg_support_avg_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.218101</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.319876</td>\n",
       "      <td>62.4</td>\n",
       "      <td>0.146589</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.214551</td>\n",
       "      <td>60.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.2</td>\n",
       "      <td>0.364690</td>\n",
       "      <td>0.121563</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.178142</td>\n",
       "      <td>174.4</td>\n",
       "      <td>0.133048</td>\n",
       "      <td>0.364690</td>\n",
       "      <td>0.194954</td>\n",
       "      <td>174.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.367524</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.537356</td>\n",
       "      <td>66.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.8</td>\n",
       "      <td>0.367524</td>\n",
       "      <td>0.122508</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.179119</td>\n",
       "      <td>180.8</td>\n",
       "      <td>0.135264</td>\n",
       "      <td>0.367524</td>\n",
       "      <td>0.197693</td>\n",
       "      <td>180.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.139318</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.206657</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.214944</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.316485</td>\n",
       "      <td>63.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.6</td>\n",
       "      <td>0.354262</td>\n",
       "      <td>0.118087</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.174381</td>\n",
       "      <td>178.4</td>\n",
       "      <td>0.125550</td>\n",
       "      <td>0.354262</td>\n",
       "      <td>0.185382</td>\n",
       "      <td>178.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.212997</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.218780</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.320640</td>\n",
       "      <td>64.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.363922</td>\n",
       "      <td>0.121307</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.177879</td>\n",
       "      <td>180.8</td>\n",
       "      <td>0.132444</td>\n",
       "      <td>0.363922</td>\n",
       "      <td>0.194208</td>\n",
       "      <td>180.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.146990</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.214976</td>\n",
       "      <td>62.4</td>\n",
       "      <td>0.219380</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.321276</td>\n",
       "      <td>63.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.6</td>\n",
       "      <td>0.366370</td>\n",
       "      <td>0.122123</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.178751</td>\n",
       "      <td>175.2</td>\n",
       "      <td>0.134245</td>\n",
       "      <td>0.366370</td>\n",
       "      <td>0.196486</td>\n",
       "      <td>175.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_train  1-49 %_precision_avg_train  1-49 %_recall_avg_train  \\\n",
       "0            0                    0.218101                      0.6   \n",
       "1            1                    0.367524                      1.0   \n",
       "2            2                    0.139318                      0.4   \n",
       "3            3                    0.145142                      0.4   \n",
       "4            4                    0.146990                      0.4   \n",
       "\n",
       "   1-49 %_f1-score_avg_train  1-49 %_support_avg_train  \\\n",
       "0                   0.319876                      62.4   \n",
       "1                   0.537356                      66.4   \n",
       "2                   0.206657                      61.6   \n",
       "3                   0.212997                      64.0   \n",
       "4                   0.214976                      62.4   \n",
       "\n",
       "   < 1 %_precision_avg_train  < 1 %_recall_avg_train  \\\n",
       "0                   0.146589                     0.4   \n",
       "1                   0.000000                     0.0   \n",
       "2                   0.214944                     0.6   \n",
       "3                   0.218780                     0.6   \n",
       "4                   0.219380                     0.6   \n",
       "\n",
       "   < 1 %_f1-score_avg_train  < 1 %_support_avg_train  \\\n",
       "0                  0.214551                     60.8   \n",
       "1                  0.000000                     61.6   \n",
       "2                  0.316485                     63.2   \n",
       "3                  0.320640                     64.8   \n",
       "4                  0.321276                     63.2   \n",
       "\n",
       "   >=50 %_precision_avg_train  ...  >=50 %_support_avg_test  \\\n",
       "0                         0.0  ...                     51.2   \n",
       "1                         0.0  ...                     52.8   \n",
       "2                         0.0  ...                     53.6   \n",
       "3                         0.0  ...                     52.0   \n",
       "4                         0.0  ...                     49.6   \n",
       "\n",
       "   accuracy_avg_test  macro avg_precision_avg_test  macro avg_recall_avg_test  \\\n",
       "0           0.364690                      0.121563                   0.333333   \n",
       "1           0.367524                      0.122508                   0.333333   \n",
       "2           0.354262                      0.118087                   0.333333   \n",
       "3           0.363922                      0.121307                   0.333333   \n",
       "4           0.366370                      0.122123                   0.333333   \n",
       "\n",
       "   macro avg_f1-score_avg_test  macro avg_support_avg_test  \\\n",
       "0                     0.178142                       174.4   \n",
       "1                     0.179119                       180.8   \n",
       "2                     0.174381                       178.4   \n",
       "3                     0.177879                       180.8   \n",
       "4                     0.178751                       175.2   \n",
       "\n",
       "   weighted avg_precision_avg_test  weighted avg_recall_avg_test  \\\n",
       "0                         0.133048                      0.364690   \n",
       "1                         0.135264                      0.367524   \n",
       "2                         0.125550                      0.354262   \n",
       "3                         0.132444                      0.363922   \n",
       "4                         0.134245                      0.366370   \n",
       "\n",
       "   weighted avg_f1-score_avg_test  weighted avg_support_avg_test  \n",
       "0                        0.194954                          174.4  \n",
       "1                        0.197693                          180.8  \n",
       "2                        0.185382                          178.4  \n",
       "3                        0.194208                          180.8  \n",
       "4                        0.196486                          175.2  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"pdl1-dummy-model.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
